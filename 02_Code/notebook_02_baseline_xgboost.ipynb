{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "NFyb0ib3VRXn",
        "outputId": "4ae199f8-ccd0-43bc-ae5a-f7f688b21687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE EXPERIMENTS - CELL 1: ENVIRONMENT SETUP\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/10] Mounting Google Drive...\n",
            "--------------------------------------------------\n",
            "Mounted at /content/drive\n",
            "SUCCESS: Google Drive mounted\n",
            "\n",
            "[STEP 2/10] Configuring project paths...\n",
            "--------------------------------------------------\n",
            "  FOUND: root\n",
            "  FOUND: dataset\n",
            "  FOUND: preprocessed\n",
            "  FOUND: results\n",
            "  FOUND: baseline_results\n",
            "\n",
            "Verifying preprocessed files exist...\n",
            "  TRAIN: 0.17 MB\n",
            "  VAL: 0.04 MB\n",
            "  TEST: 0.05 MB\n",
            "\n",
            "[STEP 3/10] Importing libraries...\n",
            "--------------------------------------------------\n",
            "SUCCESS: All libraries imported\n",
            "\n",
            "[STEP 4/10] Setting global configuration...\n",
            "--------------------------------------------------\n",
            "Random state: 42\n",
            "Primary metric: roc_auc\n",
            "CV folds: 5\n",
            "Runs per baseline: 10\n",
            "\n",
            "[STEP 5/10] Defining XGBoost configurations...\n",
            "--------------------------------------------------\n",
            "Unified XGBoost config (final model):\n",
            "  n_estimators=500, max_depth=8, lr=0.05\n",
            "  subsample=0.8, colsample=0.8\n",
            "\n",
            "RFECV XGBoost config (feature selection):\n",
            "  n_estimators=150, max_depth=6, lr=0.1\n",
            "  subsample=1.0, colsample=1.0\n",
            "\n",
            "[STEP 6/10] Defining utility functions...\n",
            "--------------------------------------------------\n",
            "SUCCESS: Utility functions defined\n",
            "\n",
            "[STEP 7/10] Loading preprocessed datasets...\n",
            "--------------------------------------------------\n",
            "Train: 1,270 samples x 25 features\n",
            "Val:   318 samples x 25 features\n",
            "Test:  397 samples x 25 features\n",
            "\n",
            "[STEP 8/10] Verifying data integrity...\n",
            "--------------------------------------------------\n",
            "Sample count verification:\n",
            "  TRAIN: 1,270 (expected 1,270) - PASS\n",
            "  VAL: 318 (expected 318) - PASS\n",
            "  TEST: 397 (expected 397) - PASS\n",
            "\n",
            "Feature count verification:\n",
            "  TRAIN: 25 features (expected 25) - PASS\n",
            "  VAL: 25 features (expected 25) - PASS\n",
            "  TEST: 25 features (expected 25) - PASS\n",
            "\n",
            "Verifying excluded columns removed:\n",
            "  CONFIRMED: ['CASE_NO_PATIENTS', 'Ethnicity'] not present\n",
            "\n",
            "Target encoding verification:\n",
            "  CONFIRMED: Target encoded as 0=Non-ASD, 1=ASD\n",
            "\n",
            "Data quality checks:\n",
            "  TRAIN: missing=0, infinite=0 - PASS\n",
            "  VAL: missing=0, infinite=0 - PASS\n",
            "  TEST: missing=0, infinite=0 - PASS\n",
            "\n",
            "Class distribution:\n",
            "  TRAIN: Non-ASD=583 (45.9%), ASD=687 (54.1%)\n",
            "  VAL: Non-ASD=146 (45.9%), ASD=172 (54.1%)\n",
            "  TEST: Non-ASD=182 (45.8%), ASD=215 (54.2%)\n",
            "\n",
            "[STEP 9/10] System configuration...\n",
            "--------------------------------------------------\n",
            "Python: 3.12.12\n",
            "Pandas: 2.2.2\n",
            "NumPy: 2.0.2\n",
            "XGBoost: 3.1.1\n",
            "Matplotlib backend: Agg\n",
            "GPU: Not available\n",
            "\n",
            "[STEP 10/10] Saving setup information...\n",
            "--------------------------------------------------\n",
            "Setup information saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/setup_info.json\n",
            "\n",
            "================================================================================\n",
            "CELL 1 COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "ENVIRONMENT STATUS:\n",
            "  Project root: /content/drive/MyDrive/ASD_GWO_XGBoost_Project\n",
            "  Results directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup\n",
            "  GPU available: False\n",
            "\n",
            "DATA STATUS:\n",
            "  Train: 1,270 samples x 25 features\n",
            "  Validation: 318 samples x 25 features\n",
            "  Test: 397 samples x 25 features\n",
            "  All integrity checks: PASSED\n",
            "\n",
            "CONFIGURATION:\n",
            "  Random state: 42\n",
            "  Scoring metric: roc_auc\n",
            "  Runs per baseline: 10\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 2: Baseline 1 - XGBoost with All Features\n",
            "  Cell 3: Baseline 2 - XGBoost with SelectKBest\n",
            "  Cell 4: Baseline 3 - XGBoost with RFECV\n",
            "\n",
            "================================================================================\n",
            "READY FOR BASELINE EXPERIMENTS\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 1: Environment Setup & Data Loading\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 1: Environment setup and load preprocessed datasets\n",
        "Establishes computational environment and verifies data integrity\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE EXPERIMENTS - CELL 1: ENVIRONMENT SETUP\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. GOOGLE DRIVE MOUNTING\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/10] Mounting Google Drive...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"SUCCESS: Google Drive mounted\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Drive mounting failed - {e}\")\n",
        "    raise\n",
        "\n",
        "# ==========================================\n",
        "# 2. PROJECT PATH CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/10] Configuring project paths...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/ASD_GWO_XGBoost_Project'\n",
        "\n",
        "PROJECT_PATHS = {\n",
        "    'root': PROJECT_ROOT,\n",
        "    'dataset': f\"{PROJECT_ROOT}/01_Dataset\",\n",
        "    'preprocessed': f\"{PROJECT_ROOT}/01_Dataset/splits/no_ethnicity/preprocessed\",\n",
        "    'results': f\"{PROJECT_ROOT}/03_Results\",\n",
        "    'baseline_results': f\"{PROJECT_ROOT}/03_Results/output_notebook_02/cell_1_setup\"\n",
        "}\n",
        "\n",
        "for name, path in PROJECT_PATHS.items():\n",
        "    if os.path.exists(path):\n",
        "        print(f\"  FOUND: {name}\")\n",
        "    elif name in ['results', 'baseline_results']:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        print(f\"  CREATED: {name}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"CRITICAL: Missing {name} directory\")\n",
        "\n",
        "PREPROCESSED_FILES = {\n",
        "    'train': f\"{PROJECT_PATHS['preprocessed']}/train_set_preprocessed.csv\",\n",
        "    'val': f\"{PROJECT_PATHS['preprocessed']}/val_set_preprocessed.csv\",\n",
        "    'test': f\"{PROJECT_PATHS['preprocessed']}/test_set_preprocessed.csv\"\n",
        "}\n",
        "\n",
        "print(\"\\nVerifying preprocessed files exist...\")\n",
        "for split_name, file_path in PREPROCESSED_FILES.items():\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"CRITICAL: Missing {split_name}_set_preprocessed.csv\")\n",
        "    file_size = os.path.getsize(file_path) / (1024**2)\n",
        "    print(f\"  {split_name.upper()}: {file_size:.2f} MB\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. LIBRARY IMPORTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/10] Importing libraries...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, RFECV, f_classif\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, log_loss,\n",
        "    confusion_matrix, roc_curve\n",
        ")\n",
        "import xgboost as xgb\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"SUCCESS: All libraries imported\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. GLOBAL CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/10] Setting global configuration...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "CONFIG = {\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'cv_folds': 5,\n",
        "    'scoring_metric': 'roc_auc',\n",
        "    'target_column': 'ASD_traits',\n",
        "    'n_jobs': -1,\n",
        "    'n_runs': 10\n",
        "}\n",
        "\n",
        "print(f\"Random state: {CONFIG['random_state']}\")\n",
        "print(f\"Primary metric: {CONFIG['scoring_metric']}\")\n",
        "print(f\"CV folds: {CONFIG['cv_folds']}\")\n",
        "print(f\"Runs per baseline: {CONFIG['n_runs']}\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. XGBOOST CONFIGURATIONS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/10] Defining XGBoost configurations...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "XGBOOST_UNIFIED_CONFIG = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'n_estimators': 500,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'n_jobs': -1,\n",
        "    'verbosity': 0\n",
        "}\n",
        "\n",
        "XGBOOST_RFECV_CONFIG = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'n_estimators': 150,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.1,\n",
        "    'subsample': 1.0,\n",
        "    'colsample_bytree': 1.0,\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'n_jobs': -1,\n",
        "    'verbosity': 0\n",
        "}\n",
        "\n",
        "SELECTKBEST_CONFIG = {\n",
        "    'selection_method': 'f_classif',\n",
        "    'k_values': [8, 12, 16, 20],\n",
        "    'scoring_function': f_classif,\n",
        "    'selection_strategy': 'statistical_ranking'\n",
        "}\n",
        "\n",
        "RFECV_CONFIG = {\n",
        "    'step': 5,\n",
        "    'cv_folds': 3,\n",
        "    'min_features_to_select': 8,\n",
        "    'scoring': 'roc_auc',\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "print(\"Unified XGBoost config (final model):\")\n",
        "print(f\"  n_estimators={XGBOOST_UNIFIED_CONFIG['n_estimators']}, max_depth={XGBOOST_UNIFIED_CONFIG['max_depth']}, lr={XGBOOST_UNIFIED_CONFIG['learning_rate']}\")\n",
        "print(f\"  subsample={XGBOOST_UNIFIED_CONFIG['subsample']}, colsample={XGBOOST_UNIFIED_CONFIG['colsample_bytree']}\")\n",
        "print(\"\\nRFECV XGBoost config (feature selection):\")\n",
        "print(f\"  n_estimators={XGBOOST_RFECV_CONFIG['n_estimators']}, max_depth={XGBOOST_RFECV_CONFIG['max_depth']}, lr={XGBOOST_RFECV_CONFIG['learning_rate']}\")\n",
        "print(f\"  subsample={XGBOOST_RFECV_CONFIG['subsample']}, colsample={XGBOOST_RFECV_CONFIG['colsample_bytree']}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. UTILITY FUNCTIONS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/10] Defining utility functions...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "def save_results(results, filepath):\n",
        "    \"\"\"Save results dictionary to JSON file\"\"\"\n",
        "    def json_serializer(obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif pd.isna(obj):\n",
        "            return None\n",
        "        return str(obj)\n",
        "\n",
        "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=json_serializer)\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_proba):\n",
        "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
        "    return {\n",
        "        'accuracy': float(accuracy_score(y_true, y_pred)),\n",
        "        'precision_macro': float(precision_score(y_true, y_pred, average='macro', zero_division=0)),\n",
        "        'recall_macro': float(recall_score(y_true, y_pred, average='macro', zero_division=0)),\n",
        "        'f1_macro': float(f1_score(y_true, y_pred, average='macro', zero_division=0)),\n",
        "        'roc_auc': float(roc_auc_score(y_true, y_proba)),\n",
        "        'log_loss': float(log_loss(y_true, y_proba))\n",
        "    }\n",
        "\n",
        "def create_confusion_matrix_plot(y_true, y_pred, title, save_path):\n",
        "    \"\"\"Create and save confusion matrix visualization\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "                xticklabels=['Non-ASD', 'ASD'],\n",
        "                yticklabels=['Non-ASD', 'ASD'])\n",
        "    plt.title(title, fontweight='bold', pad=20)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def create_roc_curve_plot(y_true, y_proba, title, save_path):\n",
        "    \"\"\"Create and save ROC curve visualization\"\"\"\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    auc_score = roc_auc_score(y_true, y_proba)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title, fontweight='bold', pad=20)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "print(\"SUCCESS: Utility functions defined\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. LOAD PREPROCESSED DATA\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/10] Loading preprocessed datasets...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "train_df = pd.read_csv(PREPROCESSED_FILES['train'])\n",
        "val_df = pd.read_csv(PREPROCESSED_FILES['val'])\n",
        "test_df = pd.read_csv(PREPROCESSED_FILES['test'])\n",
        "\n",
        "X_train = train_df.drop(columns=[CONFIG['target_column']])\n",
        "y_train = train_df[CONFIG['target_column']]\n",
        "X_val = val_df.drop(columns=[CONFIG['target_column']])\n",
        "y_val = val_df[CONFIG['target_column']]\n",
        "X_test = test_df.drop(columns=[CONFIG['target_column']])\n",
        "y_test = test_df[CONFIG['target_column']]\n",
        "\n",
        "print(f\"Train: {X_train.shape[0]:,} samples x {X_train.shape[1]} features\")\n",
        "print(f\"Val:   {X_val.shape[0]:,} samples x {X_val.shape[1]} features\")\n",
        "print(f\"Test:  {X_test.shape[0]:,} samples x {X_test.shape[1]} features\")\n",
        "\n",
        "# ==========================================\n",
        "# 8. DATA INTEGRITY VERIFICATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 8/10] Verifying data integrity...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "EXPECTED_SAMPLES = {'train': 1270, 'val': 318, 'test': 397}\n",
        "EXPECTED_FEATURES = 25\n",
        "\n",
        "actual_samples = {\n",
        "    'train': X_train.shape[0],\n",
        "    'val': X_val.shape[0],\n",
        "    'test': X_test.shape[0]\n",
        "}\n",
        "\n",
        "print(\"Sample count verification:\")\n",
        "for split, expected in EXPECTED_SAMPLES.items():\n",
        "    actual = actual_samples[split]\n",
        "    status = \"PASS\" if actual == expected else \"FAIL\"\n",
        "    print(f\"  {split.upper()}: {actual:,} (expected {expected:,}) - {status}\")\n",
        "    if actual != expected:\n",
        "        raise ValueError(f\"Sample count mismatch in {split} set\")\n",
        "\n",
        "print(\"\\nFeature count verification:\")\n",
        "for split, X in [('train', X_train), ('val', X_val), ('test', X_test)]:\n",
        "    n_features = X.shape[1]\n",
        "    status = \"PASS\" if n_features == EXPECTED_FEATURES else \"FAIL\"\n",
        "    print(f\"  {split.upper()}: {n_features} features (expected {EXPECTED_FEATURES}) - {status}\")\n",
        "    if n_features != EXPECTED_FEATURES:\n",
        "        raise ValueError(f\"Feature count mismatch in {split} set\")\n",
        "\n",
        "EXCLUDED_COLUMNS = ['CASE_NO_PATIENTS', 'Ethnicity']\n",
        "print(\"\\nVerifying excluded columns removed:\")\n",
        "for col in EXCLUDED_COLUMNS:\n",
        "    if col in X_train.columns:\n",
        "        raise ValueError(f\"Column '{col}' should have been removed\")\n",
        "print(f\"  CONFIRMED: {EXCLUDED_COLUMNS} not present\")\n",
        "\n",
        "print(\"\\nTarget encoding verification:\")\n",
        "for split, y in [('train', y_train), ('val', y_val), ('test', y_test)]:\n",
        "    unique_values = sorted(y.unique())\n",
        "    if unique_values != [0, 1]:\n",
        "        raise ValueError(f\"Target encoding incorrect in {split} set: {unique_values}\")\n",
        "print(\"  CONFIRMED: Target encoded as 0=Non-ASD, 1=ASD\")\n",
        "\n",
        "print(\"\\nData quality checks:\")\n",
        "for split, X in [('train', X_train), ('val', X_val), ('test', X_test)]:\n",
        "    missing = X.isnull().sum().sum()\n",
        "    infinite = np.isinf(X.select_dtypes(include=[np.number])).sum().sum()\n",
        "    print(f\"  {split.upper()}: missing={missing}, infinite={infinite} - {'PASS' if missing==0 and infinite==0 else 'FAIL'}\")\n",
        "    if missing > 0 or infinite > 0:\n",
        "        raise ValueError(f\"Data quality issues in {split} set\")\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "for split, y in [('train', y_train), ('val', y_val), ('test', y_test)]:\n",
        "    dist = y.value_counts().to_dict()\n",
        "    total = len(y)\n",
        "    print(f\"  {split.upper()}: Non-ASD={dist.get(0,0)} ({dist.get(0,0)/total*100:.1f}%), ASD={dist.get(1,0)} ({dist.get(1,0)/total*100:.1f}%)\")\n",
        "\n",
        "# ==========================================\n",
        "# 9. SYSTEM INFORMATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 9/10] System configuration...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "import sys\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"XGBoost: {xgb.__version__}\")\n",
        "print(f\"Matplotlib backend: {matplotlib.get_backend()}\")\n",
        "\n",
        "try:\n",
        "    import subprocess\n",
        "    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader']).decode('utf-8').strip()\n",
        "    print(f\"GPU: {gpu_info}\")\n",
        "    GPU_AVAILABLE = True\n",
        "except:\n",
        "    print(\"GPU: Not available\")\n",
        "    GPU_AVAILABLE = False\n",
        "\n",
        "# ==========================================\n",
        "# 10. EXPORT SETUP INFORMATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 10/10] Saving setup information...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "setup_info = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'cell': 'Cell 1: Environment Setup & Data Loading',\n",
        "    'project_paths': PROJECT_PATHS,\n",
        "    'configuration': CONFIG,\n",
        "    'xgboost_unified_config': XGBOOST_UNIFIED_CONFIG,\n",
        "    'xgboost_rfecv_config': XGBOOST_RFECV_CONFIG,\n",
        "    'selectkbest_config': {k: v for k, v in SELECTKBEST_CONFIG.items() if k != 'scoring_function'},\n",
        "    'rfecv_config': RFECV_CONFIG,\n",
        "    'data_verification': {\n",
        "        'expected_samples': EXPECTED_SAMPLES,\n",
        "        'actual_samples': actual_samples,\n",
        "        'expected_features': EXPECTED_FEATURES,\n",
        "        'excluded_columns_verified': True,\n",
        "        'target_encoding_verified': True,\n",
        "        'data_quality_passed': True\n",
        "    },\n",
        "    'system_info': {\n",
        "        'python_version': sys.version.split()[0],\n",
        "        'pandas_version': pd.__version__,\n",
        "        'numpy_version': np.__version__,\n",
        "        'xgboost_version': xgb.__version__,\n",
        "        'matplotlib_backend': matplotlib.get_backend(),\n",
        "        'gpu_available': GPU_AVAILABLE\n",
        "    },\n",
        "    'status': 'completed'\n",
        "}\n",
        "\n",
        "setup_path = f\"{PROJECT_PATHS['baseline_results']}/setup_info.json\"\n",
        "save_results(setup_info, setup_path)\n",
        "print(f\"Setup information saved: {setup_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CELL 1 COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nENVIRONMENT STATUS:\")\n",
        "print(f\"  Project root: {PROJECT_ROOT}\")\n",
        "print(f\"  Results directory: {PROJECT_PATHS['baseline_results']}\")\n",
        "print(f\"  GPU available: {GPU_AVAILABLE}\")\n",
        "\n",
        "print(\"\\nDATA STATUS:\")\n",
        "print(f\"  Train: {X_train.shape[0]:,} samples x {X_train.shape[1]} features\")\n",
        "print(f\"  Validation: {X_val.shape[0]:,} samples x {X_val.shape[1]} features\")\n",
        "print(f\"  Test: {X_test.shape[0]:,} samples x {X_test.shape[1]} features\")\n",
        "print(f\"  All integrity checks: PASSED\")\n",
        "\n",
        "print(\"\\nCONFIGURATION:\")\n",
        "print(f\"  Random state: {CONFIG['random_state']}\")\n",
        "print(f\"  Scoring metric: {CONFIG['scoring_metric']}\")\n",
        "print(f\"  Runs per baseline: {CONFIG['n_runs']}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 2: Baseline 1 - XGBoost with All Features\")\n",
        "print(\"  Cell 3: Baseline 2 - XGBoost with SelectKBest\")\n",
        "print(\"  Cell 4: Baseline 3 - XGBoost with RFECV\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR BASELINE EXPERIMENTS\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 2: Baseline 1 Training - XGBoost with All Features\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 2: Baseline 1 - XGBoost trained with all features (no feature selection)\n",
        "10 independent runs with unified XGBoost configuration\n",
        "Control group for feature selection comparison\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 1 TRAINING: XGBOOST WITH ALL FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/7] Verifying Cell 1 completion...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_train' in dir() and X_train.shape[1] == 25\n",
        "    assert 'X_val' in dir() and X_val.shape[0] == 318\n",
        "    assert 'XGBOOST_UNIFIED_CONFIG' in dir()\n",
        "    assert 'CONFIG' in dir() and CONFIG['n_runs'] == 10\n",
        "    print(f\"VERIFIED: Training data ({X_train.shape[0]} samples x {X_train.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Validation data ({X_val.shape[0]} samples)\")\n",
        "    print(f\"VERIFIED: XGBoost unified config loaded\")\n",
        "    print(f\"VERIFIED: Number of runs = {CONFIG['n_runs']}\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. EXPERIMENT SETUP\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/7] Setting up Baseline 1 experiment...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_1_DIR = f\"{PROJECT_PATHS['baseline_results']}/baseline_1_all_features\"\n",
        "MODELS_DIR = f\"{BASELINE_1_DIR}/models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Experiment directory: {BASELINE_1_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n",
        "\n",
        "print(\"\\nExperiment configuration:\")\n",
        "print(f\"  Method: No feature selection (all {X_train.shape[1]} features)\")\n",
        "print(f\"  Number of runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Random seeds: {CONFIG['random_state']} to {CONFIG['random_state'] + CONFIG['n_runs'] - 1}\")\n",
        "print(f\"  XGBoost config: n_estimators={XGBOOST_UNIFIED_CONFIG['n_estimators']}, \"\n",
        "      f\"max_depth={XGBOOST_UNIFIED_CONFIG['max_depth']}, \"\n",
        "      f\"learning_rate={XGBOOST_UNIFIED_CONFIG['learning_rate']}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING LOOP - 10 INDEPENDENT RUNS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/7] Training 10 independent models...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "training_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 1: XGBoost with All Features',\n",
        "        'description': 'Control group - no feature selection applied',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'n_runs': CONFIG['n_runs']\n",
        "    },\n",
        "    'configuration': {\n",
        "        'xgboost_config': XGBOOST_UNIFIED_CONFIG,\n",
        "        'n_features': X_train.shape[1],\n",
        "        'feature_names': X_train.columns.tolist()\n",
        "    },\n",
        "    'training_results': {\n",
        "        'runs': [],\n",
        "        'statistics': {}\n",
        "    },\n",
        "    'best_model': {}\n",
        "}\n",
        "\n",
        "start_time_total = time.time()\n",
        "validation_aucs = []\n",
        "\n",
        "for run_id in range(CONFIG['n_runs']):\n",
        "    print(f\"\\nRun {run_id + 1}/{CONFIG['n_runs']} (seed={CONFIG['random_state'] + run_id})\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    start_time_run = time.time()\n",
        "\n",
        "    # Initialize model with unique random seed\n",
        "    model_config = XGBOOST_UNIFIED_CONFIG.copy()\n",
        "    model_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "    model = xgb.XGBClassifier(**model_config)\n",
        "\n",
        "    # Train on all features\n",
        "    print(f\"  Training on {X_train.shape[1]} features...\")\n",
        "    model.fit(X_train, y_train, verbose=False)\n",
        "\n",
        "    # Predict on validation set\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time_run\n",
        "\n",
        "    # Save model\n",
        "    model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "    model.save_model(model_path)\n",
        "\n",
        "    # Store results\n",
        "    run_result = {\n",
        "        'run_id': run_id,\n",
        "        'random_state': CONFIG['random_state'] + run_id,\n",
        "        'training_time_seconds': round(training_time, 2),\n",
        "        'validation_metrics': val_metrics,\n",
        "        'model_path': model_path\n",
        "    }\n",
        "\n",
        "    training_results['training_results']['runs'].append(run_result)\n",
        "    validation_aucs.append(val_metrics['roc_auc'])\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.2f}s\")\n",
        "    print(f\"  Model saved: {model_path}\")\n",
        "\n",
        "total_training_time = time.time() - start_time_total\n",
        "\n",
        "print(f\"\\nTotal training time: {total_training_time:.2f}s ({total_training_time/60:.2f} min)\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. STATISTICAL SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/7] Computing statistical summary...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "validation_aucs_array = np.array(validation_aucs)\n",
        "\n",
        "statistics = {\n",
        "    'mean_val_auc': float(np.mean(validation_aucs_array)),\n",
        "    'std_val_auc': float(np.std(validation_aucs_array, ddof=1)),\n",
        "    'min_val_auc': float(np.min(validation_aucs_array)),\n",
        "    'max_val_auc': float(np.max(validation_aucs_array)),\n",
        "    'median_val_auc': float(np.median(validation_aucs_array)),\n",
        "    'best_run_id': int(np.argmax(validation_aucs_array)),\n",
        "    'total_training_time_seconds': round(total_training_time, 2)\n",
        "}\n",
        "\n",
        "training_results['training_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Validation AUC statistics across 10 runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_val_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_val_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_val_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_val_auc']:.4f}\")\n",
        "print(f\"\\nBest run: Run {statistics['best_run_id']} \"\n",
        "      f\"(AUC = {statistics['max_val_auc']:.4f})\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. IDENTIFY AND SAVE BEST MODEL\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/7] Saving best model...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_run_id = statistics['best_run_id']\n",
        "best_run_result = training_results['training_results']['runs'][best_run_id]\n",
        "\n",
        "# Load and save best model separately\n",
        "best_model = xgb.XGBClassifier()\n",
        "best_model.load_model(best_run_result['model_path'])\n",
        "\n",
        "best_model_path = f\"{BASELINE_1_DIR}/baseline_1_best_model.json\"\n",
        "best_model.save_model(best_model_path)\n",
        "\n",
        "training_results['best_model'] = {\n",
        "    'run_id': best_run_id,\n",
        "    'random_state': best_run_result['random_state'],\n",
        "    'validation_auc': best_run_result['validation_metrics']['roc_auc'],\n",
        "    'validation_metrics': best_run_result['validation_metrics'],\n",
        "    'model_path': best_model_path\n",
        "}\n",
        "\n",
        "print(f\"Best model: Run {best_run_id}\")\n",
        "print(f\"  Validation AUC: {best_run_result['validation_metrics']['roc_auc']:.4f}\")\n",
        "print(f\"  Validation Accuracy: {best_run_result['validation_metrics']['accuracy']:.4f}\")\n",
        "print(f\"  Saved to: {best_model_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. FEATURE IMPORTANCE ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/7] Analyzing feature importance (best model)...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "feature_importance = best_model.feature_importances_\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 most important features:\")\n",
        "for idx, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
        "    print(f\"  {idx:2d}. {row['feature']:<25s} {row['importance']:.4f}\")\n",
        "\n",
        "importance_csv_path = f\"{BASELINE_1_DIR}/feature_importance.csv\"\n",
        "importance_df.to_csv(importance_csv_path, index=False)\n",
        "print(f\"\\nFeature importance saved: {importance_csv_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. SAVE TRAINING RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/7] Saving training results...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "results_path = f\"{BASELINE_1_DIR}/baseline_1_training_results.json\"\n",
        "save_results(training_results, results_path)\n",
        "\n",
        "print(f\"Training results saved: {results_path}\")\n",
        "\n",
        "# Generate summary statistics file\n",
        "summary = {\n",
        "    'experiment': 'Baseline 1: XGBoost with All Features',\n",
        "    'n_features': X_train.shape[1],\n",
        "    'n_runs': CONFIG['n_runs'],\n",
        "    'validation_auc': {\n",
        "        'mean': statistics['mean_val_auc'],\n",
        "        'std': statistics['std_val_auc'],\n",
        "        'range': [statistics['min_val_auc'], statistics['max_val_auc']]\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_id,\n",
        "        'validation_auc': statistics['max_val_auc']\n",
        "    },\n",
        "    'training_time_total_minutes': round(total_training_time / 60, 2)\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_1_DIR}/training_summary.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Training summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 1 TRAINING COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nEXPERIMENT SUMMARY:\")\n",
        "print(f\"  Method: XGBoost with all features (no selection)\")\n",
        "print(f\"  Features used: {X_train.shape[1]} features\")\n",
        "print(f\"  Training runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Total training time: {total_training_time/60:.2f} minutes\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_val_auc']:.4f} Â± {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Best AUC: {statistics['max_val_auc']:.4f} (Run {best_run_id})\")\n",
        "print(f\"  AUC range: [{statistics['min_val_auc']:.4f}, {statistics['max_val_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Training results: {results_path}\")\n",
        "print(f\"  Best model: {best_model_path}\")\n",
        "print(f\"  All models: {MODELS_DIR}/ (10 models)\")\n",
        "print(f\"  Feature importance: {importance_csv_path}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 3: Baseline 2 - XGBoost with SelectKBest\")\n",
        "print(\"  Cell 5: Baseline 1 Testing - Test set evaluation\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR NEXT BASELINE EXPERIMENT\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "cellView": "form",
        "collapsed": true,
        "id": "nhZuuvO9_cQF",
        "outputId": "c854cf4c-bf52-4b32-c959-c914bc99302e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 1 TRAINING: XGBOOST WITH ALL FEATURES\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/7] Verifying Cell 1 completion...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Training data (1270 samples x 25 features)\n",
            "VERIFIED: Validation data (318 samples)\n",
            "VERIFIED: XGBoost unified config loaded\n",
            "VERIFIED: Number of runs = 10\n",
            "\n",
            "[STEP 2/7] Setting up Baseline 1 experiment...\n",
            "--------------------------------------------------\n",
            "Experiment directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features\n",
            "Models directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models\n",
            "\n",
            "Experiment configuration:\n",
            "  Method: No feature selection (all 25 features)\n",
            "  Number of runs: 10\n",
            "  Random seeds: 42 to 51\n",
            "  XGBoost config: n_estimators=500, max_depth=8, learning_rate=0.05\n",
            "\n",
            "[STEP 3/7] Training 10 independent models...\n",
            "--------------------------------------------------\n",
            "\n",
            "Run 1/10 (seed=42)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "Invalid Input: 'gpu_hist', valid values are: {'approx', 'auto', 'exact', 'hist'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1858265116.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Train on all features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Training on {X_train.shape[1]} features...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Predict on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1801\u001b[0m             )\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1803\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1804\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2433\u001b[0;31m             _check_call(\n\u001b[0m\u001b[1;32m   2434\u001b[0m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[1;32m   2435\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: Invalid Input: 'gpu_hist', valid values are: {'approx', 'auto', 'exact', 'hist'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 3: Baseline 2 Training - XGBoost with SelectKBest\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 3: Baseline 2 - XGBoost with SelectKBest (Filter Method)\n",
        "Phase 1: K-value optimization (k=[8,12,16,20])\n",
        "Phase 2: 10 independent runs with optimal k\n",
        "Statistical feature selection using ANOVA F-test\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 2 TRAINING: XGBOOST WITH SELECTKBEST\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/8] Verifying Cell 1 completion...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_train' in dir() and X_train.shape[1] == 25\n",
        "    assert 'X_val' in dir() and X_val.shape[0] == 318\n",
        "    assert 'XGBOOST_UNIFIED_CONFIG' in dir()\n",
        "    assert 'SELECTKBEST_CONFIG' in dir()\n",
        "    assert 'CONFIG' in dir() and CONFIG['n_runs'] == 10\n",
        "    print(f\"VERIFIED: Training data ({X_train.shape[0]} samples x {X_train.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Validation data ({X_val.shape[0]} samples)\")\n",
        "    print(f\"VERIFIED: SelectKBest config (k_values={SELECTKBEST_CONFIG['k_values']})\")\n",
        "    print(f\"VERIFIED: Number of runs = {CONFIG['n_runs']}\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. EXPERIMENT SETUP\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/8] Setting up Baseline 2 experiment...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_2_DIR = f\"{PROJECT_PATHS['root']}/03_Results/output_notebook_02/cell_3_baseline2\"\n",
        "MODELS_DIR = f\"{BASELINE_2_DIR}/models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Experiment directory: {BASELINE_2_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n",
        "\n",
        "print(\"\\nExperiment configuration:\")\n",
        "print(f\"  Method: SelectKBest (Filter - ANOVA F-test)\")\n",
        "print(f\"  K-values to test: {SELECTKBEST_CONFIG['k_values']}\")\n",
        "print(f\"  Number of runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Selection: Deterministic (same features per k)\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. PHASE 1: K-VALUE OPTIMIZATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/8] Phase 1: K-value optimization...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "k_value_results = {}\n",
        "\n",
        "for k in SELECTKBEST_CONFIG['k_values']:\n",
        "    print(f\"\\nTesting k={k} features...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Initialize SelectKBest\n",
        "    selector = SelectKBest(score_func=SELECTKBEST_CONFIG['scoring_function'], k=k)\n",
        "\n",
        "    # Fit on training data and transform\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_val_selected = selector.transform(X_val)\n",
        "\n",
        "    # Get selected features\n",
        "    selected_mask = selector.get_support()\n",
        "    selected_features = X_train.columns[selected_mask].tolist()\n",
        "    f_scores = selector.scores_[selected_mask]\n",
        "\n",
        "    print(f\"  Selected {len(selected_features)} features\")\n",
        "    print(f\"  Top 3: {selected_features[:3]}\")\n",
        "\n",
        "    # Train single XGBoost model with unified config\n",
        "    model = xgb.XGBClassifier(**XGBOOST_UNIFIED_CONFIG)\n",
        "    model.fit(X_train_selected, y_train, verbose=False)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    y_val_pred = model.predict(X_val_selected)\n",
        "    y_val_proba = model.predict_proba(X_val_selected)[:, 1]\n",
        "    val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Store results\n",
        "    k_value_results[k] = {\n",
        "        'val_auc': val_metrics['roc_auc'],\n",
        "        'val_metrics': val_metrics,\n",
        "        'selected_features': selected_features,\n",
        "        'f_scores': f_scores.tolist(),\n",
        "        'selector': selector\n",
        "    }\n",
        "\n",
        "# Determine optimal k\n",
        "optimal_k = max(k_value_results.keys(), key=lambda k: k_value_results[k]['val_auc'])\n",
        "\n",
        "print(f\"\\n[OPTIMAL K DETERMINED]\")\n",
        "print(f\"  Best k-value: {optimal_k}\")\n",
        "print(f\"  Validation AUC: {k_value_results[optimal_k]['val_auc']:.4f}\")\n",
        "\n",
        "print(\"\\nK-value optimization results:\")\n",
        "for k in SELECTKBEST_CONFIG['k_values']:\n",
        "    marker = \" <- OPTIMAL\" if k == optimal_k else \"\"\n",
        "    print(f\"  k={k:2d}: AUC = {k_value_results[k]['val_auc']:.4f}{marker}\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. PREPARE OPTIMAL FEATURE SELECTION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/8] Preparing feature selection with optimal k...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Use selector from optimal k (already fitted in Phase 1)\n",
        "optimal_selector = k_value_results[optimal_k]['selector']\n",
        "selected_features = k_value_results[optimal_k]['selected_features']\n",
        "\n",
        "print(f\"Selected features (k={optimal_k}):\")\n",
        "for i, feature in enumerate(selected_features[:10], 1):\n",
        "    print(f\"  {i:2d}. {feature}\")\n",
        "if len(selected_features) > 10:\n",
        "    print(f\"  ... and {len(selected_features) - 10} more\")\n",
        "\n",
        "# Save feature selection details\n",
        "feature_selection_details = pd.DataFrame({\n",
        "    'feature': selected_features,\n",
        "    'f_score': k_value_results[optimal_k]['f_scores']\n",
        "}).sort_values('f_score', ascending=False)\n",
        "\n",
        "feature_details_path = f\"{BASELINE_2_DIR}/feature_selection_details.csv\"\n",
        "feature_selection_details.to_csv(feature_details_path, index=False)\n",
        "print(f\"\\nFeature selection details saved: {feature_details_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. PHASE 2: MULTIPLE RUNS WITH OPTIMAL K\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/8] Phase 2: Training 10 models with optimal k...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "training_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 2: XGBoost with SelectKBest',\n",
        "        'description': 'Filter method - ANOVA F-test statistical ranking',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'n_runs': CONFIG['n_runs']\n",
        "    },\n",
        "    'k_value_optimization': {\n",
        "        'k_values_tested': SELECTKBEST_CONFIG['k_values'],\n",
        "        'results': {\n",
        "            str(k): {\n",
        "                'val_auc': float(results['val_auc']),\n",
        "                'selected_features': results['selected_features']\n",
        "            } for k, results in k_value_results.items()\n",
        "        },\n",
        "        'optimal_k': optimal_k,\n",
        "        'optimal_val_auc': float(k_value_results[optimal_k]['val_auc'])\n",
        "    },\n",
        "    'feature_selection': {\n",
        "        'method': 'SelectKBest - f_classif',\n",
        "        'n_features_selected': optimal_k,\n",
        "        'selected_features': selected_features,\n",
        "        'f_scores': {feature: float(score) for feature, score in\n",
        "                     zip(selected_features, k_value_results[optimal_k]['f_scores'])}\n",
        "    },\n",
        "    'configuration': {\n",
        "        'xgboost_config': XGBOOST_UNIFIED_CONFIG,\n",
        "        'selectkbest_config': {k: v for k, v in SELECTKBEST_CONFIG.items() if k != 'scoring_function'}\n",
        "    },\n",
        "    'training_results': {\n",
        "        'runs': [],\n",
        "        'statistics': {}\n",
        "    },\n",
        "    'best_model': {}\n",
        "}\n",
        "\n",
        "# Transform data using optimal selector (same for all runs)\n",
        "X_train_selected = optimal_selector.transform(X_train)\n",
        "X_val_selected = optimal_selector.transform(X_val)\n",
        "\n",
        "print(f\"Feature selection applied: {X_train.shape[1]} -> {optimal_k} features\")\n",
        "print(f\"Same features used across all {CONFIG['n_runs']} runs\")\n",
        "\n",
        "start_time_total = time.time()\n",
        "validation_aucs = []\n",
        "\n",
        "for run_id in range(CONFIG['n_runs']):\n",
        "    print(f\"\\nRun {run_id + 1}/{CONFIG['n_runs']} (seed={CONFIG['random_state'] + run_id})\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    start_time_run = time.time()\n",
        "\n",
        "    # Initialize model with unique random seed\n",
        "    model_config = XGBOOST_UNIFIED_CONFIG.copy()\n",
        "    model_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "    model = xgb.XGBClassifier(**model_config)\n",
        "\n",
        "    # Train on selected features\n",
        "    print(f\"  Training on {optimal_k} selected features...\")\n",
        "    model.fit(X_train_selected, y_train, verbose=False)\n",
        "\n",
        "    # Predict on validation set\n",
        "    y_val_pred = model.predict(X_val_selected)\n",
        "    y_val_proba = model.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time_run\n",
        "\n",
        "    # Save model\n",
        "    model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "    model.save_model(model_path)\n",
        "\n",
        "    # Store results\n",
        "    run_result = {\n",
        "        'run_id': run_id,\n",
        "        'random_state': CONFIG['random_state'] + run_id,\n",
        "        'n_features_selected': optimal_k,\n",
        "        'training_time_seconds': round(training_time, 2),\n",
        "        'validation_metrics': val_metrics,\n",
        "        'model_path': model_path\n",
        "    }\n",
        "\n",
        "    training_results['training_results']['runs'].append(run_result)\n",
        "    validation_aucs.append(val_metrics['roc_auc'])\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.2f}s\")\n",
        "    print(f\"  Model saved: {model_path}\")\n",
        "\n",
        "total_training_time = time.time() - start_time_total\n",
        "\n",
        "print(f\"\\nTotal training time: {total_training_time:.2f}s ({total_training_time/60:.2f} min)\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. STATISTICAL SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/8] Computing statistical summary...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "validation_aucs_array = np.array(validation_aucs)\n",
        "\n",
        "statistics = {\n",
        "    'mean_val_auc': float(np.mean(validation_aucs_array)),\n",
        "    'std_val_auc': float(np.std(validation_aucs_array, ddof=1)),\n",
        "    'min_val_auc': float(np.min(validation_aucs_array)),\n",
        "    'max_val_auc': float(np.max(validation_aucs_array)),\n",
        "    'median_val_auc': float(np.median(validation_aucs_array)),\n",
        "    'best_run_id': int(np.argmax(validation_aucs_array)),\n",
        "    'total_training_time_seconds': round(total_training_time, 2)\n",
        "}\n",
        "\n",
        "training_results['training_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Validation AUC statistics across 10 runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_val_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_val_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_val_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_val_auc']:.4f}\")\n",
        "print(f\"\\nBest run: Run {statistics['best_run_id']} \"\n",
        "      f\"(AUC = {statistics['max_val_auc']:.4f})\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. IDENTIFY AND SAVE BEST MODEL\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/8] Saving best model...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_run_id = statistics['best_run_id']\n",
        "best_run_result = training_results['training_results']['runs'][best_run_id]\n",
        "\n",
        "# Load and save best model separately\n",
        "best_model = xgb.XGBClassifier()\n",
        "best_model.load_model(best_run_result['model_path'])\n",
        "\n",
        "best_model_path = f\"{BASELINE_2_DIR}/baseline_2_best_model.json\"\n",
        "best_model.save_model(best_model_path)\n",
        "\n",
        "training_results['best_model'] = {\n",
        "    'run_id': best_run_id,\n",
        "    'random_state': best_run_result['random_state'],\n",
        "    'validation_auc': best_run_result['validation_metrics']['roc_auc'],\n",
        "    'validation_metrics': best_run_result['validation_metrics'],\n",
        "    'model_path': best_model_path\n",
        "}\n",
        "\n",
        "print(f\"Best model: Run {best_run_id}\")\n",
        "print(f\"  Validation AUC: {best_run_result['validation_metrics']['roc_auc']:.4f}\")\n",
        "print(f\"  Validation Accuracy: {best_run_result['validation_metrics']['accuracy']:.4f}\")\n",
        "print(f\"  Features used: {optimal_k}\")\n",
        "print(f\"  Saved to: {best_model_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 8. SAVE TRAINING RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 8/8] Saving training results...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "results_path = f\"{BASELINE_2_DIR}/baseline_2_training_results_CPU.json\"\n",
        "save_results(training_results, results_path)\n",
        "\n",
        "print(f\"Training results saved: {results_path}\")\n",
        "\n",
        "# Generate summary statistics file\n",
        "summary = {\n",
        "    'experiment': 'Baseline 2: XGBoost with SelectKBest',\n",
        "    'feature_selection': {\n",
        "        'method': 'Filter (ANOVA F-test)',\n",
        "        'k_values_tested': SELECTKBEST_CONFIG['k_values'],\n",
        "        'optimal_k': optimal_k,\n",
        "        'original_features': X_train.shape[1],\n",
        "        'reduction_percent': round((1 - optimal_k/X_train.shape[1]) * 100, 1)\n",
        "    },\n",
        "    'n_runs': CONFIG['n_runs'],\n",
        "    'validation_auc': {\n",
        "        'mean': statistics['mean_val_auc'],\n",
        "        'std': statistics['std_val_auc'],\n",
        "        'range': [statistics['min_val_auc'], statistics['max_val_auc']]\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_id,\n",
        "        'validation_auc': statistics['max_val_auc']\n",
        "    },\n",
        "    'training_time_total_minutes': round(total_training_time / 60, 2)\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_2_DIR}/training_summary.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Training summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 2 TRAINING COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nEXPERIMENT SUMMARY:\")\n",
        "print(f\"  Method: SelectKBest (Filter - ANOVA F-test)\")\n",
        "print(f\"  Feature selection: {X_train.shape[1]} -> {optimal_k} features\")\n",
        "print(f\"  Reduction: {(1 - optimal_k/X_train.shape[1]) * 100:.1f}%\")\n",
        "print(f\"  Training runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Total training time: {total_training_time/60:.2f} minutes\")\n",
        "\n",
        "print(\"\\nK-VALUE OPTIMIZATION:\")\n",
        "for k in SELECTKBEST_CONFIG['k_values']:\n",
        "    marker = \" <- OPTIMAL\" if k == optimal_k else \"\"\n",
        "    print(f\"  k={k:2d}: AUC = {k_value_results[k]['val_auc']:.4f}{marker}\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_val_auc']:.4f} Â± {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Best AUC: {statistics['max_val_auc']:.4f} (Run {best_run_id})\")\n",
        "print(f\"  AUC range: [{statistics['min_val_auc']:.4f}, {statistics['max_val_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nSELECTED FEATURES (Top 10):\")\n",
        "for i, feature in enumerate(selected_features[:10], 1):\n",
        "    print(f\"  {i:2d}. {feature}\")\n",
        "if len(selected_features) > 10:\n",
        "    print(f\"  ... and {len(selected_features) - 10} more\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Training results: {results_path}\")\n",
        "print(f\"  Best model: {best_model_path}\")\n",
        "print(f\"  All models: {MODELS_DIR}/ (10 models)\")\n",
        "print(f\"  Feature selection: {feature_details_path}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 4: Baseline 3 - XGBoost with RFECV\")\n",
        "print(\"  Cell 6: Baseline 2 Testing - Test set evaluation\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR NEXT BASELINE EXPERIMENT\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "Axaw7TUQYazI",
        "outputId": "c849b704-b0e0-40df-8cea-449110c2af40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 2 TRAINING: XGBOOST WITH SELECTKBEST\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/8] Verifying Cell 1 completion...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Training data (1270 samples x 25 features)\n",
            "VERIFIED: Validation data (318 samples)\n",
            "VERIFIED: SelectKBest config (k_values=[8, 12, 16, 20])\n",
            "VERIFIED: Number of runs = 10\n",
            "\n",
            "[STEP 2/8] Setting up Baseline 2 experiment...\n",
            "--------------------------------------------------\n",
            "Experiment directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2\n",
            "Models directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models\n",
            "\n",
            "Experiment configuration:\n",
            "  Method: SelectKBest (Filter - ANOVA F-test)\n",
            "  K-values to test: [8, 12, 16, 20]\n",
            "  Number of runs: 10\n",
            "  Selection: Deterministic (same features per k)\n",
            "\n",
            "[STEP 3/8] Phase 1: K-value optimization...\n",
            "--------------------------------------------------\n",
            "\n",
            "Testing k=8 features...\n",
            "----------------------------------------\n",
            "  Selected 8 features\n",
            "  Top 3: ['A1', 'A2', 'A4']\n",
            "  Validation AUC: 0.9671\n",
            "  Validation Accuracy: 0.8836\n",
            "\n",
            "Testing k=12 features...\n",
            "----------------------------------------\n",
            "  Selected 12 features\n",
            "  Top 3: ['A1', 'A2', 'A3']\n",
            "  Validation AUC: 0.9950\n",
            "  Validation Accuracy: 0.9591\n",
            "\n",
            "Testing k=16 features...\n",
            "----------------------------------------\n",
            "  Selected 16 features\n",
            "  Top 3: ['A1', 'A2', 'A3']\n",
            "  Validation AUC: 0.9950\n",
            "  Validation Accuracy: 0.9591\n",
            "\n",
            "Testing k=20 features...\n",
            "----------------------------------------\n",
            "  Selected 20 features\n",
            "  Top 3: ['A1', 'A2', 'A3']\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "\n",
            "[OPTIMAL K DETERMINED]\n",
            "  Best k-value: 20\n",
            "  Validation AUC: 0.9964\n",
            "\n",
            "K-value optimization results:\n",
            "  k= 8: AUC = 0.9671\n",
            "  k=12: AUC = 0.9950\n",
            "  k=16: AUC = 0.9950\n",
            "  k=20: AUC = 0.9964 <- OPTIMAL\n",
            "\n",
            "[STEP 4/8] Preparing feature selection with optimal k...\n",
            "--------------------------------------------------\n",
            "Selected features (k=20):\n",
            "   1. A1\n",
            "   2. A2\n",
            "   3. A3\n",
            "   4. A4\n",
            "   5. A5\n",
            "   6. A6\n",
            "   7. A7\n",
            "   8. A8\n",
            "   9. A9\n",
            "  10. Social_Responsiveness_Scale\n",
            "  ... and 10 more\n",
            "\n",
            "Feature selection details saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/feature_selection_details.csv\n",
            "\n",
            "[STEP 5/8] Phase 2: Training 10 models with optimal k...\n",
            "--------------------------------------------------\n",
            "Feature selection applied: 25 -> 20 features\n",
            "Same features used across all 10 runs\n",
            "\n",
            "Run 1/10 (seed=42)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.43s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_0_model.json\n",
            "\n",
            "Run 2/10 (seed=43)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.45s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_1_model.json\n",
            "\n",
            "Run 3/10 (seed=44)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.54s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_2_model.json\n",
            "\n",
            "Run 4/10 (seed=45)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.58s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_3_model.json\n",
            "\n",
            "Run 5/10 (seed=46)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.60s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_4_model.json\n",
            "\n",
            "Run 6/10 (seed=47)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.61s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_5_model.json\n",
            "\n",
            "Run 7/10 (seed=48)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.57s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_6_model.json\n",
            "\n",
            "Run 8/10 (seed=49)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.43s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_7_model.json\n",
            "\n",
            "Run 9/10 (seed=50)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.46s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_8_model.json\n",
            "\n",
            "Run 10/10 (seed=51)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.43s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/run_9_model.json\n",
            "\n",
            "Total training time: 5.39s (0.09 min)\n",
            "\n",
            "[STEP 6/8] Computing statistical summary...\n",
            "--------------------------------------------------\n",
            "Validation AUC statistics across 10 runs:\n",
            "  Mean:   0.9964\n",
            "  Std:    0.0000\n",
            "  Min:    0.9964\n",
            "  Max:    0.9964\n",
            "  Median: 0.9964\n",
            "\n",
            "Best run: Run 0 (AUC = 0.9964)\n",
            "\n",
            "[STEP 7/8] Saving best model...\n",
            "--------------------------------------------------\n",
            "Best model: Run 0\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Features used: 20\n",
            "  Saved to: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/baseline_2_best_model.json\n",
            "\n",
            "[STEP 8/8] Saving training results...\n",
            "--------------------------------------------------\n",
            "Training results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/baseline_2_training_results.json\n",
            "Training summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/training_summary.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 2 TRAINING COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "EXPERIMENT SUMMARY:\n",
            "  Method: SelectKBest (Filter - ANOVA F-test)\n",
            "  Feature selection: 25 -> 20 features\n",
            "  Reduction: 20.0%\n",
            "  Training runs: 10\n",
            "  Total training time: 0.09 minutes\n",
            "\n",
            "K-VALUE OPTIMIZATION:\n",
            "  k= 8: AUC = 0.9671\n",
            "  k=12: AUC = 0.9950\n",
            "  k=16: AUC = 0.9950\n",
            "  k=20: AUC = 0.9964 <- OPTIMAL\n",
            "\n",
            "VALIDATION PERFORMANCE:\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "  Best AUC: 0.9964 (Run 0)\n",
            "  AUC range: [0.9964, 0.9964]\n",
            "\n",
            "SELECTED FEATURES (Top 10):\n",
            "   1. A1\n",
            "   2. A2\n",
            "   3. A3\n",
            "   4. A4\n",
            "   5. A5\n",
            "   6. A6\n",
            "   7. A7\n",
            "   8. A8\n",
            "   9. A9\n",
            "  10. Social_Responsiveness_Scale\n",
            "  ... and 10 more\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Training results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/baseline_2_training_results.json\n",
            "  Best model: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/baseline_2_best_model.json\n",
            "  All models: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/models/ (10 models)\n",
            "  Feature selection: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/feature_selection_details.csv\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 4: Baseline 3 - XGBoost with RFECV\n",
            "  Cell 6: Baseline 2 Testing - Test set evaluation\n",
            "\n",
            "================================================================================\n",
            "READY FOR NEXT BASELINE EXPERIMENT\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4: Baseline 3 Training - XGBoost with RFECV (FIXED VERSION)\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 4: Baseline 3 - XGBoost with RFECV (Wrapper Method) - FIXED\n",
        "10 independent RFECV runs (each performs feature selection separately)\n",
        "Model-guided iterative feature elimination with cross-validation\n",
        "\n",
        "FIXES APPLIED:\n",
        "- Disabled parallel processing in RFECV to avoid joblib conflicts\n",
        "- Adjusted XGBoost threading parameters\n",
        "- Added better error handling\n",
        "- Improved stability for long-running processes\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 3 TRAINING: XGBOOST WITH RFECV (FIXED VERSION)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/7] Verifying Cell 1 completion...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_train' in dir() and X_train.shape[1] == 25\n",
        "    assert 'X_val' in dir() and X_val.shape[0] == 318\n",
        "    assert 'XGBOOST_UNIFIED_CONFIG' in dir()\n",
        "    assert 'XGBOOST_RFECV_CONFIG' in dir()\n",
        "    assert 'RFECV_CONFIG' in dir()\n",
        "    assert 'CONFIG' in dir() and CONFIG['n_runs'] == 10\n",
        "    print(f\"VERIFIED: Training data ({X_train.shape[0]} samples x {X_train.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Validation data ({X_val.shape[0]} samples)\")\n",
        "    print(f\"VERIFIED: RFECV config loaded\")\n",
        "    print(f\"VERIFIED: Number of runs = {CONFIG['n_runs']}\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. EXPERIMENT SETUP\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/7] Setting up Baseline 3 experiment...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_3_DIR = f\"{PROJECT_PATHS['root']}/03_Results/output_notebook_02/cell_4_baseline3\"\n",
        "MODELS_DIR = f\"{BASELINE_3_DIR}/models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Experiment directory: {BASELINE_3_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n",
        "\n",
        "print(\"\\nExperiment configuration:\")\n",
        "print(f\"  Method: RFECV (Wrapper - model-guided)\")\n",
        "print(f\"  RFECV estimator: n_estimators={XGBOOST_RFECV_CONFIG['n_estimators']}, \"\n",
        "      f\"max_depth={XGBOOST_RFECV_CONFIG['max_depth']}, \"\n",
        "      f\"lr={XGBOOST_RFECV_CONFIG['learning_rate']}\")\n",
        "print(f\"  Final model: n_estimators={XGBOOST_UNIFIED_CONFIG['n_estimators']}, \"\n",
        "      f\"max_depth={XGBOOST_UNIFIED_CONFIG['max_depth']}, \"\n",
        "      f\"lr={XGBOOST_UNIFIED_CONFIG['learning_rate']}\")\n",
        "print(f\"  Tree method: hist (CPU-optimized, GPU params removed)\")\n",
        "print(f\"  RFECV step: {RFECV_CONFIG['step']} features\")\n",
        "print(f\"  RFECV CV: {RFECV_CONFIG['cv_folds']} folds\")\n",
        "print(f\"  Min features: {RFECV_CONFIG['min_features_to_select']}\")\n",
        "print(f\"  Number of runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Parallel processing: DISABLED (n_jobs=1, nthread=1 for stability)\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING LOOP - 10 INDEPENDENT RFECV RUNS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/7] Running 10 independent RFECV experiments...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "training_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 3: XGBoost with RFECV',\n",
        "        'description': 'Wrapper method - recursive feature elimination with CV (CPU-only, Fixed version)',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'n_runs': CONFIG['n_runs'],\n",
        "        'notes': 'n_jobs=1, nthread=1, tree_method=hist (CPU-only for stability)'\n",
        "    },\n",
        "    'rfecv_configuration': {\n",
        "        'step': RFECV_CONFIG['step'],\n",
        "        'cv_folds': RFECV_CONFIG['cv_folds'],\n",
        "        'min_features_to_select': RFECV_CONFIG['min_features_to_select'],\n",
        "        'scoring': RFECV_CONFIG['scoring'],\n",
        "        'n_jobs': 1  # FIXED: Sequential processing\n",
        "    },\n",
        "    'configuration': {\n",
        "        'xgboost_rfecv_config': XGBOOST_RFECV_CONFIG,\n",
        "        'xgboost_unified_config': XGBOOST_UNIFIED_CONFIG\n",
        "    },\n",
        "    'training_results': {\n",
        "        'runs': [],\n",
        "        'statistics': {}\n",
        "    },\n",
        "    'feature_stability': {},\n",
        "    'best_model': {}\n",
        "}\n",
        "\n",
        "start_time_total = time.time()\n",
        "validation_aucs = []\n",
        "all_selected_features = []\n",
        "all_optimal_n = []\n",
        "\n",
        "for run_id in range(CONFIG['n_runs']):\n",
        "    print(f\"\\nRun {run_id + 1}/{CONFIG['n_runs']} (seed={CONFIG['random_state'] + run_id})\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    start_time_run = time.time()\n",
        "\n",
        "    try:\n",
        "        # Phase 1: RFECV Feature Selection\n",
        "        print(f\"  Phase 1: RFECV feature selection...\")\n",
        "\n",
        "        # Configure RFECV estimator - FIXED: Remove n_jobs and GPU params\n",
        "        rfecv_estimator_config = XGBOOST_RFECV_CONFIG.copy()\n",
        "        rfecv_estimator_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "        # FIXED: Remove GPU and parallel parameters\n",
        "        params_to_remove = ['n_jobs', 'nthread', 'tree_method', 'gpu_id',\n",
        "                           'predictor', 'enable_categorical']\n",
        "        for param in params_to_remove:\n",
        "            if param in rfecv_estimator_config:\n",
        "                del rfecv_estimator_config[param]\n",
        "\n",
        "        # FIXED: Set safe CPU-only parameters\n",
        "        rfecv_estimator_config['tree_method'] = 'hist'  # Fast CPU method\n",
        "        rfecv_estimator_config['nthread'] = 1  # Single thread for stability\n",
        "\n",
        "        rfecv_estimator = xgb.XGBClassifier(**rfecv_estimator_config)\n",
        "\n",
        "        # Initialize RFECV - FIXED: n_jobs=1 to avoid parallel processing conflicts\n",
        "        rfecv = RFECV(\n",
        "            estimator=rfecv_estimator,\n",
        "            step=RFECV_CONFIG['step'],\n",
        "            cv=RFECV_CONFIG['cv_folds'],\n",
        "            scoring=RFECV_CONFIG['scoring'],\n",
        "            min_features_to_select=RFECV_CONFIG['min_features_to_select'],\n",
        "            n_jobs=1,  # FIXED: Sequential processing\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Fit RFECV on training data\n",
        "        rfecv_start = time.time()\n",
        "        print(f\"    Starting RFECV (this may take several minutes)...\")\n",
        "        rfecv.fit(X_train, y_train)\n",
        "        rfecv_time = time.time() - rfecv_start\n",
        "\n",
        "        # Extract RFECV results\n",
        "        optimal_n_features = rfecv.n_features_\n",
        "        selected_mask = rfecv.support_\n",
        "        feature_ranking = rfecv.ranking_\n",
        "        cv_scores = rfecv.cv_results_['mean_test_score']\n",
        "        convergence_iteration = len(cv_scores)\n",
        "\n",
        "        # Get selected features\n",
        "        selected_features = X_train.columns[selected_mask].tolist()\n",
        "\n",
        "        print(f\"    RFECV completed in {rfecv_time:.1f}s ({rfecv_time/60:.1f} min)\")\n",
        "        print(f\"    Optimal features: {optimal_n_features}/{X_train.shape[1]}\")\n",
        "        print(f\"    Best CV AUC: {np.max(cv_scores):.4f}\")\n",
        "        print(f\"    Convergence iterations: {convergence_iteration}\")\n",
        "\n",
        "        # Phase 2: Train Final Model with Selected Features\n",
        "        print(f\"  Phase 2: Training final model...\")\n",
        "\n",
        "        # Transform data using selected features\n",
        "        X_train_selected = rfecv.transform(X_train)\n",
        "        X_val_selected = rfecv.transform(X_val)\n",
        "\n",
        "        # Configure final model - FIXED: Clean CPU-only config\n",
        "        final_model_config = XGBOOST_UNIFIED_CONFIG.copy()\n",
        "        final_model_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "        # FIXED: Remove GPU and parallel parameters\n",
        "        params_to_remove = ['n_jobs', 'nthread', 'tree_method', 'gpu_id',\n",
        "                           'predictor', 'enable_categorical']\n",
        "        for param in params_to_remove:\n",
        "            if param in final_model_config:\n",
        "                del final_model_config[param]\n",
        "\n",
        "        # FIXED: Set safe CPU-only parameters\n",
        "        final_model_config['tree_method'] = 'hist'  # Fast CPU method\n",
        "        final_model_config['nthread'] = 1  # Single thread for stability\n",
        "\n",
        "        final_model = xgb.XGBClassifier(**final_model_config)\n",
        "\n",
        "        # Train final model\n",
        "        final_model.fit(X_train_selected, y_train, verbose=False)\n",
        "\n",
        "        # Predict on validation set\n",
        "        y_val_pred = final_model.predict(X_val_selected)\n",
        "        y_val_proba = final_model.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "        # Calculate total training time\n",
        "        training_time = time.time() - start_time_run\n",
        "\n",
        "        # Save RFECV details\n",
        "        rfecv_details_path = f\"{MODELS_DIR}/run_{run_id}_rfecv_details.json\"\n",
        "        rfecv_details = {\n",
        "            'run_id': run_id,\n",
        "            'optimal_n_features': int(optimal_n_features),\n",
        "            'selected_features': selected_features,\n",
        "            'feature_ranking': {feat: int(rank) for feat, rank in zip(X_train.columns, feature_ranking)},\n",
        "            'cv_scores_trajectory': [float(score) for score in cv_scores],\n",
        "            'convergence_iterations': convergence_iteration,\n",
        "            'rfecv_time_seconds': round(rfecv_time, 2)\n",
        "        }\n",
        "        save_results(rfecv_details, rfecv_details_path)\n",
        "\n",
        "        # Save final model\n",
        "        model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "        final_model.save_model(model_path)\n",
        "\n",
        "        # Store results\n",
        "        run_result = {\n",
        "            'run_id': run_id,\n",
        "            'random_state': CONFIG['random_state'] + run_id,\n",
        "            'rfecv_results': {\n",
        "                'optimal_n_features': int(optimal_n_features),\n",
        "                'selected_features': selected_features,\n",
        "                'convergence_iterations': convergence_iteration,\n",
        "                'best_cv_score': float(np.max(cv_scores)),\n",
        "                'cv_scores_trajectory': [float(score) for score in cv_scores],\n",
        "                'rfecv_time_seconds': round(rfecv_time, 2)\n",
        "            },\n",
        "            'training_time_seconds': round(training_time, 2),\n",
        "            'validation_metrics': val_metrics,\n",
        "            'model_path': model_path,\n",
        "            'rfecv_details_path': rfecv_details_path\n",
        "        }\n",
        "\n",
        "        training_results['training_results']['runs'].append(run_result)\n",
        "        validation_aucs.append(val_metrics['roc_auc'])\n",
        "        all_selected_features.append(set(selected_features))\n",
        "        all_optimal_n.append(optimal_n_features)\n",
        "\n",
        "        print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "        print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "        print(f\"  Total time: {training_time:.2f}s ({training_time/60:.1f} min)\")\n",
        "        print(f\"  Model saved: {model_path}\")\n",
        "        print(f\"  â Run {run_id + 1} completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  â ERROR in Run {run_id + 1}: {str(e)}\")\n",
        "        print(f\"  Traceback: {e}\")\n",
        "        # Log error but continue with next run\n",
        "        error_log_path = f\"{MODELS_DIR}/run_{run_id}_error.txt\"\n",
        "        with open(error_log_path, 'w') as f:\n",
        "            f.write(f\"Error in Run {run_id}\\n\")\n",
        "            f.write(f\"Error: {str(e)}\\n\")\n",
        "            import traceback\n",
        "            f.write(traceback.format_exc())\n",
        "        print(f\"  Error logged to: {error_log_path}\")\n",
        "        continue\n",
        "\n",
        "total_training_time = time.time() - start_time_total\n",
        "\n",
        "print(f\"\\nTotal training time: {total_training_time:.2f}s ({total_training_time/60:.2f} min)\")\n",
        "print(f\"Successful runs: {len(validation_aucs)}/{CONFIG['n_runs']}\")\n",
        "\n",
        "# Check if we have enough successful runs\n",
        "if len(validation_aucs) == 0:\n",
        "    raise RuntimeError(\"All runs failed. Please check error logs.\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. STATISTICAL SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/7] Computing statistical summary...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "validation_aucs_array = np.array(validation_aucs)\n",
        "optimal_n_array = np.array(all_optimal_n)\n",
        "\n",
        "statistics = {\n",
        "    'optimal_n_mean': float(np.mean(optimal_n_array)),\n",
        "    'optimal_n_std': float(np.std(optimal_n_array, ddof=1)) if len(optimal_n_array) > 1 else 0.0,\n",
        "    'optimal_n_range': [int(np.min(optimal_n_array)), int(np.max(optimal_n_array))],\n",
        "    'mean_val_auc': float(np.mean(validation_aucs_array)),\n",
        "    'std_val_auc': float(np.std(validation_aucs_array, ddof=1)) if len(validation_aucs_array) > 1 else 0.0,\n",
        "    'min_val_auc': float(np.min(validation_aucs_array)),\n",
        "    'max_val_auc': float(np.max(validation_aucs_array)),\n",
        "    'median_val_auc': float(np.median(validation_aucs_array)),\n",
        "    'best_run_id': int(np.argmax(validation_aucs_array)),\n",
        "    'total_training_time_seconds': round(total_training_time, 2),\n",
        "    'successful_runs': len(validation_aucs),\n",
        "    'total_runs': CONFIG['n_runs']\n",
        "}\n",
        "\n",
        "training_results['training_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Optimal number of features across successful runs:\")\n",
        "print(f\"  Mean:   {statistics['optimal_n_mean']:.1f}\")\n",
        "print(f\"  Std:    {statistics['optimal_n_std']:.1f}\")\n",
        "print(f\"  Range:  [{statistics['optimal_n_range'][0]}, {statistics['optimal_n_range'][1]}]\")\n",
        "\n",
        "print(\"\\nValidation AUC statistics across successful runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_val_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_val_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_val_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_val_auc']:.4f}\")\n",
        "print(f\"\\nBest run: Run {statistics['best_run_id']} \"\n",
        "      f\"(AUC = {statistics['max_val_auc']:.4f}, n_features = {all_optimal_n[statistics['best_run_id']]})\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. FEATURE STABILITY ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/7] Analyzing feature selection stability...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate selection frequency\n",
        "all_features = X_train.columns.tolist()\n",
        "selection_frequency = {}\n",
        "\n",
        "for feature in all_features:\n",
        "    count = sum(1 for selected_set in all_selected_features if feature in selected_set)\n",
        "    selection_frequency[feature] = count / len(all_selected_features)\n",
        "\n",
        "# Sort by frequency\n",
        "sorted_features = sorted(selection_frequency.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Identify core and stable features\n",
        "core_features = [feat for feat, freq in sorted_features if freq == 1.0]\n",
        "stable_features = [feat for feat, freq in sorted_features if freq >= 0.8]\n",
        "\n",
        "# Calculate mean Jaccard similarity\n",
        "jaccard_similarities = []\n",
        "for i in range(len(all_selected_features)):\n",
        "    for j in range(i+1, len(all_selected_features)):\n",
        "        intersection = len(all_selected_features[i] & all_selected_features[j])\n",
        "        union = len(all_selected_features[i] | all_selected_features[j])\n",
        "        jaccard = intersection / union if union > 0 else 0\n",
        "        jaccard_similarities.append(jaccard)\n",
        "\n",
        "mean_jaccard = np.mean(jaccard_similarities) if jaccard_similarities else 0\n",
        "\n",
        "training_results['feature_stability'] = {\n",
        "    'selection_frequency': selection_frequency,\n",
        "    'core_features': core_features,\n",
        "    'stable_features': stable_features,\n",
        "    'mean_jaccard_similarity': float(mean_jaccard)\n",
        "}\n",
        "\n",
        "print(f\"Core features (100% selection): {len(core_features)}\")\n",
        "for feature in core_features:\n",
        "    print(f\"  - {feature}\")\n",
        "\n",
        "print(f\"\\nStable features (>=80% selection): {len(stable_features)}\")\n",
        "for feature in stable_features[:10]:\n",
        "    freq = selection_frequency[feature]\n",
        "    print(f\"  - {feature}: {freq*100:.0f}%\")\n",
        "if len(stable_features) > 10:\n",
        "    print(f\"  ... and {len(stable_features) - 10} more\")\n",
        "\n",
        "print(f\"\\nMean Jaccard similarity: {mean_jaccard:.3f}\")\n",
        "\n",
        "# Save feature stability details\n",
        "stability_df = pd.DataFrame([\n",
        "    {'feature': feat, 'selection_frequency': freq}\n",
        "    for feat, freq in sorted_features\n",
        "])\n",
        "stability_csv_path = f\"{BASELINE_3_DIR}/feature_stability_analysis.csv\"\n",
        "stability_df.to_csv(stability_csv_path, index=False)\n",
        "print(f\"\\nFeature stability saved: {stability_csv_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. IDENTIFY AND SAVE BEST MODEL\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/7] Saving best model...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_run_id = statistics['best_run_id']\n",
        "best_run_result = training_results['training_results']['runs'][best_run_id]\n",
        "\n",
        "# Load and save best model separately\n",
        "best_model = xgb.XGBClassifier()\n",
        "best_model.load_model(best_run_result['model_path'])\n",
        "\n",
        "best_model_path = f\"{BASELINE_3_DIR}/baseline_3_best_model.json\"\n",
        "best_model.save_model(best_model_path)\n",
        "\n",
        "training_results['best_model'] = {\n",
        "    'run_id': best_run_id,\n",
        "    'random_state': best_run_result['random_state'],\n",
        "    'n_features_selected': best_run_result['rfecv_results']['optimal_n_features'],\n",
        "    'selected_features': best_run_result['rfecv_results']['selected_features'],\n",
        "    'validation_auc': best_run_result['validation_metrics']['roc_auc'],\n",
        "    'validation_metrics': best_run_result['validation_metrics'],\n",
        "    'model_path': best_model_path\n",
        "}\n",
        "\n",
        "print(f\"Best model: Run {best_run_id}\")\n",
        "print(f\"  Validation AUC: {best_run_result['validation_metrics']['roc_auc']:.4f}\")\n",
        "print(f\"  Validation Accuracy: {best_run_result['validation_metrics']['accuracy']:.4f}\")\n",
        "print(f\"  Features selected: {best_run_result['rfecv_results']['optimal_n_features']}\")\n",
        "print(f\"  Saved to: {best_model_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. SAVE TRAINING RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/7] Saving training results...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "results_path = f\"{BASELINE_3_DIR}/baseline_3_training_results.json\"\n",
        "save_results(training_results, results_path)\n",
        "\n",
        "print(f\"Training results saved: {results_path}\")\n",
        "\n",
        "# Generate summary statistics file\n",
        "summary = {\n",
        "    'experiment': 'Baseline 3: XGBoost with RFECV (Fixed)',\n",
        "    'feature_selection': {\n",
        "        'method': 'Wrapper (RFECV - model-guided)',\n",
        "        'optimal_n_mean': statistics['optimal_n_mean'],\n",
        "        'optimal_n_range': statistics['optimal_n_range'],\n",
        "        'original_features': X_train.shape[1],\n",
        "        'reduction_mean_percent': round((1 - statistics['optimal_n_mean']/X_train.shape[1]) * 100, 1)\n",
        "    },\n",
        "    'n_runs': CONFIG['n_runs'],\n",
        "    'successful_runs': statistics['successful_runs'],\n",
        "    'validation_auc': {\n",
        "        'mean': statistics['mean_val_auc'],\n",
        "        'std': statistics['std_val_auc'],\n",
        "        'range': [statistics['min_val_auc'], statistics['max_val_auc']]\n",
        "    },\n",
        "    'feature_stability': {\n",
        "        'core_features_count': len(core_features),\n",
        "        'stable_features_count': len(stable_features),\n",
        "        'mean_jaccard_similarity': mean_jaccard\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_id,\n",
        "        'validation_auc': statistics['max_val_auc'],\n",
        "        'n_features': all_optimal_n[best_run_id]\n",
        "    },\n",
        "    'training_time_total_minutes': round(total_training_time / 60, 2)\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_3_DIR}/training_summary.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Training summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 3 TRAINING COMPLETED\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nEXPERIMENT SUMMARY:\")\n",
        "print(f\"  Method: RFECV (Wrapper - model-guided)\")\n",
        "print(f\"  Feature selection: Independent per run\")\n",
        "print(f\"  Successful runs: {statistics['successful_runs']}/{CONFIG['n_runs']}\")\n",
        "print(f\"  Total training time: {total_training_time/60:.2f} minutes\")\n",
        "\n",
        "print(\"\\nFEATURE SELECTION RESULTS:\")\n",
        "print(f\"  Optimal n (mean): {statistics['optimal_n_mean']:.1f} Â± {statistics['optimal_n_std']:.1f}\")\n",
        "print(f\"  Optimal n (range): [{statistics['optimal_n_range'][0]}, {statistics['optimal_n_range'][1]}]\")\n",
        "print(f\"  Reduction (mean): {(1 - statistics['optimal_n_mean']/X_train.shape[1]) * 100:.1f}%\")\n",
        "print(f\"  Core features: {len(core_features)} (selected in 100% runs)\")\n",
        "print(f\"  Stable features: {len(stable_features)} (selected in >=80% runs)\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_val_auc']:.4f} Â± {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Best AUC: {statistics['max_val_auc']:.4f} (Run {best_run_id})\")\n",
        "print(f\"  AUC range: [{statistics['min_val_auc']:.4f}, {statistics['max_val_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nCORE FEATURES (100% selection):\")\n",
        "if core_features:\n",
        "    for feature in core_features:\n",
        "        print(f\"  - {feature}\")\n",
        "else:\n",
        "    print(\"  (None - expected with wrapper method variability)\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Training results: {results_path}\")\n",
        "print(f\"  Best model: {best_model_path}\")\n",
        "print(f\"  All models: {MODELS_DIR}/ (models + RFECV details)\")\n",
        "print(f\"  Feature stability: {stability_csv_path}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  - Review feature selection results\")\n",
        "print(\"  - Compare with other baseline methods\")\n",
        "print(\"  - Proceed to testing phase\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR ANALYSIS\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1FW55gBZnpa",
        "outputId": "b548a2f2-2a57-4c77-b8a7-3f234a4f0078",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 3 TRAINING: XGBOOST WITH RFECV (FIXED VERSION)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/7] Verifying Cell 1 completion...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Training data (1270 samples x 25 features)\n",
            "VERIFIED: Validation data (318 samples)\n",
            "VERIFIED: RFECV config loaded\n",
            "VERIFIED: Number of runs = 10\n",
            "\n",
            "[STEP 2/7] Setting up Baseline 3 experiment...\n",
            "--------------------------------------------------\n",
            "Experiment directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3\n",
            "Models directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models\n",
            "\n",
            "Experiment configuration:\n",
            "  Method: RFECV (Wrapper - model-guided)\n",
            "  RFECV estimator: n_estimators=150, max_depth=6, lr=0.1\n",
            "  Final model: n_estimators=500, max_depth=8, lr=0.05\n",
            "  Tree method: hist (CPU-optimized, GPU params removed)\n",
            "  RFECV step: 5 features\n",
            "  RFECV CV: 3 folds\n",
            "  Min features: 8\n",
            "  Number of runs: 10\n",
            "  Parallel processing: DISABLED (n_jobs=1, nthread=1 for stability)\n",
            "\n",
            "[STEP 3/7] Running 10 independent RFECV experiments...\n",
            "--------------------------------------------------\n",
            "\n",
            "Run 1/10 (seed=42)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 4.5s (0.1 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 5.08s (0.1 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_0_model.json\n",
            "  â Run 1 completed successfully\n",
            "\n",
            "Run 2/10 (seed=43)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 2.6s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 2.96s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_1_model.json\n",
            "  â Run 2 completed successfully\n",
            "\n",
            "Run 3/10 (seed=44)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 1.9s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 2.31s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_2_model.json\n",
            "  â Run 3 completed successfully\n",
            "\n",
            "Run 4/10 (seed=45)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 2.3s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 2.65s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_3_model.json\n",
            "  â Run 4 completed successfully\n",
            "\n",
            "Run 5/10 (seed=46)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 1.1s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 1.32s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_4_model.json\n",
            "  â Run 5 completed successfully\n",
            "\n",
            "Run 6/10 (seed=47)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 1.9s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 2.12s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_5_model.json\n",
            "  â Run 6 completed successfully\n",
            "\n",
            "Run 7/10 (seed=48)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.9s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 1.03s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_6_model.json\n",
            "  â Run 7 completed successfully\n",
            "\n",
            "Run 8/10 (seed=49)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.6s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.80s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_7_model.json\n",
            "  â Run 8 completed successfully\n",
            "\n",
            "Run 9/10 (seed=50)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.6s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.78s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_8_model.json\n",
            "  â Run 9 completed successfully\n",
            "\n",
            "Run 10/10 (seed=51)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.7s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.80s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/run_9_model.json\n",
            "  â Run 10 completed successfully\n",
            "\n",
            "Total training time: 20.26s (0.34 min)\n",
            "Successful runs: 10/10\n",
            "\n",
            "[STEP 4/7] Computing statistical summary...\n",
            "--------------------------------------------------\n",
            "Optimal number of features across successful runs:\n",
            "  Mean:   25.0\n",
            "  Std:    0.0\n",
            "  Range:  [25, 25]\n",
            "\n",
            "Validation AUC statistics across successful runs:\n",
            "  Mean:   0.9964\n",
            "  Std:    0.0000\n",
            "  Min:    0.9964\n",
            "  Max:    0.9964\n",
            "  Median: 0.9964\n",
            "\n",
            "Best run: Run 1 (AUC = 0.9964, n_features = 25)\n",
            "\n",
            "[STEP 5/7] Analyzing feature selection stability...\n",
            "--------------------------------------------------\n",
            "Core features (100% selection): 25\n",
            "  - A1\n",
            "  - A2\n",
            "  - A3\n",
            "  - A4\n",
            "  - A5\n",
            "  - A6\n",
            "  - A7\n",
            "  - A8\n",
            "  - A9\n",
            "  - A10_Autism_Spectrum_Quotient\n",
            "  - Social_Responsiveness_Scale\n",
            "  - Age_Years\n",
            "  - Qchat_10_Score\n",
            "  - Speech Delay/Language Disorder\n",
            "  - Learning disorder\n",
            "  - Genetic_Disorders\n",
            "  - Depression\n",
            "  - Global developmental delay/intellectual disability\n",
            "  - Social/Behavioural Issues\n",
            "  - Childhood Autism Rating Scale\n",
            "  - Anxiety_disorder\n",
            "  - Sex\n",
            "  - Jaundice\n",
            "  - Family_mem_with_ASD\n",
            "  - Who_completed_the_test\n",
            "\n",
            "Stable features (>=80% selection): 25\n",
            "  - A1: 100%\n",
            "  - A2: 100%\n",
            "  - A3: 100%\n",
            "  - A4: 100%\n",
            "  - A5: 100%\n",
            "  - A6: 100%\n",
            "  - A7: 100%\n",
            "  - A8: 100%\n",
            "  - A9: 100%\n",
            "  - A10_Autism_Spectrum_Quotient: 100%\n",
            "  ... and 15 more\n",
            "\n",
            "Mean Jaccard similarity: 1.000\n",
            "\n",
            "Feature stability saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/feature_stability_analysis.csv\n",
            "\n",
            "[STEP 6/7] Saving best model...\n",
            "--------------------------------------------------\n",
            "Best model: Run 1\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Features selected: 25\n",
            "  Saved to: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/baseline_3_best_model.json\n",
            "\n",
            "[STEP 7/7] Saving training results...\n",
            "--------------------------------------------------\n",
            "Training results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/baseline_3_training_results.json\n",
            "Training summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/training_summary.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 3 TRAINING COMPLETED\n",
            "================================================================================\n",
            "\n",
            "EXPERIMENT SUMMARY:\n",
            "  Method: RFECV (Wrapper - model-guided)\n",
            "  Feature selection: Independent per run\n",
            "  Successful runs: 10/10\n",
            "  Total training time: 0.34 minutes\n",
            "\n",
            "FEATURE SELECTION RESULTS:\n",
            "  Optimal n (mean): 25.0 Â± 0.0\n",
            "  Optimal n (range): [25, 25]\n",
            "  Reduction (mean): 0.0%\n",
            "  Core features: 25 (selected in 100% runs)\n",
            "  Stable features: 25 (selected in >=80% runs)\n",
            "\n",
            "VALIDATION PERFORMANCE:\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "  Best AUC: 0.9964 (Run 1)\n",
            "  AUC range: [0.9964, 0.9964]\n",
            "\n",
            "CORE FEATURES (100% selection):\n",
            "  - A1\n",
            "  - A2\n",
            "  - A3\n",
            "  - A4\n",
            "  - A5\n",
            "  - A6\n",
            "  - A7\n",
            "  - A8\n",
            "  - A9\n",
            "  - A10_Autism_Spectrum_Quotient\n",
            "  - Social_Responsiveness_Scale\n",
            "  - Age_Years\n",
            "  - Qchat_10_Score\n",
            "  - Speech Delay/Language Disorder\n",
            "  - Learning disorder\n",
            "  - Genetic_Disorders\n",
            "  - Depression\n",
            "  - Global developmental delay/intellectual disability\n",
            "  - Social/Behavioural Issues\n",
            "  - Childhood Autism Rating Scale\n",
            "  - Anxiety_disorder\n",
            "  - Sex\n",
            "  - Jaundice\n",
            "  - Family_mem_with_ASD\n",
            "  - Who_completed_the_test\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Training results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/baseline_3_training_results.json\n",
            "  Best model: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/baseline_3_best_model.json\n",
            "  All models: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/models/ (models + RFECV details)\n",
            "  Feature stability: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/feature_stability_analysis.csv\n",
            "\n",
            "NEXT STEPS:\n",
            "  - Review feature selection results\n",
            "  - Compare with other baseline methods\n",
            "  - Proceed to testing phase\n",
            "\n",
            "================================================================================\n",
            "READY FOR ANALYSIS\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5: Baseline 1 Testing - Test Set Evaluation\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 5: Baseline 1 Testing - Test set evaluation for XGBoost with All Features\n",
        "Evaluate all 10 trained models on held-out test set\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 1 TESTING: TEST SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/7] Verifying prerequisites...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_test' in dir() and X_test.shape[0] == 397\n",
        "    assert 'y_test' in dir() and len(y_test) == 397\n",
        "    assert X_test.shape[1] == 25\n",
        "    print(f\"VERIFIED: Test data ({X_test.shape[0]} samples x {X_test.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Test set integrity maintained\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOAD TRAINING RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/7] Loading training results from Cell 2...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_1_TRAINING_DIR = f\"{PROJECT_PATHS['root']}/03_Results/output_notebook_02/cell_2_baseline1/training\"\n",
        "BASELINE_1_TESTING_DIR = f\"{PROJECT_PATHS['root']}/03_Results/output_notebook_02/cell_2_baseline1/testing\"\n",
        "os.makedirs(BASELINE_1_TESTING_DIR, exist_ok=True)\n",
        "\n",
        "training_results_path = f\"{BASELINE_1_TRAINING_DIR}/baseline_1_training_results.json\"\n",
        "\n",
        "if not os.path.exists(training_results_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Training results not found: {training_results_path}\\n\"\n",
        "        \"ERROR: Cell 2 (Baseline 1 Training) must be executed first\"\n",
        "    )\n",
        "\n",
        "with open(training_results_path, 'r') as f:\n",
        "    training_results = json.load(f)\n",
        "\n",
        "print(f\"Training results loaded: {training_results_path}\")\n",
        "\n",
        "# Verify training completed\n",
        "n_runs_trained = len(training_results['training_results']['runs'])\n",
        "if n_runs_trained != 10:\n",
        "    raise ValueError(f\"Expected 10 training runs, found {n_runs_trained}\")\n",
        "\n",
        "print(f\"Verified: {n_runs_trained} training runs completed\")\n",
        "print(f\"Training mean validation AUC: {training_results['training_results']['statistics']['mean_val_auc']:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. LOAD ALL TRAINED MODELS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/7] Loading all trained models...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "MODELS_DIR = f\"{BASELINE_1_TRAINING_DIR}/models\"\n",
        "\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    raise FileNotFoundError(f\"Models directory not found: {MODELS_DIR}\")\n",
        "\n",
        "loaded_models = []\n",
        "\n",
        "for run_id in range(10):\n",
        "    model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "\n",
        "    # Check if model file exists\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Model file not found: {model_path}\\n\"\n",
        "            f\"ERROR: Training run {run_id} incomplete\"\n",
        "        )\n",
        "\n",
        "    # Load model\n",
        "    try:\n",
        "        model = xgb.XGBClassifier()\n",
        "        model.load_model(model_path)\n",
        "        loaded_models.append({\n",
        "            'run_id': run_id,\n",
        "            'model': model,\n",
        "            'model_path': model_path\n",
        "        })\n",
        "        print(f\"  Loaded: run_{run_id}_model.json\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to load model {run_id}: {e}\")\n",
        "\n",
        "print(f\"\\nSuccessfully loaded all {len(loaded_models)} models\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. EVALUATE ALL MODELS ON TEST SET\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/7] Evaluating all models on test set...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 1 Testing: XGBoost with All Features',\n",
        "        'description': 'Test set evaluation for all 10 trained models',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'test_set_size': len(y_test),\n",
        "        'n_features': X_test.shape[1]\n",
        "    },\n",
        "    'training_summary': {\n",
        "        'n_runs': n_runs_trained,\n",
        "        'validation_auc_mean': training_results['training_results']['statistics']['mean_val_auc'],\n",
        "        'validation_auc_std': training_results['training_results']['statistics']['std_val_auc']\n",
        "    },\n",
        "    'test_results': {\n",
        "        'runs': []\n",
        "    }\n",
        "}\n",
        "\n",
        "test_aucs = []\n",
        "test_accuracies = []\n",
        "\n",
        "for model_info in loaded_models:\n",
        "    run_id = model_info['run_id']\n",
        "    model = model_info['model']\n",
        "\n",
        "    print(f\"\\nRun {run_id}:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Get validation results from training\n",
        "    training_run = training_results['training_results']['runs'][run_id]\n",
        "    val_metrics = training_run['validation_metrics']\n",
        "\n",
        "    # Predict on test set (all 25 features)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate test metrics\n",
        "    test_metrics = calculate_metrics(y_test, y_test_pred, y_test_proba)\n",
        "\n",
        "    # Store results\n",
        "    run_result = {\n",
        "        'run_id': run_id,\n",
        "        'random_state': training_run['random_state'],\n",
        "        'validation_metrics': val_metrics,\n",
        "        'test_metrics': test_metrics,\n",
        "        'generalization_gap': {\n",
        "            'auc_gap': float(val_metrics['roc_auc'] - test_metrics['roc_auc']),\n",
        "            'accuracy_gap': float(val_metrics['accuracy'] - test_metrics['accuracy'])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    test_results['test_results']['runs'].append(run_result)\n",
        "    test_aucs.append(test_metrics['roc_auc'])\n",
        "    test_accuracies.append(test_metrics['accuracy'])\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Test AUC:       {test_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Gap:            {run_result['generalization_gap']['auc_gap']:.4f}\")\n",
        "    print(f\"  Test Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
        "\n",
        "print(\"\\nAll models evaluated on test set\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. STATISTICAL SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/7] Computing statistical summary...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_aucs_array = np.array(test_aucs)\n",
        "test_accuracies_array = np.array(test_accuracies)\n",
        "\n",
        "# Calculate 95% confidence intervals (percentile-based)\n",
        "ci_95_lower = float(np.percentile(test_aucs_array, 2.5))\n",
        "ci_95_upper = float(np.percentile(test_aucs_array, 97.5))\n",
        "\n",
        "statistics = {\n",
        "    'mean_test_auc': float(np.mean(test_aucs_array)),\n",
        "    'std_test_auc': float(np.std(test_aucs_array, ddof=1)),\n",
        "    'min_test_auc': float(np.min(test_aucs_array)),\n",
        "    'max_test_auc': float(np.max(test_aucs_array)),\n",
        "    'median_test_auc': float(np.median(test_aucs_array)),\n",
        "    'ci_95_lower': ci_95_lower,\n",
        "    'ci_95_upper': ci_95_upper,\n",
        "    'best_run_index': int(np.argmax(test_aucs_array)),\n",
        "    'all_metrics_summary': {\n",
        "        'accuracy': {\n",
        "            'mean': float(np.mean(test_accuracies_array)),\n",
        "            'std': float(np.std(test_accuracies_array, ddof=1))\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Add all metrics summary\n",
        "for metric in ['precision_macro', 'recall_macro', 'f1_macro', 'log_loss']:\n",
        "    metric_values = [run['test_metrics'][metric] for run in test_results['test_results']['runs']]\n",
        "    statistics['all_metrics_summary'][metric] = {\n",
        "        'mean': float(np.mean(metric_values)),\n",
        "        'std': float(np.std(metric_values, ddof=1))\n",
        "    }\n",
        "\n",
        "test_results['test_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Test AUC statistics across 10 runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_test_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_test_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_test_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_test_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_test_auc']:.4f}\")\n",
        "print(f\"  95% CI: [{ci_95_lower:.4f}, {ci_95_upper:.4f}]\")\n",
        "\n",
        "print(\"\\nAll metrics summary:\")\n",
        "for metric, values in statistics['all_metrics_summary'].items():\n",
        "    print(f\"  {metric}: {values['mean']:.4f} Â± {values['std']:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. OVERFITTING DETECTION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/7] Detecting overfitting...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "OVERFITTING_THRESHOLD = 0.03\n",
        "\n",
        "val_auc_mean = test_results['training_summary']['validation_auc_mean']\n",
        "test_auc_mean = statistics['mean_test_auc']\n",
        "overall_gap = val_auc_mean - test_auc_mean\n",
        "\n",
        "# Per-run overfitting detection\n",
        "overfitting_runs = []\n",
        "for run in test_results['test_results']['runs']:\n",
        "    gap = run['generalization_gap']['auc_gap']\n",
        "    if gap > OVERFITTING_THRESHOLD:\n",
        "        overfitting_runs.append({\n",
        "            'run_id': run['run_id'],\n",
        "            'gap': gap,\n",
        "            'validation_auc': run['validation_metrics']['roc_auc'],\n",
        "            'test_auc': run['test_metrics']['roc_auc']\n",
        "        })\n",
        "\n",
        "overfitting_analysis = {\n",
        "    'threshold': OVERFITTING_THRESHOLD,\n",
        "    'overall_gap': float(overall_gap),\n",
        "    'overall_status': 'OVERFITTING' if overall_gap > OVERFITTING_THRESHOLD else 'GOOD_GENERALIZATION',\n",
        "    'n_overfitting_runs': len(overfitting_runs),\n",
        "    'overfitting_runs': overfitting_runs\n",
        "}\n",
        "\n",
        "test_results['overfitting_analysis'] = overfitting_analysis\n",
        "\n",
        "print(f\"Overfitting threshold: {OVERFITTING_THRESHOLD}\")\n",
        "print(f\"Overall generalization gap: {overall_gap:.4f}\")\n",
        "print(f\"Overall status: {overfitting_analysis['overall_status']}\")\n",
        "\n",
        "if overfitting_runs:\n",
        "    print(f\"\\nWARNING: {len(overfitting_runs)} run(s) show overfitting (gap > {OVERFITTING_THRESHOLD}):\")\n",
        "    for run in overfitting_runs:\n",
        "        print(f\"  Run {run['run_id']}: gap = {run['gap']:.4f} \"\n",
        "              f\"(val={run['validation_auc']:.4f}, test={run['test_auc']:.4f})\")\n",
        "else:\n",
        "    print(f\"\\nAll runs show good generalization (gap <= {OVERFITTING_THRESHOLD})\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. SAVE TEST RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/7] Saving test results...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Add best performance details\n",
        "best_run_idx = statistics['best_run_index']\n",
        "best_run = test_results['test_results']['runs'][best_run_idx]\n",
        "\n",
        "test_results['best_performance'] = {\n",
        "    'run_id': best_run_idx,\n",
        "    'random_state': best_run['random_state'],\n",
        "    'test_auc': best_run['test_metrics']['roc_auc'],\n",
        "    'all_test_metrics': best_run['test_metrics'],\n",
        "    'validation_auc': best_run['validation_metrics']['roc_auc'],\n",
        "    'generalization_gap': best_run['generalization_gap']['auc_gap']\n",
        "}\n",
        "\n",
        "# Save results\n",
        "results_path = f\"{BASELINE_1_TESTING_DIR}/baseline_1_test_results_CPU.json\"\n",
        "save_results(test_results, results_path)\n",
        "\n",
        "print(f\"Test results saved: {results_path}\")\n",
        "\n",
        "# Generate summary\n",
        "summary = {\n",
        "    'experiment': 'Baseline 1 Testing: XGBoost with All Features',\n",
        "    'n_features': X_test.shape[1],\n",
        "    'test_set_size': len(y_test),\n",
        "    'n_models_tested': len(loaded_models),\n",
        "    'performance': {\n",
        "        'validation_auc_mean': val_auc_mean,\n",
        "        'test_auc_mean': test_auc_mean,\n",
        "        'generalization_gap': overall_gap\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_idx,\n",
        "        'test_auc': best_run['test_metrics']['roc_auc']\n",
        "    },\n",
        "    'overfitting_status': overfitting_analysis['overall_status']\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_1_TESTING_DIR}/testing_summary.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Testing summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 1 TESTING COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nTEST SET EVALUATION:\")\n",
        "print(f\"  Method: XGBoost with all features (no selection)\")\n",
        "print(f\"  Features: {X_test.shape[1]} features\")\n",
        "print(f\"  Test samples: {len(y_test)}\")\n",
        "print(f\"  Models tested: {len(loaded_models)}\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE (from training):\")\n",
        "print(f\"  Mean AUC: {val_auc_mean:.4f} Â± {test_results['training_summary']['validation_auc_std']:.4f}\")\n",
        "\n",
        "print(\"\\nTEST PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_test_auc']:.4f} Â± {statistics['std_test_auc']:.4f}\")\n",
        "print(f\"  95% CI: [{ci_95_lower:.4f}, {ci_95_upper:.4f}]\")\n",
        "print(f\"  Best AUC: {statistics['max_test_auc']:.4f} (Run {best_run_idx})\")\n",
        "print(f\"  AUC range: [{statistics['min_test_auc']:.4f}, {statistics['max_test_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nGENERALIZATION ANALYSIS:\")\n",
        "print(f\"  Overall gap (val - test): {overall_gap:.4f}\")\n",
        "print(f\"  Status: {overfitting_analysis['overall_status']}\")\n",
        "if overfitting_runs:\n",
        "    print(f\"  WARNING: {len(overfitting_runs)}/10 runs show overfitting\")\n",
        "else:\n",
        "    print(f\"  All runs generalize well\")\n",
        "\n",
        "print(\"\\nALL METRICS (Test Set):\")\n",
        "print(f\"  Accuracy:       {statistics['all_metrics_summary']['accuracy']['mean']:.4f} Â± {statistics['all_metrics_summary']['accuracy']['std']:.4f}\")\n",
        "print(f\"  Precision:      {statistics['all_metrics_summary']['precision_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['precision_macro']['std']:.4f}\")\n",
        "print(f\"  Recall:         {statistics['all_metrics_summary']['recall_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['recall_macro']['std']:.4f}\")\n",
        "print(f\"  F1-Score:       {statistics['all_metrics_summary']['f1_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['f1_macro']['std']:.4f}\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Test results: {results_path}\")\n",
        "print(f\"  Testing summary: {summary_path}\")\n",
        "print(f\"  Output directory: {BASELINE_1_TESTING_DIR}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 6: Baseline 2 Testing - SelectKBest test set evaluation\")\n",
        "print(\"  Cell 7: Baseline 3 Testing - RFECV test set evaluation\")\n",
        "print(\"  Cell 8: Comprehensive Comparison & Statistical Analysis\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR NEXT BASELINE TESTING\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "UYEublqV21DI",
        "outputId": "12530778-2a54-483d-8af3-5abd74805e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 1 TESTING: TEST SET EVALUATION\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/7] Verifying prerequisites...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Test data (397 samples x 25 features)\n",
            "VERIFIED: Test set integrity maintained\n",
            "\n",
            "[STEP 2/7] Loading training results from Cell 2...\n",
            "--------------------------------------------------\n",
            "Training results loaded: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_2_baseline1/training/baseline_1_training_results.json\n",
            "Verified: 10 training runs completed\n",
            "Training mean validation AUC: 0.9964\n",
            "\n",
            "[STEP 3/7] Loading all trained models...\n",
            "--------------------------------------------------\n",
            "  Loaded: run_0_model.json\n",
            "  Loaded: run_1_model.json\n",
            "  Loaded: run_2_model.json\n",
            "  Loaded: run_3_model.json\n",
            "  Loaded: run_4_model.json\n",
            "  Loaded: run_5_model.json\n",
            "  Loaded: run_6_model.json\n",
            "  Loaded: run_7_model.json\n",
            "  Loaded: run_8_model.json\n",
            "  Loaded: run_9_model.json\n",
            "\n",
            "Successfully loaded all 10 models\n",
            "\n",
            "[STEP 4/7] Evaluating all models on test set...\n",
            "--------------------------------------------------\n",
            "\n",
            "Run 0:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 1:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9982\n",
            "  Gap:            -0.0018\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 2:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9982\n",
            "  Gap:            -0.0018\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 3:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 4:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 5:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 6:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 7:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9982\n",
            "  Gap:            -0.0018\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 8:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 9:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9983\n",
            "  Gap:            -0.0019\n",
            "  Test Accuracy:  0.9597\n",
            "\n",
            "All models evaluated on test set\n",
            "\n",
            "[STEP 5/7] Computing statistical summary...\n",
            "--------------------------------------------------\n",
            "Test AUC statistics across 10 runs:\n",
            "  Mean:   0.9981\n",
            "  Std:    0.0001\n",
            "  Min:    0.9981\n",
            "  Max:    0.9983\n",
            "  Median: 0.9981\n",
            "  95% CI: [0.9981, 0.9983]\n",
            "\n",
            "All metrics summary:\n",
            "  accuracy: 0.9574 Â± 0.0008\n",
            "  precision_macro: 0.9624 Â± 0.0006\n",
            "  recall_macro: 0.9540 Â± 0.0009\n",
            "  f1_macro: 0.9568 Â± 0.0008\n",
            "  log_loss: 0.0542 Â± 0.0009\n",
            "\n",
            "[STEP 6/7] Detecting overfitting...\n",
            "--------------------------------------------------\n",
            "Overfitting threshold: 0.03\n",
            "Overall generalization gap: -0.0017\n",
            "Overall status: GOOD_GENERALIZATION\n",
            "\n",
            "All runs show good generalization (gap <= 0.03)\n",
            "\n",
            "[STEP 7/7] Saving test results...\n",
            "--------------------------------------------------\n",
            "Test results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_2_baseline1/testing/baseline_1_test_results_CPU.json\n",
            "Testing summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_2_baseline1/testing/testing_summary.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 1 TESTING COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "TEST SET EVALUATION:\n",
            "  Method: XGBoost with all features (no selection)\n",
            "  Features: 25 features\n",
            "  Test samples: 397\n",
            "  Models tested: 10\n",
            "\n",
            "VALIDATION PERFORMANCE (from training):\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "\n",
            "TEST PERFORMANCE:\n",
            "  Mean AUC: 0.9981 Â± 0.0001\n",
            "  95% CI: [0.9981, 0.9983]\n",
            "  Best AUC: 0.9983 (Run 9)\n",
            "  AUC range: [0.9981, 0.9983]\n",
            "\n",
            "GENERALIZATION ANALYSIS:\n",
            "  Overall gap (val - test): -0.0017\n",
            "  Status: GOOD_GENERALIZATION\n",
            "  All runs generalize well\n",
            "\n",
            "ALL METRICS (Test Set):\n",
            "  Accuracy:       0.9574 Â± 0.0008\n",
            "  Precision:      0.9624 Â± 0.0006\n",
            "  Recall:         0.9540 Â± 0.0009\n",
            "  F1-Score:       0.9568 Â± 0.0008\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Test results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_2_baseline1/testing/baseline_1_test_results_CPU.json\n",
            "  Testing summary: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_2_baseline1/testing/testing_summary.json\n",
            "  Output directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_2_baseline1/testing\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 6: Baseline 2 Testing - SelectKBest test set evaluation\n",
            "  Cell 7: Baseline 3 Testing - RFECV test set evaluation\n",
            "  Cell 8: Comprehensive Comparison & Statistical Analysis\n",
            "\n",
            "================================================================================\n",
            "READY FOR NEXT BASELINE TESTING\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 6: Baseline 2 Testing - Test Set Evaluation\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 6: Baseline 2 Testing - Test set evaluation for XGBoost with SelectKBest\n",
        "Evaluate all 10 trained models on held-out test set with selected features\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 2 TESTING: TEST SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/8] Verifying prerequisites...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_test' in dir() and X_test.shape[0] == 397\n",
        "    assert 'y_test' in dir() and len(y_test) == 397\n",
        "    assert X_test.shape[1] == 25\n",
        "    print(f\"VERIFIED: Test data ({X_test.shape[0]} samples x {X_test.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Test set integrity maintained\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOAD TRAINING RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/8] Loading training results from Cell 3...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_2_TRAINING_DIR = f\"{PROJECT_PATHS['root']}/03_Results/output_notebook_02/cell_3_baseline2/training\"\n",
        "BASELINE_2_TESTING_DIR = f\"{PROJECT_PATHS['root']}/03_Results/output_notebook_02/cell_3_baseline2/testing\"\n",
        "os.makedirs(BASELINE_2_TESTING_DIR, exist_ok=True)\n",
        "\n",
        "training_results_path = f\"{BASELINE_2_TRAINING_DIR}/baseline_2_training_results.json\"\n",
        "\n",
        "if not os.path.exists(training_results_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Training results not found: {training_results_path}\\n\"\n",
        "        \"ERROR: Cell 3 (Baseline 2 Training) must be executed first\"\n",
        "    )\n",
        "\n",
        "with open(training_results_path, 'r') as f:\n",
        "    training_results = json.load(f)\n",
        "\n",
        "print(f\"Training results loaded: {training_results_path}\")\n",
        "\n",
        "# Verify training completed\n",
        "n_runs_trained = len(training_results['training_results']['runs'])\n",
        "if n_runs_trained != 10:\n",
        "    raise ValueError(f\"Expected 10 training runs, found {n_runs_trained}\")\n",
        "\n",
        "print(f\"Verified: {n_runs_trained} training runs completed\")\n",
        "print(f\"Training mean validation AUC: {training_results['training_results']['statistics']['mean_val_auc']:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. EXTRACT FEATURE SELECTION DETAILS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/8] Extracting feature selection details...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "optimal_k = training_results['feature_selection']['n_features_selected']\n",
        "selected_features = training_results['feature_selection']['selected_features']\n",
        "feature_reduction_percent = (1 - optimal_k / X_test.shape[1]) * 100\n",
        "\n",
        "print(f\"Feature selection method: SelectKBest (f_classif)\")\n",
        "print(f\"Optimal k: {optimal_k}\")\n",
        "print(f\"Original features: {X_test.shape[1]}\")\n",
        "print(f\"Selected features: {optimal_k}\")\n",
        "print(f\"Feature reduction: {feature_reduction_percent:.1f}%\")\n",
        "\n",
        "print(f\"\\nSelected features:\")\n",
        "for i, feature in enumerate(selected_features[:10], 1):\n",
        "    print(f\"  {i:2d}. {feature}\")\n",
        "if len(selected_features) > 10:\n",
        "    print(f\"  ... and {len(selected_features) - 10} more\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. VERIFY FEATURE CONSISTENCY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/8] Verifying feature consistency across runs...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Verify all runs used same number of features\n",
        "for run in training_results['training_results']['runs']:\n",
        "    if run['n_features_selected'] != optimal_k:\n",
        "        raise ValueError(\n",
        "            f\"Inconsistent feature count: Run {run['run_id']} has \"\n",
        "            f\"{run['n_features_selected']} features, expected {optimal_k}\"\n",
        "        )\n",
        "\n",
        "print(f\"VERIFIED: All runs used {optimal_k} features (deterministic selection)\")\n",
        "\n",
        "# Verify selected features exist in test set\n",
        "missing_features = set(selected_features) - set(X_test.columns)\n",
        "if missing_features:\n",
        "    raise ValueError(f\"Selected features not in test set: {missing_features}\")\n",
        "\n",
        "print(f\"VERIFIED: All selected features available in test set\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. TRANSFORM TEST SET\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/8] Transforming test set with selected features...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "print(f\"Original test set: {X_test.shape[0]} samples x {X_test.shape[1]} features\")\n",
        "print(f\"Transformed test set: {X_test_selected.shape[0]} samples x {X_test_selected.shape[1]} features\")\n",
        "print(f\"Feature selection applied successfully\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. LOAD ALL TRAINED MODELS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/8] Loading all trained models...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "MODELS_DIR = f\"{BASELINE_2_TRAINING_DIR}/models\"\n",
        "\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    raise FileNotFoundError(f\"Models directory not found: {MODELS_DIR}\")\n",
        "\n",
        "loaded_models = []\n",
        "\n",
        "for run_id in range(10):\n",
        "    model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "\n",
        "    # Check if model file exists\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Model file not found: {model_path}\\n\"\n",
        "            f\"ERROR: Training run {run_id} incomplete\"\n",
        "        )\n",
        "\n",
        "    # Load model\n",
        "    try:\n",
        "        model = xgb.XGBClassifier()\n",
        "        model.load_model(model_path)\n",
        "        loaded_models.append({\n",
        "            'run_id': run_id,\n",
        "            'model': model,\n",
        "            'model_path': model_path\n",
        "        })\n",
        "        print(f\"  Loaded: run_{run_id}_model.json\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to load model {run_id}: {e}\")\n",
        "\n",
        "print(f\"\\nSuccessfully loaded all {len(loaded_models)} models\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. EVALUATE ALL MODELS ON TEST SET\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/8] Evaluating all models on test set...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 2 Testing: XGBoost with SelectKBest',\n",
        "        'description': 'Test set evaluation for all 10 trained models with selected features',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'test_set_size': len(y_test),\n",
        "        'n_features_original': X_test.shape[1],\n",
        "        'n_features_selected': optimal_k\n",
        "    },\n",
        "    'feature_selection_summary': {\n",
        "        'method': 'SelectKBest',\n",
        "        'n_features_selected': optimal_k,\n",
        "        'selected_features': selected_features,\n",
        "        'feature_reduction_percent': round(feature_reduction_percent, 1)\n",
        "    },\n",
        "    'training_summary': {\n",
        "        'n_runs': n_runs_trained,\n",
        "        'validation_auc_mean': training_results['training_results']['statistics']['mean_val_auc'],\n",
        "        'validation_auc_std': training_results['training_results']['statistics']['std_val_auc']\n",
        "    },\n",
        "    'test_results': {\n",
        "        'runs': []\n",
        "    }\n",
        "}\n",
        "\n",
        "test_aucs = []\n",
        "test_accuracies = []\n",
        "\n",
        "for model_info in loaded_models:\n",
        "    run_id = model_info['run_id']\n",
        "    model = model_info['model']\n",
        "\n",
        "    print(f\"\\nRun {run_id}:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Get validation results from training\n",
        "    training_run = training_results['training_results']['runs'][run_id]\n",
        "    val_metrics = training_run['validation_metrics']\n",
        "\n",
        "    # Predict on test set (selected features only)\n",
        "    y_test_pred = model.predict(X_test_selected)\n",
        "    y_test_proba = model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "    # Calculate test metrics\n",
        "    test_metrics = calculate_metrics(y_test, y_test_pred, y_test_proba)\n",
        "\n",
        "    # Store results\n",
        "    run_result = {\n",
        "        'run_id': run_id,\n",
        "        'random_state': training_run['random_state'],\n",
        "        'n_features_used': optimal_k,\n",
        "        'validation_metrics': val_metrics,\n",
        "        'test_metrics': test_metrics,\n",
        "        'generalization_gap': {\n",
        "            'auc_gap': float(val_metrics['roc_auc'] - test_metrics['roc_auc']),\n",
        "            'accuracy_gap': float(val_metrics['accuracy'] - test_metrics['accuracy'])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    test_results['test_results']['runs'].append(run_result)\n",
        "    test_aucs.append(test_metrics['roc_auc'])\n",
        "    test_accuracies.append(test_metrics['accuracy'])\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Test AUC:       {test_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Gap:            {run_result['generalization_gap']['auc_gap']:.4f}\")\n",
        "    print(f\"  Test Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
        "\n",
        "print(\"\\nAll models evaluated on test set\")\n",
        "\n",
        "# ==========================================\n",
        "# 8. STATISTICAL SUMMARY & ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 8/8] Computing statistical summary and analysis...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_aucs_array = np.array(test_aucs)\n",
        "test_accuracies_array = np.array(test_accuracies)\n",
        "\n",
        "# Calculate 95% confidence intervals (percentile-based)\n",
        "ci_95_lower = float(np.percentile(test_aucs_array, 2.5))\n",
        "ci_95_upper = float(np.percentile(test_aucs_array, 97.5))\n",
        "\n",
        "statistics = {\n",
        "    'mean_test_auc': float(np.mean(test_aucs_array)),\n",
        "    'std_test_auc': float(np.std(test_aucs_array, ddof=1)),\n",
        "    'min_test_auc': float(np.min(test_aucs_array)),\n",
        "    'max_test_auc': float(np.max(test_aucs_array)),\n",
        "    'median_test_auc': float(np.median(test_aucs_array)),\n",
        "    'ci_95_lower': ci_95_lower,\n",
        "    'ci_95_upper': ci_95_upper,\n",
        "    'best_run_index': int(np.argmax(test_aucs_array)),\n",
        "    'all_metrics_summary': {\n",
        "        'accuracy': {\n",
        "            'mean': float(np.mean(test_accuracies_array)),\n",
        "            'std': float(np.std(test_accuracies_array, ddof=1))\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Add all metrics summary\n",
        "for metric in ['precision_macro', 'recall_macro', 'f1_macro', 'log_loss']:\n",
        "    metric_values = [run['test_metrics'][metric] for run in test_results['test_results']['runs']]\n",
        "    statistics['all_metrics_summary'][metric] = {\n",
        "        'mean': float(np.mean(metric_values)),\n",
        "        'std': float(np.std(metric_values, ddof=1))\n",
        "    }\n",
        "\n",
        "test_results['test_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Test AUC statistics across 10 runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_test_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_test_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_test_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_test_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_test_auc']:.4f}\")\n",
        "print(f\"  95% CI: [{ci_95_lower:.4f}, {ci_95_upper:.4f}]\")\n",
        "\n",
        "print(\"\\nAll metrics summary:\")\n",
        "for metric, values in statistics['all_metrics_summary'].items():\n",
        "    print(f\"  {metric}: {values['mean']:.4f} Â± {values['std']:.4f}\")\n",
        "\n",
        "# Overfitting detection\n",
        "OVERFITTING_THRESHOLD = 0.03\n",
        "\n",
        "val_auc_mean = test_results['training_summary']['validation_auc_mean']\n",
        "test_auc_mean = statistics['mean_test_auc']\n",
        "overall_gap = val_auc_mean - test_auc_mean\n",
        "\n",
        "overfitting_runs = []\n",
        "for run in test_results['test_results']['runs']:\n",
        "    gap = run['generalization_gap']['auc_gap']\n",
        "    if gap > OVERFITTING_THRESHOLD:\n",
        "        overfitting_runs.append({\n",
        "            'run_id': run['run_id'],\n",
        "            'gap': gap,\n",
        "            'validation_auc': run['validation_metrics']['roc_auc'],\n",
        "            'test_auc': run['test_metrics']['roc_auc']\n",
        "        })\n",
        "\n",
        "overfitting_analysis = {\n",
        "    'threshold': OVERFITTING_THRESHOLD,\n",
        "    'overall_gap': float(overall_gap),\n",
        "    'overall_status': 'OVERFITTING' if overall_gap > OVERFITTING_THRESHOLD else 'GOOD_GENERALIZATION',\n",
        "    'n_overfitting_runs': len(overfitting_runs),\n",
        "    'overfitting_runs': overfitting_runs\n",
        "}\n",
        "\n",
        "test_results['overfitting_analysis'] = overfitting_analysis\n",
        "\n",
        "print(\"\\nOverfitting detection:\")\n",
        "print(f\"  Threshold: {OVERFITTING_THRESHOLD}\")\n",
        "print(f\"  Overall gap: {overall_gap:.4f}\")\n",
        "print(f\"  Status: {overfitting_analysis['overall_status']}\")\n",
        "\n",
        "if overfitting_runs:\n",
        "    print(f\"\\n  WARNING: {len(overfitting_runs)} run(s) show overfitting (gap > {OVERFITTING_THRESHOLD}):\")\n",
        "    for run in overfitting_runs:\n",
        "        print(f\"    Run {run['run_id']}: gap = {run['gap']:.4f} \"\n",
        "              f\"(val={run['validation_auc']:.4f}, test={run['test_auc']:.4f})\")\n",
        "else:\n",
        "    print(f\"\\n  All runs show good generalization (gap <= {OVERFITTING_THRESHOLD})\")\n",
        "\n",
        "# Best performance\n",
        "best_run_idx = statistics['best_run_index']\n",
        "best_run = test_results['test_results']['runs'][best_run_idx]\n",
        "\n",
        "test_results['best_performance'] = {\n",
        "    'run_id': best_run_idx,\n",
        "    'random_state': best_run['random_state'],\n",
        "    'n_features_used': optimal_k,\n",
        "    'test_auc': best_run['test_metrics']['roc_auc'],\n",
        "    'all_test_metrics': best_run['test_metrics'],\n",
        "    'validation_auc': best_run['validation_metrics']['roc_auc'],\n",
        "    'generalization_gap': best_run['generalization_gap']['auc_gap']\n",
        "}\n",
        "\n",
        "# Save results\n",
        "results_path = f\"{BASELINE_2_TESTING_DIR}/baseline_2_test_results_CPU.json\"\n",
        "save_results(test_results, results_path)\n",
        "\n",
        "print(f\"\\nTest results saved: {results_path}\")\n",
        "\n",
        "# Generate summary\n",
        "summary = {\n",
        "    'experiment': 'Baseline 2 Testing: XGBoost with SelectKBest',\n",
        "    'feature_selection': {\n",
        "        'method': 'SelectKBest (f_classif)',\n",
        "        'n_features_selected': optimal_k,\n",
        "        'feature_reduction_percent': round(feature_reduction_percent, 1)\n",
        "    },\n",
        "    'test_set_size': len(y_test),\n",
        "    'n_models_tested': len(loaded_models),\n",
        "    'performance': {\n",
        "        'validation_auc_mean': val_auc_mean,\n",
        "        'test_auc_mean': test_auc_mean,\n",
        "        'generalization_gap': overall_gap\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_idx,\n",
        "        'test_auc': best_run['test_metrics']['roc_auc']\n",
        "    },\n",
        "    'overfitting_status': overfitting_analysis['overall_status']\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_2_TESTING_DIR}/testing_summary.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Testing summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 2 TESTING COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nTEST SET EVALUATION:\")\n",
        "print(f\"  Method: XGBoost with SelectKBest feature selection\")\n",
        "print(f\"  Features: {optimal_k}/{X_test.shape[1]} features (reduction: {feature_reduction_percent:.1f}%)\")\n",
        "print(f\"  Test samples: {len(y_test)}\")\n",
        "print(f\"  Models tested: {len(loaded_models)}\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE (from training):\")\n",
        "print(f\"  Mean AUC: {val_auc_mean:.4f} Â± {test_results['training_summary']['validation_auc_std']:.4f}\")\n",
        "\n",
        "print(\"\\nTEST PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_test_auc']:.4f} Â± {statistics['std_test_auc']:.4f}\")\n",
        "print(f\"  95% CI: [{ci_95_lower:.4f}, {ci_95_upper:.4f}]\")\n",
        "print(f\"  Best AUC: {statistics['max_test_auc']:.4f} (Run {best_run_idx})\")\n",
        "print(f\"  AUC range: [{statistics['min_test_auc']:.4f}, {statistics['max_test_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nGENERALIZATION ANALYSIS:\")\n",
        "print(f\"  Overall gap (val - test): {overall_gap:.4f}\")\n",
        "print(f\"  Status: {overfitting_analysis['overall_status']}\")\n",
        "if overfitting_runs:\n",
        "    print(f\"  WARNING: {len(overfitting_runs)}/10 runs show overfitting\")\n",
        "else:\n",
        "    print(f\"  All runs generalize well\")\n",
        "\n",
        "print(\"\\nALL METRICS (Test Set):\")\n",
        "print(f\"  Accuracy:       {statistics['all_metrics_summary']['accuracy']['mean']:.4f} Â± {statistics['all_metrics_summary']['accuracy']['std']:.4f}\")\n",
        "print(f\"  Precision:      {statistics['all_metrics_summary']['precision_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['precision_macro']['std']:.4f}\")\n",
        "print(f\"  Recall:         {statistics['all_metrics_summary']['recall_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['recall_macro']['std']:.4f}\")\n",
        "print(f\"  F1-Score:       {statistics['all_metrics_summary']['f1_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['f1_macro']['std']:.4f}\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Test results: {results_path}\")\n",
        "print(f\"  Testing summary: {summary_path}\")\n",
        "print(f\"  Output directory: {BASELINE_2_TESTING_DIR}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 7: Baseline 3 Testing - RFECV test set evaluation\")\n",
        "print(\"  Cell 8: Comprehensive Comparison & Statistical Analysis\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR NEXT BASELINE TESTING\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "5p8tn8i0bWUp",
        "outputId": "36902453-226d-4dc9-c495-229c18e6b1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 2 TESTING: TEST SET EVALUATION\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/8] Verifying prerequisites...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Test data (397 samples x 25 features)\n",
            "VERIFIED: Test set integrity maintained\n",
            "\n",
            "[STEP 2/8] Loading training results from Cell 3...\n",
            "--------------------------------------------------\n",
            "Training results loaded: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/training/baseline_2_training_results.json\n",
            "Verified: 10 training runs completed\n",
            "Training mean validation AUC: 0.9964\n",
            "\n",
            "[STEP 3/8] Extracting feature selection details...\n",
            "--------------------------------------------------\n",
            "Feature selection method: SelectKBest (f_classif)\n",
            "Optimal k: 20\n",
            "Original features: 25\n",
            "Selected features: 20\n",
            "Feature reduction: 20.0%\n",
            "\n",
            "Selected features:\n",
            "   1. A1\n",
            "   2. A2\n",
            "   3. A3\n",
            "   4. A4\n",
            "   5. A5\n",
            "   6. A6\n",
            "   7. A7\n",
            "   8. A8\n",
            "   9. A9\n",
            "  10. Social_Responsiveness_Scale\n",
            "  ... and 10 more\n",
            "\n",
            "[STEP 4/8] Verifying feature consistency across runs...\n",
            "--------------------------------------------------\n",
            "VERIFIED: All runs used 20 features (deterministic selection)\n",
            "VERIFIED: All selected features available in test set\n",
            "\n",
            "[STEP 5/8] Transforming test set with selected features...\n",
            "--------------------------------------------------\n",
            "Original test set: 397 samples x 25 features\n",
            "Transformed test set: 397 samples x 20 features\n",
            "Feature selection applied successfully\n",
            "\n",
            "[STEP 6/8] Loading all trained models...\n",
            "--------------------------------------------------\n",
            "  Loaded: run_0_model.json\n",
            "  Loaded: run_1_model.json\n",
            "  Loaded: run_2_model.json\n",
            "  Loaded: run_3_model.json\n",
            "  Loaded: run_4_model.json\n",
            "  Loaded: run_5_model.json\n",
            "  Loaded: run_6_model.json\n",
            "  Loaded: run_7_model.json\n",
            "  Loaded: run_8_model.json\n",
            "  Loaded: run_9_model.json\n",
            "\n",
            "Successfully loaded all 10 models\n",
            "\n",
            "[STEP 7/8] Evaluating all models on test set...\n",
            "--------------------------------------------------\n",
            "\n",
            "Run 0:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0016\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 1:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 2:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 3:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 4:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 5:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 6:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 7:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 8:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 9:\n",
            "----------------------------------------\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9979\n",
            "  Gap:            -0.0015\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "All models evaluated on test set\n",
            "\n",
            "[STEP 8/8] Computing statistical summary and analysis...\n",
            "--------------------------------------------------\n",
            "Test AUC statistics across 10 runs:\n",
            "  Mean:   0.9979\n",
            "  Std:    0.0000\n",
            "  Min:    0.9979\n",
            "  Max:    0.9979\n",
            "  Median: 0.9979\n",
            "  95% CI: [0.9979, 0.9979]\n",
            "\n",
            "All metrics summary:\n",
            "  accuracy: 0.9572 Â± 0.0000\n",
            "  precision_macro: 0.9612 Â± 0.0000\n",
            "  recall_macro: 0.9541 Â± 0.0000\n",
            "  f1_macro: 0.9566 Â± 0.0000\n",
            "  log_loss: 0.0566 Â± 0.0008\n",
            "\n",
            "Overfitting detection:\n",
            "  Threshold: 0.03\n",
            "  Overall gap: -0.0015\n",
            "  Status: GOOD_GENERALIZATION\n",
            "\n",
            "  All runs show good generalization (gap <= 0.03)\n",
            "\n",
            "Test results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/testing/baseline_2_test_results_CPU.json\n",
            "Testing summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/testing/testing_summary.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 2 TESTING COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "TEST SET EVALUATION:\n",
            "  Method: XGBoost with SelectKBest feature selection\n",
            "  Features: 20/25 features (reduction: 20.0%)\n",
            "  Test samples: 397\n",
            "  Models tested: 10\n",
            "\n",
            "VALIDATION PERFORMANCE (from training):\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "\n",
            "TEST PERFORMANCE:\n",
            "  Mean AUC: 0.9979 Â± 0.0000\n",
            "  95% CI: [0.9979, 0.9979]\n",
            "  Best AUC: 0.9979 (Run 0)\n",
            "  AUC range: [0.9979, 0.9979]\n",
            "\n",
            "GENERALIZATION ANALYSIS:\n",
            "  Overall gap (val - test): -0.0015\n",
            "  Status: GOOD_GENERALIZATION\n",
            "  All runs generalize well\n",
            "\n",
            "ALL METRICS (Test Set):\n",
            "  Accuracy:       0.9572 Â± 0.0000\n",
            "  Precision:      0.9612 Â± 0.0000\n",
            "  Recall:         0.9541 Â± 0.0000\n",
            "  F1-Score:       0.9566 Â± 0.0000\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Test results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/testing/baseline_2_test_results_CPU.json\n",
            "  Testing summary: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/testing/testing_summary.json\n",
            "  Output directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_3_baseline2/testing\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 7: Baseline 3 Testing - RFECV test set evaluation\n",
            "  Cell 8: Comprehensive Comparison & Statistical Analysis\n",
            "\n",
            "================================================================================\n",
            "READY FOR NEXT BASELINE TESTING\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 7: Baseline 3 Testing - Test Set Evaluation (CPU)\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 7: Baseline 3 Testing - Test set evaluation for XGBoost with RFECV\n",
        "Evaluate all 10 trained models on held-out test set with selected features\n",
        "CPU-compatible version matching new training output structure\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 3 TESTING: TEST SET EVALUATION (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/8] Verifying prerequisites...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_test' in dir() and X_test.shape[0] == 397\n",
        "    assert 'y_test' in dir() and len(y_test) == 397\n",
        "    assert X_test.shape[1] == 25\n",
        "    print(f\"VERIFIED: Test data ({X_test.shape[0]} samples x {X_test.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Test set integrity maintained\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOAD TRAINING RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/8] Loading training results from Cell 4...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_3_TRAINING_DIR = \"/content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/training\"\n",
        "TESTING_DIR = \"/content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/testing\"\n",
        "os.makedirs(TESTING_DIR, exist_ok=True)\n",
        "\n",
        "training_results_path = f\"{BASELINE_3_TRAINING_DIR}/baseline_3_training_results.json\"\n",
        "\n",
        "if not os.path.exists(training_results_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Training results not found: {training_results_path}\\n\"\n",
        "        \"ERROR: Cell 4 (Baseline 3 Training) must be executed first\"\n",
        "    )\n",
        "\n",
        "with open(training_results_path, 'r') as f:\n",
        "    training_results = json.load(f)\n",
        "\n",
        "print(f\"Training results loaded: {training_results_path}\")\n",
        "\n",
        "# Verify training completed\n",
        "n_runs_trained = len(training_results['training_results']['runs'])\n",
        "successful_runs = training_results['training_results']['statistics'].get('successful_runs', n_runs_trained)\n",
        "\n",
        "if successful_runs == 0:\n",
        "    raise ValueError(\"No successful training runs found\")\n",
        "\n",
        "print(f\"Verified: {successful_runs}/{n_runs_trained} training runs completed successfully\")\n",
        "print(f\"Training mean validation AUC: {training_results['training_results']['statistics']['mean_val_auc']:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. EXTRACT FEATURE SELECTION DETAILS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/8] Extracting feature selection details...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Get feature selection statistics from training results\n",
        "stats = training_results['training_results']['statistics']\n",
        "mean_optimal_features = stats['mean_optimal_features']\n",
        "std_optimal_features = stats['std_optimal_features']\n",
        "\n",
        "print(f\"Feature selection method: RFECV (wrapper - model-guided)\")\n",
        "print(f\"Optimal features (mean): {mean_optimal_features:.1f} Â± {std_optimal_features:.1f}\")\n",
        "print(f\"Original features: {X_test.shape[1]}\")\n",
        "\n",
        "# Check if all runs selected same number of features\n",
        "feature_counts = [run['rfecv_results']['optimal_n_features']\n",
        "                  for run in training_results['training_results']['runs']]\n",
        "all_same_count = len(set(feature_counts)) == 1\n",
        "\n",
        "if all_same_count:\n",
        "    n_features_selected = feature_counts[0]\n",
        "    print(f\"All runs selected: {n_features_selected} features (100% stability)\")\n",
        "else:\n",
        "    n_features_selected = int(round(mean_optimal_features))\n",
        "    print(f\"Feature selection varies: {min(feature_counts)} to {max(feature_counts)} features\")\n",
        "    print(f\"Using mean: {n_features_selected} features\")\n",
        "\n",
        "feature_reduction_percent = (1 - mean_optimal_features / X_test.shape[1]) * 100\n",
        "print(f\"Feature reduction: {feature_reduction_percent:.1f}%\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. ANALYZE FEATURE STABILITY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/8] Analyzing feature stability across runs...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Extract selected features from each run\n",
        "all_selected_features = []\n",
        "for run in training_results['training_results']['runs']:\n",
        "    features = run['rfecv_results']['selected_features']\n",
        "    all_selected_features.append(set(features))\n",
        "\n",
        "# Count feature frequency\n",
        "feature_frequency = {}\n",
        "for feature_set in all_selected_features:\n",
        "    for feature in feature_set:\n",
        "        feature_frequency[feature] = feature_frequency.get(feature, 0) + 1\n",
        "\n",
        "# Sort by frequency\n",
        "sorted_features = sorted(feature_frequency.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Core features (appear in all runs)\n",
        "core_features = [f for f, freq in sorted_features if freq == len(all_selected_features)]\n",
        "\n",
        "print(f\"Feature stability analysis (across {len(all_selected_features)} runs):\")\n",
        "\n",
        "if core_features:\n",
        "    print(f\"  Core features (100% frequency): {len(core_features)} features\")\n",
        "    for i, feature in enumerate(core_features[:10], 1):\n",
        "        print(f\"    {i:2d}. {feature}\")\n",
        "    if len(core_features) > 10:\n",
        "        print(f\"    ... and {len(core_features) - 10} more\")\n",
        "else:\n",
        "    print(f\"  No core features (selection varies across runs)\")\n",
        "    print(f\"  Most frequent features:\")\n",
        "    for i, (feature, freq) in enumerate(sorted_features[:10], 1):\n",
        "        print(f\"    {i:2d}. {feature}: {freq}/{len(all_selected_features)} runs ({100*freq/len(all_selected_features):.0f}%)\")\n",
        "\n",
        "# Determine reference features for testing\n",
        "# Use most frequent features up to mean count\n",
        "reference_features = [f for f, _ in sorted_features[:n_features_selected]]\n",
        "\n",
        "print(f\"\\nUsing {len(reference_features)} most frequent features for evaluation\")\n",
        "\n",
        "# Verify reference features exist in test set\n",
        "missing_features = set(reference_features) - set(X_test.columns)\n",
        "if missing_features:\n",
        "    raise ValueError(f\"Reference features not in test set: {missing_features}\")\n",
        "\n",
        "print(f\"VERIFIED: All reference features available in test set\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. LOAD ALL TRAINED MODELS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/8] Loading all trained models...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "MODELS_DIR = f\"{BASELINE_3_TRAINING_DIR}/models\"\n",
        "\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    raise FileNotFoundError(f\"Models directory not found: {MODELS_DIR}\")\n",
        "\n",
        "loaded_models = []\n",
        "\n",
        "for run in training_results['training_results']['runs']:\n",
        "    run_id = run['run_id']\n",
        "\n",
        "    # Construct model path using updated MODELS_DIR (not from training results JSON)\n",
        "    model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "\n",
        "    # Check if model file exists\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"  WARNING: Model file not found: {model_path}\")\n",
        "        print(f\"  Skipping run {run_id}\")\n",
        "        continue\n",
        "\n",
        "    # Load model\n",
        "    try:\n",
        "        model = xgb.XGBClassifier()\n",
        "        model.load_model(model_path)\n",
        "\n",
        "        # Get selected features for this run\n",
        "        selected_features = run['rfecv_results']['selected_features']\n",
        "\n",
        "        loaded_models.append({\n",
        "            'run_id': run_id,\n",
        "            'model': model,\n",
        "            'model_path': model_path,\n",
        "            'selected_features': selected_features,\n",
        "            'n_features': len(selected_features)\n",
        "        })\n",
        "        print(f\"  Loaded: run_{run_id}_model.json ({len(selected_features)} features)\")\n",
        "    except Exception as e:\n",
        "        print(f\"  WARNING: Failed to load model {run_id}: {e}\")\n",
        "        print(f\"  Skipping run {run_id}\")\n",
        "        continue\n",
        "\n",
        "if len(loaded_models) == 0:\n",
        "    raise RuntimeError(\"No models could be loaded successfully\")\n",
        "\n",
        "print(f\"\\nSuccessfully loaded {len(loaded_models)}/{len(training_results['training_results']['runs'])} models\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. EVALUATE ALL MODELS ON TEST SET\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/8] Evaluating all models on test set...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 3 Testing: XGBoost with RFECV (CPU)',\n",
        "        'description': 'Test set evaluation for trained models with RFECV selected features',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'test_set_size': len(y_test),\n",
        "        'n_features_original': X_test.shape[1],\n",
        "        'n_features_mean': mean_optimal_features,\n",
        "        'compute_backend': 'CPU'\n",
        "    },\n",
        "    'feature_selection_summary': {\n",
        "        'method': 'RFECV (wrapper - model-guided)',\n",
        "        'mean_features_selected': mean_optimal_features,\n",
        "        'std_features_selected': std_optimal_features,\n",
        "        'feature_reduction_percent': round(feature_reduction_percent, 1),\n",
        "        'core_features_count': len(core_features),\n",
        "        'core_features': core_features\n",
        "    },\n",
        "    'training_summary': {\n",
        "        'n_runs': n_runs_trained,\n",
        "        'successful_runs': successful_runs,\n",
        "        'validation_auc_mean': stats['mean_val_auc'],\n",
        "        'validation_auc_std': stats['std_val_auc']\n",
        "    },\n",
        "    'test_results': {\n",
        "        'runs': []\n",
        "    }\n",
        "}\n",
        "\n",
        "test_aucs = []\n",
        "test_accuracies = []\n",
        "\n",
        "for model_info in loaded_models:\n",
        "    run_id = model_info['run_id']\n",
        "    model = model_info['model']\n",
        "    selected_features = model_info['selected_features']\n",
        "    n_features = model_info['n_features']\n",
        "\n",
        "    print(f\"\\nRun {run_id}:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Get validation results from training\n",
        "    training_run = next(r for r in training_results['training_results']['runs'] if r['run_id'] == run_id)\n",
        "    val_metrics = training_run['validation_metrics']\n",
        "\n",
        "    # Transform test set with this run's selected features\n",
        "    X_test_selected = X_test[selected_features]\n",
        "\n",
        "    # Predict on test set\n",
        "    y_test_pred = model.predict(X_test_selected)\n",
        "    y_test_proba = model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "    # Calculate test metrics\n",
        "    test_metrics = calculate_metrics(y_test, y_test_pred, y_test_proba)\n",
        "\n",
        "    # Store results\n",
        "    run_result = {\n",
        "        'run_id': run_id,\n",
        "        'random_state': training_run['random_state'],\n",
        "        'n_features_used': n_features,\n",
        "        'validation_metrics': val_metrics,\n",
        "        'test_metrics': test_metrics,\n",
        "        'generalization_gap': {\n",
        "            'auc_gap': float(val_metrics['roc_auc'] - test_metrics['roc_auc']),\n",
        "            'accuracy_gap': float(val_metrics['accuracy'] - test_metrics['accuracy'])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    test_results['test_results']['runs'].append(run_result)\n",
        "    test_aucs.append(test_metrics['roc_auc'])\n",
        "    test_accuracies.append(test_metrics['accuracy'])\n",
        "\n",
        "    print(f\"  Features used:  {n_features}\")\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Test AUC:       {test_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Gap:            {run_result['generalization_gap']['auc_gap']:.4f}\")\n",
        "    print(f\"  Test Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nAll {len(loaded_models)} models evaluated on test set\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. STATISTICAL SUMMARY & ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/8] Computing statistical summary and analysis...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_aucs_array = np.array(test_aucs)\n",
        "test_accuracies_array = np.array(test_accuracies)\n",
        "\n",
        "# Calculate 95% confidence intervals\n",
        "ci_95_lower = float(np.percentile(test_aucs_array, 2.5))\n",
        "ci_95_upper = float(np.percentile(test_aucs_array, 97.5))\n",
        "\n",
        "statistics = {\n",
        "    'mean_test_auc': float(np.mean(test_aucs_array)),\n",
        "    'std_test_auc': float(np.std(test_aucs_array, ddof=1)),\n",
        "    'min_test_auc': float(np.min(test_aucs_array)),\n",
        "    'max_test_auc': float(np.max(test_aucs_array)),\n",
        "    'median_test_auc': float(np.median(test_aucs_array)),\n",
        "    'ci_95_lower': ci_95_lower,\n",
        "    'ci_95_upper': ci_95_upper,\n",
        "    'best_run_index': int(np.argmax(test_aucs_array)),\n",
        "    'models_evaluated': len(loaded_models),\n",
        "    'all_metrics_summary': {\n",
        "        'accuracy': {\n",
        "            'mean': float(np.mean(test_accuracies_array)),\n",
        "            'std': float(np.std(test_accuracies_array, ddof=1))\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Add all metrics summary\n",
        "for metric in ['precision_macro', 'recall_macro', 'f1_macro', 'log_loss']:\n",
        "    metric_values = [run['test_metrics'][metric] for run in test_results['test_results']['runs']]\n",
        "    statistics['all_metrics_summary'][metric] = {\n",
        "        'mean': float(np.mean(metric_values)),\n",
        "        'std': float(np.std(metric_values, ddof=1))\n",
        "    }\n",
        "\n",
        "test_results['test_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Test AUC statistics across evaluated runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_test_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_test_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_test_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_test_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_test_auc']:.4f}\")\n",
        "print(f\"  95% CI: [{ci_95_lower:.4f}, {ci_95_upper:.4f}]\")\n",
        "\n",
        "print(\"\\nAll metrics summary (Test Set):\")\n",
        "for metric, values in statistics['all_metrics_summary'].items():\n",
        "    print(f\"  {metric:20s}: {values['mean']:.4f} Â± {values['std']:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 8. GENERALIZATION ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 8/8] Analyzing generalization performance...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "OVERFITTING_THRESHOLD = 0.03\n",
        "\n",
        "val_auc_mean = test_results['training_summary']['validation_auc_mean']\n",
        "test_auc_mean = statistics['mean_test_auc']\n",
        "overall_gap = val_auc_mean - test_auc_mean\n",
        "\n",
        "overfitting_runs = []\n",
        "for run in test_results['test_results']['runs']:\n",
        "    gap = run['generalization_gap']['auc_gap']\n",
        "    if gap > OVERFITTING_THRESHOLD:\n",
        "        overfitting_runs.append({\n",
        "            'run_id': run['run_id'],\n",
        "            'gap': gap,\n",
        "            'validation_auc': run['validation_metrics']['roc_auc'],\n",
        "            'test_auc': run['test_metrics']['roc_auc']\n",
        "        })\n",
        "\n",
        "overfitting_analysis = {\n",
        "    'threshold': OVERFITTING_THRESHOLD,\n",
        "    'overall_gap': float(overall_gap),\n",
        "    'overall_status': 'OVERFITTING' if overall_gap > OVERFITTING_THRESHOLD else 'GOOD_GENERALIZATION',\n",
        "    'n_overfitting_runs': len(overfitting_runs),\n",
        "    'overfitting_runs': overfitting_runs\n",
        "}\n",
        "\n",
        "test_results['overfitting_analysis'] = overfitting_analysis\n",
        "\n",
        "print(\"Generalization analysis:\")\n",
        "print(f\"  Threshold: {OVERFITTING_THRESHOLD}\")\n",
        "print(f\"  Overall gap (val - test): {overall_gap:.4f}\")\n",
        "print(f\"  Status: {overfitting_analysis['overall_status']}\")\n",
        "\n",
        "if overfitting_runs:\n",
        "    print(f\"\\n  WARNING: {len(overfitting_runs)} run(s) show overfitting (gap > {OVERFITTING_THRESHOLD}):\")\n",
        "    for run in overfitting_runs:\n",
        "        print(f\"    Run {run['run_id']}: gap = {run['gap']:.4f} \"\n",
        "              f\"(val={run['validation_auc']:.4f}, test={run['test_auc']:.4f})\")\n",
        "else:\n",
        "    print(f\"\\n  All runs show good generalization (gap <= {OVERFITTING_THRESHOLD})\")\n",
        "\n",
        "# Best performance\n",
        "best_run_idx_in_tested = statistics['best_run_index']\n",
        "best_run = test_results['test_results']['runs'][best_run_idx_in_tested]\n",
        "\n",
        "test_results['best_performance'] = {\n",
        "    'run_id': best_run['run_id'],\n",
        "    'random_state': best_run['random_state'],\n",
        "    'n_features_used': best_run['n_features_used'],\n",
        "    'test_auc': best_run['test_metrics']['roc_auc'],\n",
        "    'all_test_metrics': best_run['test_metrics'],\n",
        "    'validation_auc': best_run['validation_metrics']['roc_auc'],\n",
        "    'generalization_gap': best_run['generalization_gap']['auc_gap']\n",
        "}\n",
        "\n",
        "# Save results\n",
        "results_path = f\"{TESTING_DIR}/baseline_3_test_results.json\"\n",
        "save_results(test_results, results_path)\n",
        "\n",
        "print(f\"\\nTest results saved: {results_path}\")\n",
        "\n",
        "# Generate summary\n",
        "summary = {\n",
        "    'experiment': 'Baseline 3 Testing: XGBoost with RFECV (CPU)',\n",
        "    'feature_selection': {\n",
        "        'method': 'RFECV (wrapper - model-guided)',\n",
        "        'mean_features_selected': mean_optimal_features,\n",
        "        'std_features_selected': std_optimal_features,\n",
        "        'feature_reduction_percent': round(feature_reduction_percent, 1)\n",
        "    },\n",
        "    'test_set_size': len(y_test),\n",
        "    'n_models_tested': len(loaded_models),\n",
        "    'compute_backend': 'CPU',\n",
        "    'performance': {\n",
        "        'validation_auc_mean': val_auc_mean,\n",
        "        'test_auc_mean': test_auc_mean,\n",
        "        'generalization_gap': overall_gap\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run['run_id'],\n",
        "        'test_auc': best_run['test_metrics']['roc_auc']\n",
        "    },\n",
        "    'overfitting_status': overfitting_analysis['overall_status']\n",
        "}\n",
        "\n",
        "summary_path = f\"{TESTING_DIR}/testing_summary.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Testing summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 3 TESTING COMPLETED SUCCESSFULLY (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nTEST SET EVALUATION:\")\n",
        "print(f\"  Method: XGBoost with RFECV feature selection\")\n",
        "print(f\"  Features (mean): {mean_optimal_features:.1f} Â± {std_optimal_features:.1f}\")\n",
        "print(f\"  Feature reduction: {feature_reduction_percent:.1f}%\")\n",
        "print(f\"  Test samples: {len(y_test)}\")\n",
        "print(f\"  Models tested: {len(loaded_models)}/{n_runs_trained}\")\n",
        "print(f\"  Compute backend: CPU\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE (from training):\")\n",
        "print(f\"  Mean AUC: {val_auc_mean:.4f} Â± {test_results['training_summary']['validation_auc_std']:.4f}\")\n",
        "\n",
        "print(\"\\nTEST PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_test_auc']:.4f} Â± {statistics['std_test_auc']:.4f}\")\n",
        "print(f\"  95% CI: [{ci_95_lower:.4f}, {ci_95_upper:.4f}]\")\n",
        "print(f\"  Best AUC: {statistics['max_test_auc']:.4f} (Run {best_run['run_id']})\")\n",
        "print(f\"  AUC range: [{statistics['min_test_auc']:.4f}, {statistics['max_test_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nGENERALIZATION ANALYSIS:\")\n",
        "print(f\"  Overall gap (val - test): {overall_gap:.4f}\")\n",
        "print(f\"  Status: {overfitting_analysis['overall_status']}\")\n",
        "if overfitting_runs:\n",
        "    print(f\"  WARNING: {len(overfitting_runs)}/{len(loaded_models)} runs show overfitting\")\n",
        "else:\n",
        "    print(f\"  All runs generalize well\")\n",
        "\n",
        "print(\"\\nALL METRICS (Test Set):\")\n",
        "print(f\"  Accuracy:       {statistics['all_metrics_summary']['accuracy']['mean']:.4f} Â± {statistics['all_metrics_summary']['accuracy']['std']:.4f}\")\n",
        "print(f\"  Precision:      {statistics['all_metrics_summary']['precision_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['precision_macro']['std']:.4f}\")\n",
        "print(f\"  Recall:         {statistics['all_metrics_summary']['recall_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['recall_macro']['std']:.4f}\")\n",
        "print(f\"  F1-Score:       {statistics['all_metrics_summary']['f1_macro']['mean']:.4f} Â± {statistics['all_metrics_summary']['f1_macro']['std']:.4f}\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Test results: {results_path}\")\n",
        "print(f\"  Testing summary: {summary_path}\")\n",
        "print(f\"  Output directory: {TESTING_DIR}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 8: Comprehensive Comparison & Statistical Analysis\")\n",
        "print(\"  Compare all three baselines (Baseline 1, 2, 3)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 3 TESTING READY FOR COMPARISON\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "s7B7CuOsitpJ",
        "outputId": "34b5f0f5-d284-4b17-b3f1-490db76de700",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 3 TESTING: TEST SET EVALUATION (CPU)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/8] Verifying prerequisites...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Test data (397 samples x 25 features)\n",
            "VERIFIED: Test set integrity maintained\n",
            "\n",
            "[STEP 2/8] Loading training results from Cell 4...\n",
            "--------------------------------------------------\n",
            "Training results loaded: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/training/baseline_3_training_results.json\n",
            "Verified: 10/10 training runs completed successfully\n",
            "Training mean validation AUC: 0.9964\n",
            "\n",
            "[STEP 3/8] Extracting feature selection details...\n",
            "--------------------------------------------------\n",
            "Feature selection method: RFECV (wrapper - model-guided)\n",
            "Optimal features (mean): 25.0 Â± 0.0\n",
            "Original features: 25\n",
            "All runs selected: 25 features (100% stability)\n",
            "Feature reduction: 0.0%\n",
            "\n",
            "[STEP 4/8] Analyzing feature stability across runs...\n",
            "--------------------------------------------------\n",
            "Feature stability analysis (across 10 runs):\n",
            "  Core features (100% frequency): 25 features\n",
            "     1. A5\n",
            "     2. Social/Behavioural Issues\n",
            "     3. A9\n",
            "     4. Speech Delay/Language Disorder\n",
            "     5. Jaundice\n",
            "     6. Genetic_Disorders\n",
            "     7. Depression\n",
            "     8. Age_Years\n",
            "     9. Family_mem_with_ASD\n",
            "    10. Childhood Autism Rating Scale\n",
            "    ... and 15 more\n",
            "\n",
            "Using 25 most frequent features for evaluation\n",
            "VERIFIED: All reference features available in test set\n",
            "\n",
            "[STEP 5/8] Loading all trained models...\n",
            "--------------------------------------------------\n",
            "  Loaded: run_0_model.json (25 features)\n",
            "  Loaded: run_1_model.json (25 features)\n",
            "  Loaded: run_2_model.json (25 features)\n",
            "  Loaded: run_3_model.json (25 features)\n",
            "  Loaded: run_4_model.json (25 features)\n",
            "  Loaded: run_5_model.json (25 features)\n",
            "  Loaded: run_6_model.json (25 features)\n",
            "  Loaded: run_7_model.json (25 features)\n",
            "  Loaded: run_8_model.json (25 features)\n",
            "  Loaded: run_9_model.json (25 features)\n",
            "\n",
            "Successfully loaded 10/10 models\n",
            "\n",
            "[STEP 6/8] Evaluating all models on test set...\n",
            "--------------------------------------------------\n",
            "\n",
            "Run 0:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 1:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9982\n",
            "  Gap:            -0.0018\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 2:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9982\n",
            "  Gap:            -0.0018\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 3:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 4:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 5:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 6:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 7:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9982\n",
            "  Gap:            -0.0018\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 8:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9981\n",
            "  Gap:            -0.0017\n",
            "  Test Accuracy:  0.9572\n",
            "\n",
            "Run 9:\n",
            "----------------------------------------\n",
            "  Features used:  25\n",
            "  Validation AUC: 0.9964\n",
            "  Test AUC:       0.9983\n",
            "  Gap:            -0.0019\n",
            "  Test Accuracy:  0.9597\n",
            "\n",
            "All 10 models evaluated on test set\n",
            "\n",
            "[STEP 7/8] Computing statistical summary and analysis...\n",
            "--------------------------------------------------\n",
            "Test AUC statistics across evaluated runs:\n",
            "  Mean:   0.9981\n",
            "  Std:    0.0001\n",
            "  Min:    0.9981\n",
            "  Max:    0.9983\n",
            "  Median: 0.9981\n",
            "  95% CI: [0.9981, 0.9983]\n",
            "\n",
            "All metrics summary (Test Set):\n",
            "  accuracy            : 0.9574 Â± 0.0008\n",
            "  precision_macro     : 0.9624 Â± 0.0006\n",
            "  recall_macro        : 0.9540 Â± 0.0009\n",
            "  f1_macro            : 0.9568 Â± 0.0008\n",
            "  log_loss            : 0.0542 Â± 0.0009\n",
            "\n",
            "[STEP 8/8] Analyzing generalization performance...\n",
            "--------------------------------------------------\n",
            "Generalization analysis:\n",
            "  Threshold: 0.03\n",
            "  Overall gap (val - test): -0.0017\n",
            "  Status: GOOD_GENERALIZATION\n",
            "\n",
            "  All runs show good generalization (gap <= 0.03)\n",
            "\n",
            "Test results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/testing/baseline_3_test_results.json\n",
            "Testing summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/testing/testing_summary.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 3 TESTING COMPLETED SUCCESSFULLY (CPU)\n",
            "================================================================================\n",
            "\n",
            "TEST SET EVALUATION:\n",
            "  Method: XGBoost with RFECV feature selection\n",
            "  Features (mean): 25.0 Â± 0.0\n",
            "  Feature reduction: 0.0%\n",
            "  Test samples: 397\n",
            "  Models tested: 10/10\n",
            "  Compute backend: CPU\n",
            "\n",
            "VALIDATION PERFORMANCE (from training):\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "\n",
            "TEST PERFORMANCE:\n",
            "  Mean AUC: 0.9981 Â± 0.0001\n",
            "  95% CI: [0.9981, 0.9983]\n",
            "  Best AUC: 0.9983 (Run 9)\n",
            "  AUC range: [0.9981, 0.9983]\n",
            "\n",
            "GENERALIZATION ANALYSIS:\n",
            "  Overall gap (val - test): -0.0017\n",
            "  Status: GOOD_GENERALIZATION\n",
            "  All runs generalize well\n",
            "\n",
            "ALL METRICS (Test Set):\n",
            "  Accuracy:       0.9574 Â± 0.0008\n",
            "  Precision:      0.9624 Â± 0.0006\n",
            "  Recall:         0.9540 Â± 0.0009\n",
            "  F1-Score:       0.9568 Â± 0.0008\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Test results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/testing/baseline_3_test_results.json\n",
            "  Testing summary: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/testing/testing_summary.json\n",
            "  Output directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_4_baseline3/testing\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 8: Comprehensive Comparison & Statistical Analysis\n",
            "  Compare all three baselines (Baseline 1, 2, 3)\n",
            "\n",
            "================================================================================\n",
            "BASELINE 3 TESTING READY FOR COMPARISON\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "try cpu"
      ],
      "metadata": {
        "id": "viSxVNod-_Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 2: Baseline 1 Training - XGBoost with All Features (CPU)\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 2: Baseline 1 - XGBoost trained with all features (no feature selection)\n",
        "10 independent runs with unified XGBoost configuration\n",
        "CPU-compatible implementation for reproducibility\n",
        "Control group for feature selection comparison\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 1 TRAINING: XGBOOST WITH ALL FEATURES (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/7] Verifying Cell 1 completion...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_train' in dir() and X_train.shape[1] == 25\n",
        "    assert 'X_val' in dir() and X_val.shape[0] == 318\n",
        "    assert 'CONFIG' in dir() and CONFIG['n_runs'] == 10\n",
        "    print(f\"VERIFIED: Training data ({X_train.shape[0]} samples x {X_train.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Validation data ({X_val.shape[0]} samples)\")\n",
        "    print(f\"VERIFIED: Number of runs = {CONFIG['n_runs']}\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. CPU-COMPATIBLE XGBOOST CONFIG\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/7] Setting up CPU-compatible XGBoost configuration...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# CPU-compatible unified configuration\n",
        "XGBOOST_UNIFIED_CONFIG_CPU = {\n",
        "    'n_estimators': 500,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'tree_method': 'hist',              # CPU-compatible histogram method\n",
        "    'predictor': 'cpu_predictor',       # Explicit CPU predictor\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42  # Will be overridden per run\n",
        "}\n",
        "\n",
        "print(\"CPU-compatible XGBoost configuration:\")\n",
        "print(f\"  tree_method: {XGBOOST_UNIFIED_CONFIG_CPU['tree_method']}\")\n",
        "print(f\"  predictor: {XGBOOST_UNIFIED_CONFIG_CPU['predictor']}\")\n",
        "print(f\"  n_estimators: {XGBOOST_UNIFIED_CONFIG_CPU['n_estimators']}\")\n",
        "print(f\"  max_depth: {XGBOOST_UNIFIED_CONFIG_CPU['max_depth']}\")\n",
        "print(f\"  learning_rate: {XGBOOST_UNIFIED_CONFIG_CPU['learning_rate']}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. EXPERIMENT SETUP\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/7] Setting up Baseline 1 experiment...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_1_DIR = f\"{PROJECT_PATHS['baseline_results']}/baseline_1_all_features\"\n",
        "MODELS_DIR = f\"{BASELINE_1_DIR}/models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Experiment directory: {BASELINE_1_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n",
        "\n",
        "print(\"\\nExperiment configuration:\")\n",
        "print(f\"  Method: No feature selection (all {X_train.shape[1]} features)\")\n",
        "print(f\"  Number of runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Random seeds: {CONFIG['random_state']} to {CONFIG['random_state'] + CONFIG['n_runs'] - 1}\")\n",
        "print(f\"  Hardware: CPU-based computation\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAINING LOOP - 10 INDEPENDENT RUNS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/7] Training 10 independent models...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "training_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 1: XGBoost with All Features (CPU)',\n",
        "        'description': 'Control group - no feature selection applied, CPU implementation',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'n_runs': CONFIG['n_runs'],\n",
        "        'gpu_available': False,\n",
        "        'compute_backend': 'CPU'\n",
        "    },\n",
        "    'configuration': {\n",
        "        'xgboost_config': XGBOOST_UNIFIED_CONFIG_CPU,\n",
        "        'n_features': X_train.shape[1],\n",
        "        'feature_names': X_train.columns.tolist()\n",
        "    },\n",
        "    'training_results': {\n",
        "        'runs': [],\n",
        "        'statistics': {}\n",
        "    },\n",
        "    'best_model': {}\n",
        "}\n",
        "\n",
        "start_time_total = time.time()\n",
        "validation_aucs = []\n",
        "\n",
        "for run_id in range(CONFIG['n_runs']):\n",
        "    print(f\"\\nRun {run_id + 1}/{CONFIG['n_runs']} (seed={CONFIG['random_state'] + run_id})\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    start_time_run = time.time()\n",
        "\n",
        "    # Initialize model with unique random seed\n",
        "    model_config = XGBOOST_UNIFIED_CONFIG_CPU.copy()\n",
        "    model_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "    model = xgb.XGBClassifier(**model_config)\n",
        "\n",
        "    # Train on all features\n",
        "    print(f\"  Training on {X_train.shape[1]} features...\")\n",
        "    model.fit(X_train, y_train, verbose=False)\n",
        "\n",
        "    # Predict on validation set\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time_run\n",
        "\n",
        "    # Save model\n",
        "    model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "    model.save_model(model_path)\n",
        "\n",
        "    # Store results\n",
        "    run_result = {\n",
        "        'run_id': run_id,\n",
        "        'random_state': CONFIG['random_state'] + run_id,\n",
        "        'training_time_seconds': round(training_time, 2),\n",
        "        'validation_metrics': val_metrics,\n",
        "        'model_path': model_path\n",
        "    }\n",
        "\n",
        "    training_results['training_results']['runs'].append(run_result)\n",
        "    validation_aucs.append(val_metrics['roc_auc'])\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.2f}s\")\n",
        "    print(f\"  Model saved: {model_path}\")\n",
        "\n",
        "total_training_time = time.time() - start_time_total\n",
        "\n",
        "print(f\"\\nTotal training time: {total_training_time:.2f}s ({total_training_time/60:.2f} min)\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. STATISTICAL SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/7] Computing statistical summary...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "validation_aucs_array = np.array(validation_aucs)\n",
        "\n",
        "statistics = {\n",
        "    'mean_val_auc': float(np.mean(validation_aucs_array)),\n",
        "    'std_val_auc': float(np.std(validation_aucs_array, ddof=1)),\n",
        "    'min_val_auc': float(np.min(validation_aucs_array)),\n",
        "    'max_val_auc': float(np.max(validation_aucs_array)),\n",
        "    'median_val_auc': float(np.median(validation_aucs_array)),\n",
        "    'best_run_id': int(np.argmax(validation_aucs_array)),\n",
        "    'total_training_time_seconds': round(total_training_time, 2)\n",
        "}\n",
        "\n",
        "training_results['training_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Validation AUC statistics across 10 runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_val_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_val_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_val_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_val_auc']:.4f}\")\n",
        "print(f\"\\nBest run: Run {statistics['best_run_id']} \"\n",
        "      f\"(AUC = {statistics['max_val_auc']:.4f})\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. IDENTIFY AND SAVE BEST MODEL\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/7] Saving best model...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_run_id = statistics['best_run_id']\n",
        "best_run_result = training_results['training_results']['runs'][best_run_id]\n",
        "\n",
        "# Load and save best model separately\n",
        "best_model = xgb.XGBClassifier()\n",
        "best_model.load_model(best_run_result['model_path'])\n",
        "\n",
        "best_model_path = f\"{BASELINE_1_DIR}/baseline_1_best_model.json\"\n",
        "best_model.save_model(best_model_path)\n",
        "\n",
        "training_results['best_model'] = {\n",
        "    'run_id': best_run_id,\n",
        "    'random_state': best_run_result['random_state'],\n",
        "    'validation_auc': best_run_result['validation_metrics']['roc_auc'],\n",
        "    'validation_metrics': best_run_result['validation_metrics'],\n",
        "    'model_path': best_model_path\n",
        "}\n",
        "\n",
        "print(f\"Best model: Run {best_run_id}\")\n",
        "print(f\"  Validation AUC: {best_run_result['validation_metrics']['roc_auc']:.4f}\")\n",
        "print(f\"  Validation Accuracy: {best_run_result['validation_metrics']['accuracy']:.4f}\")\n",
        "print(f\"  Saved to: {best_model_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. FEATURE IMPORTANCE ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/7] Analyzing feature importance (best model)...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "feature_importance = best_model.feature_importances_\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 most important features:\")\n",
        "for idx, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
        "    print(f\"  {idx:2d}. {row['feature']:<25s} {row['importance']:.4f}\")\n",
        "\n",
        "importance_csv_path = f\"{BASELINE_1_DIR}/feature_importance.csv\"\n",
        "importance_df.to_csv(importance_csv_path, index=False)\n",
        "print(f\"\\nFeature importance saved: {importance_csv_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 8. SAVE TRAINING RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 8/7] Saving training results...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "results_path = f\"{BASELINE_1_DIR}/baseline_1_training_results_CPU.json\"\n",
        "save_results(training_results, results_path)\n",
        "\n",
        "print(f\"Training results saved: {results_path}\")\n",
        "\n",
        "# Generate summary statistics file\n",
        "summary = {\n",
        "    'experiment': 'Baseline 1: XGBoost with All Features (CPU)',\n",
        "    'n_features': X_train.shape[1],\n",
        "    'n_runs': CONFIG['n_runs'],\n",
        "    'compute_backend': 'CPU',\n",
        "    'validation_auc': {\n",
        "        'mean': statistics['mean_val_auc'],\n",
        "        'std': statistics['std_val_auc'],\n",
        "        'range': [statistics['min_val_auc'], statistics['max_val_auc']]\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_id,\n",
        "        'validation_auc': statistics['max_val_auc']\n",
        "    },\n",
        "    'training_time_total_minutes': round(total_training_time / 60, 2)\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_1_DIR}/training_summary_CPU.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Training summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 1 TRAINING COMPLETED SUCCESSFULLY (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nEXPERIMENT SUMMARY:\")\n",
        "print(f\"  Method: XGBoost with all features (no selection)\")\n",
        "print(f\"  Features used: {X_train.shape[1]} features\")\n",
        "print(f\"  Training runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Compute backend: CPU (tree_method='hist')\")\n",
        "print(f\"  Total training time: {total_training_time/60:.2f} minutes\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_val_auc']:.4f} Â± {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Best AUC: {statistics['max_val_auc']:.4f} (Run {best_run_id})\")\n",
        "print(f\"  AUC range: [{statistics['min_val_auc']:.4f}, {statistics['max_val_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Training results: {results_path}\")\n",
        "print(f\"  Best model: {best_model_path}\")\n",
        "print(f\"  All models: {MODELS_DIR}/ (10 models)\")\n",
        "print(f\"  Feature importance: {importance_csv_path}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 3: Baseline 2 - XGBoost with SelectKBest (CPU)\")\n",
        "print(\"  Cell 5: Baseline 1 Testing - Test set evaluation\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR NEXT BASELINE EXPERIMENT\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "6GQVDoIj_B8w",
        "outputId": "40fbec6b-1cd5-4622-dfb0-5bbcc39513e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 1 TRAINING: XGBOOST WITH ALL FEATURES (CPU)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/7] Verifying Cell 1 completion...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Training data (1270 samples x 25 features)\n",
            "VERIFIED: Validation data (318 samples)\n",
            "VERIFIED: Number of runs = 10\n",
            "\n",
            "[STEP 2/7] Setting up CPU-compatible XGBoost configuration...\n",
            "--------------------------------------------------\n",
            "CPU-compatible XGBoost configuration:\n",
            "  tree_method: hist\n",
            "  predictor: cpu_predictor\n",
            "  n_estimators: 500\n",
            "  max_depth: 8\n",
            "  learning_rate: 0.05\n",
            "\n",
            "[STEP 3/7] Setting up Baseline 1 experiment...\n",
            "--------------------------------------------------\n",
            "Experiment directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features\n",
            "Models directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models\n",
            "\n",
            "Experiment configuration:\n",
            "  Method: No feature selection (all 25 features)\n",
            "  Number of runs: 10\n",
            "  Random seeds: 42 to 51\n",
            "  Hardware: CPU-based computation\n",
            "\n",
            "[STEP 4/7] Training 10 independent models...\n",
            "--------------------------------------------------\n",
            "\n",
            "Run 1/10 (seed=42)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.82s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_0_model.json\n",
            "\n",
            "Run 2/10 (seed=43)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.73s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_1_model.json\n",
            "\n",
            "Run 3/10 (seed=44)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.27s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_2_model.json\n",
            "\n",
            "Run 4/10 (seed=45)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.23s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_3_model.json\n",
            "\n",
            "Run 5/10 (seed=46)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.22s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_4_model.json\n",
            "\n",
            "Run 6/10 (seed=47)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.22s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_5_model.json\n",
            "\n",
            "Run 7/10 (seed=48)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.28s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_6_model.json\n",
            "\n",
            "Run 8/10 (seed=49)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.23s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_7_model.json\n",
            "\n",
            "Run 9/10 (seed=50)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.22s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_8_model.json\n",
            "\n",
            "Run 10/10 (seed=51)\n",
            "----------------------------------------\n",
            "  Training on 25 features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.22s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/run_9_model.json\n",
            "\n",
            "Total training time: 3.69s (0.06 min)\n",
            "\n",
            "[STEP 5/7] Computing statistical summary...\n",
            "--------------------------------------------------\n",
            "Validation AUC statistics across 10 runs:\n",
            "  Mean:   0.9964\n",
            "  Std:    0.0000\n",
            "  Min:    0.9964\n",
            "  Max:    0.9964\n",
            "  Median: 0.9964\n",
            "\n",
            "Best run: Run 1 (AUC = 0.9964)\n",
            "\n",
            "[STEP 6/7] Saving best model...\n",
            "--------------------------------------------------\n",
            "Best model: Run 1\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Saved to: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/baseline_1_best_model.json\n",
            "\n",
            "[STEP 7/7] Analyzing feature importance (best model)...\n",
            "--------------------------------------------------\n",
            "\n",
            "Top 10 most important features:\n",
            "   1. A9                        0.1390\n",
            "   2. Speech Delay/Language Disorder 0.1357\n",
            "   3. Sex                       0.1296\n",
            "   4. Qchat_10_Score            0.0683\n",
            "   5. Depression                0.0673\n",
            "   6. A7                        0.0580\n",
            "   7. A5                        0.0473\n",
            "   8. A6                        0.0460\n",
            "   9. Learning disorder         0.0449\n",
            "  10. A2                        0.0412\n",
            "\n",
            "Feature importance saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/feature_importance.csv\n",
            "\n",
            "[STEP 8/7] Saving training results...\n",
            "--------------------------------------------------\n",
            "Training results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/baseline_1_training_results_CPU.json\n",
            "Training summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/training_summary_CPU.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 1 TRAINING COMPLETED SUCCESSFULLY (CPU)\n",
            "================================================================================\n",
            "\n",
            "EXPERIMENT SUMMARY:\n",
            "  Method: XGBoost with all features (no selection)\n",
            "  Features used: 25 features\n",
            "  Training runs: 10\n",
            "  Compute backend: CPU (tree_method='hist')\n",
            "  Total training time: 0.06 minutes\n",
            "\n",
            "VALIDATION PERFORMANCE:\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "  Best AUC: 0.9964 (Run 1)\n",
            "  AUC range: [0.9964, 0.9964]\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Training results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/baseline_1_training_results_CPU.json\n",
            "  Best model: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/baseline_1_best_model.json\n",
            "  All models: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/models/ (10 models)\n",
            "  Feature importance: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_1_all_features/feature_importance.csv\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 3: Baseline 2 - XGBoost with SelectKBest (CPU)\n",
            "  Cell 5: Baseline 1 Testing - Test set evaluation\n",
            "\n",
            "================================================================================\n",
            "READY FOR NEXT BASELINE EXPERIMENT\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 3: Baseline 2 Training - XGBoost with SelectKBest (CPU)\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 3: Baseline 2 - XGBoost with SelectKBest (Filter Method)\n",
        "Phase 1: K-value optimization (k=[8,12,16,20])\n",
        "Phase 2: 10 independent runs with optimal k\n",
        "CPU-compatible implementation for reproducibility\n",
        "Statistical feature selection using ANOVA F-test\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 2 TRAINING: XGBOOST WITH SELECTKBEST (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/8] Verifying Cell 1 completion...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_train' in dir() and X_train.shape[1] == 25\n",
        "    assert 'X_val' in dir() and X_val.shape[0] == 318\n",
        "    assert 'SELECTKBEST_CONFIG' in dir()\n",
        "    assert 'CONFIG' in dir() and CONFIG['n_runs'] == 10\n",
        "    print(f\"VERIFIED: Training data ({X_train.shape[0]} samples x {X_train.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Validation data ({X_val.shape[0]} samples)\")\n",
        "    print(f\"VERIFIED: SelectKBest config (k_values={SELECTKBEST_CONFIG['k_values']})\")\n",
        "    print(f\"VERIFIED: Number of runs = {CONFIG['n_runs']}\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. CPU-COMPATIBLE XGBOOST CONFIG\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/8] Setting up CPU-compatible XGBoost configuration...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# CPU-compatible unified configuration\n",
        "XGBOOST_UNIFIED_CONFIG_CPU = {\n",
        "    'n_estimators': 500,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'tree_method': 'hist',              # CPU-compatible histogram method\n",
        "    'predictor': 'cpu_predictor',       # Explicit CPU predictor\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42  # Will be overridden per run\n",
        "}\n",
        "\n",
        "print(\"CPU-compatible XGBoost configuration:\")\n",
        "print(f\"  tree_method: {XGBOOST_UNIFIED_CONFIG_CPU['tree_method']}\")\n",
        "print(f\"  predictor: {XGBOOST_UNIFIED_CONFIG_CPU['predictor']}\")\n",
        "print(f\"  n_estimators: {XGBOOST_UNIFIED_CONFIG_CPU['n_estimators']}\")\n",
        "print(f\"  max_depth: {XGBOOST_UNIFIED_CONFIG_CPU['max_depth']}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. EXPERIMENT SETUP\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/8] Setting up Baseline 2 experiment...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_2_DIR = f\"{PROJECT_PATHS['baseline_results']}/baseline_2_selectkbest\"\n",
        "MODELS_DIR = f\"{BASELINE_2_DIR}/models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Experiment directory: {BASELINE_2_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n",
        "\n",
        "print(\"\\nExperiment configuration:\")\n",
        "print(f\"  Method: SelectKBest (Filter - ANOVA F-test)\")\n",
        "print(f\"  K-values to test: {SELECTKBEST_CONFIG['k_values']}\")\n",
        "print(f\"  Number of runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Hardware: CPU-based computation\")\n",
        "print(f\"  Selection: Deterministic (same features per k)\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. PHASE 1: K-VALUE OPTIMIZATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/8] Phase 1: K-value optimization...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "k_value_results = {}\n",
        "\n",
        "for k in SELECTKBEST_CONFIG['k_values']:\n",
        "    print(f\"\\nTesting k={k} features...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Initialize SelectKBest\n",
        "    selector = SelectKBest(score_func=SELECTKBEST_CONFIG['scoring_function'], k=k)\n",
        "\n",
        "    # Fit on training data and transform\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_val_selected = selector.transform(X_val)\n",
        "\n",
        "    # Get selected features\n",
        "    selected_mask = selector.get_support()\n",
        "    selected_features = X_train.columns[selected_mask].tolist()\n",
        "    f_scores = selector.scores_[selected_mask]\n",
        "\n",
        "    print(f\"  Selected {len(selected_features)} features\")\n",
        "    print(f\"  Top 3: {selected_features[:3]}\")\n",
        "\n",
        "    # Train single XGBoost model with unified config\n",
        "    model = xgb.XGBClassifier(**XGBOOST_UNIFIED_CONFIG_CPU)\n",
        "    model.fit(X_train_selected, y_train, verbose=False)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    y_val_pred = model.predict(X_val_selected)\n",
        "    y_val_proba = model.predict_proba(X_val_selected)[:, 1]\n",
        "    val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Store results\n",
        "    k_value_results[k] = {\n",
        "        'val_auc': val_metrics['roc_auc'],\n",
        "        'val_metrics': val_metrics,\n",
        "        'selected_features': selected_features,\n",
        "        'f_scores': f_scores.tolist(),\n",
        "        'selector': selector\n",
        "    }\n",
        "\n",
        "# Determine optimal k\n",
        "optimal_k = max(k_value_results.keys(), key=lambda k: k_value_results[k]['val_auc'])\n",
        "\n",
        "print(f\"\\n[OPTIMAL K DETERMINED]\")\n",
        "print(f\"  Best k-value: {optimal_k}\")\n",
        "print(f\"  Validation AUC: {k_value_results[optimal_k]['val_auc']:.4f}\")\n",
        "\n",
        "print(\"\\nK-value optimization results:\")\n",
        "for k in SELECTKBEST_CONFIG['k_values']:\n",
        "    marker = \" <- OPTIMAL\" if k == optimal_k else \"\"\n",
        "    print(f\"  k={k:2d}: AUC = {k_value_results[k]['val_auc']:.4f}{marker}\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. PREPARE OPTIMAL FEATURE SELECTION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/8] Preparing feature selection with optimal k...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Use selector from optimal k (already fitted in Phase 1)\n",
        "optimal_selector = k_value_results[optimal_k]['selector']\n",
        "selected_features = k_value_results[optimal_k]['selected_features']\n",
        "\n",
        "print(f\"Selected features (k={optimal_k}):\")\n",
        "for i, feature in enumerate(selected_features[:10], 1):\n",
        "    print(f\"  {i:2d}. {feature}\")\n",
        "if len(selected_features) > 10:\n",
        "    print(f\"  ... and {len(selected_features) - 10} more\")\n",
        "\n",
        "# Save feature selection details\n",
        "feature_selection_details = pd.DataFrame({\n",
        "    'feature': selected_features,\n",
        "    'f_score': k_value_results[optimal_k]['f_scores']\n",
        "}).sort_values('f_score', ascending=False)\n",
        "\n",
        "feature_details_path = f\"{BASELINE_2_DIR}/feature_selection_details.csv\"\n",
        "feature_selection_details.to_csv(feature_details_path, index=False)\n",
        "print(f\"\\nFeature selection details saved: {feature_details_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. PHASE 2: MULTIPLE RUNS WITH OPTIMAL K\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/8] Phase 2: Training 10 models with optimal k...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "training_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 2: XGBoost with SelectKBest (CPU)',\n",
        "        'description': 'Filter method - ANOVA F-test statistical ranking, CPU implementation',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'n_runs': CONFIG['n_runs'],\n",
        "        'gpu_available': False,\n",
        "        'compute_backend': 'CPU'\n",
        "    },\n",
        "    'k_value_optimization': {\n",
        "        'k_values_tested': SELECTKBEST_CONFIG['k_values'],\n",
        "        'results': {\n",
        "            str(k): {\n",
        "                'val_auc': float(results['val_auc']),\n",
        "                'selected_features': results['selected_features']\n",
        "            } for k, results in k_value_results.items()\n",
        "        },\n",
        "        'optimal_k': optimal_k,\n",
        "        'optimal_val_auc': float(k_value_results[optimal_k]['val_auc'])\n",
        "    },\n",
        "    'feature_selection': {\n",
        "        'method': 'SelectKBest - f_classif',\n",
        "        'n_features_selected': optimal_k,\n",
        "        'selected_features': selected_features,\n",
        "        'f_scores': {feature: float(score) for feature, score in\n",
        "                     zip(selected_features, k_value_results[optimal_k]['f_scores'])}\n",
        "    },\n",
        "    'configuration': {\n",
        "        'xgboost_config': XGBOOST_UNIFIED_CONFIG_CPU,\n",
        "        'selectkbest_config': {k: v for k, v in SELECTKBEST_CONFIG.items() if k != 'scoring_function'}\n",
        "    },\n",
        "    'training_results': {\n",
        "        'runs': [],\n",
        "        'statistics': {}\n",
        "    },\n",
        "    'best_model': {}\n",
        "}\n",
        "\n",
        "# Transform data using optimal selector (same for all runs)\n",
        "X_train_selected = optimal_selector.transform(X_train)\n",
        "X_val_selected = optimal_selector.transform(X_val)\n",
        "\n",
        "print(f\"Feature selection applied: {X_train.shape[1]} -> {optimal_k} features\")\n",
        "print(f\"Same features used across all {CONFIG['n_runs']} runs\")\n",
        "\n",
        "start_time_total = time.time()\n",
        "validation_aucs = []\n",
        "\n",
        "for run_id in range(CONFIG['n_runs']):\n",
        "    print(f\"\\nRun {run_id + 1}/{CONFIG['n_runs']} (seed={CONFIG['random_state'] + run_id})\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    start_time_run = time.time()\n",
        "\n",
        "    # Initialize model with unique random seed\n",
        "    model_config = XGBOOST_UNIFIED_CONFIG_CPU.copy()\n",
        "    model_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "    model = xgb.XGBClassifier(**model_config)\n",
        "\n",
        "    # Train on selected features\n",
        "    print(f\"  Training on {optimal_k} selected features...\")\n",
        "    model.fit(X_train_selected, y_train, verbose=False)\n",
        "\n",
        "    # Predict on validation set\n",
        "    y_val_pred = model.predict(X_val_selected)\n",
        "    y_val_proba = model.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time_run\n",
        "\n",
        "    # Save model\n",
        "    model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "    model.save_model(model_path)\n",
        "\n",
        "    # Store results\n",
        "    run_result = {\n",
        "        'run_id': run_id,\n",
        "        'random_state': CONFIG['random_state'] + run_id,\n",
        "        'n_features_selected': optimal_k,\n",
        "        'training_time_seconds': round(training_time, 2),\n",
        "        'validation_metrics': val_metrics,\n",
        "        'model_path': model_path\n",
        "    }\n",
        "\n",
        "    training_results['training_results']['runs'].append(run_result)\n",
        "    validation_aucs.append(val_metrics['roc_auc'])\n",
        "\n",
        "    print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.2f}s\")\n",
        "    print(f\"  Model saved: {model_path}\")\n",
        "\n",
        "total_training_time = time.time() - start_time_total\n",
        "\n",
        "print(f\"\\nTotal training time: {total_training_time:.2f}s ({total_training_time/60:.2f} min)\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. STATISTICAL SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/8] Computing statistical summary...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "validation_aucs_array = np.array(validation_aucs)\n",
        "\n",
        "statistics = {\n",
        "    'mean_val_auc': float(np.mean(validation_aucs_array)),\n",
        "    'std_val_auc': float(np.std(validation_aucs_array, ddof=1)),\n",
        "    'min_val_auc': float(np.min(validation_aucs_array)),\n",
        "    'max_val_auc': float(np.max(validation_aucs_array)),\n",
        "    'median_val_auc': float(np.median(validation_aucs_array)),\n",
        "    'best_run_id': int(np.argmax(validation_aucs_array)),\n",
        "    'total_training_time_seconds': round(total_training_time, 2)\n",
        "}\n",
        "\n",
        "training_results['training_results']['statistics'] = statistics\n",
        "\n",
        "print(\"Validation AUC statistics across 10 runs:\")\n",
        "print(f\"  Mean:   {statistics['mean_val_auc']:.4f}\")\n",
        "print(f\"  Std:    {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Min:    {statistics['min_val_auc']:.4f}\")\n",
        "print(f\"  Max:    {statistics['max_val_auc']:.4f}\")\n",
        "print(f\"  Median: {statistics['median_val_auc']:.4f}\")\n",
        "print(f\"\\nBest run: Run {statistics['best_run_id']} \"\n",
        "      f\"(AUC = {statistics['max_val_auc']:.4f})\")\n",
        "\n",
        "# ==========================================\n",
        "# 8. IDENTIFY AND SAVE BEST MODEL\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 8/8] Saving best model and results...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_run_id = statistics['best_run_id']\n",
        "best_run_result = training_results['training_results']['runs'][best_run_id]\n",
        "\n",
        "# Load and save best model separately\n",
        "best_model = xgb.XGBClassifier()\n",
        "best_model.load_model(best_run_result['model_path'])\n",
        "\n",
        "best_model_path = f\"{BASELINE_2_DIR}/baseline_2_best_model.json\"\n",
        "best_model.save_model(best_model_path)\n",
        "\n",
        "training_results['best_model'] = {\n",
        "    'run_id': best_run_id,\n",
        "    'random_state': best_run_result['random_state'],\n",
        "    'validation_auc': best_run_result['validation_metrics']['roc_auc'],\n",
        "    'validation_metrics': best_run_result['validation_metrics'],\n",
        "    'model_path': best_model_path\n",
        "}\n",
        "\n",
        "print(f\"Best model: Run {best_run_id}\")\n",
        "print(f\"  Validation AUC: {best_run_result['validation_metrics']['roc_auc']:.4f}\")\n",
        "print(f\"  Validation Accuracy: {best_run_result['validation_metrics']['accuracy']:.4f}\")\n",
        "print(f\"  Features used: {optimal_k}\")\n",
        "print(f\"  Saved to: {best_model_path}\")\n",
        "\n",
        "# Save training results\n",
        "results_path = f\"{BASELINE_2_DIR}/baseline_2_training_results_CPU.json\"\n",
        "save_results(training_results, results_path)\n",
        "print(f\"\\nTraining results saved: {results_path}\")\n",
        "\n",
        "# Generate summary statistics file\n",
        "summary = {\n",
        "    'experiment': 'Baseline 2: XGBoost with SelectKBest (CPU)',\n",
        "    'feature_selection': {\n",
        "        'method': 'Filter (ANOVA F-test)',\n",
        "        'k_values_tested': SELECTKBEST_CONFIG['k_values'],\n",
        "        'optimal_k': optimal_k,\n",
        "        'original_features': X_train.shape[1],\n",
        "        'reduction_percent': round((1 - optimal_k/X_train.shape[1]) * 100, 1)\n",
        "    },\n",
        "    'n_runs': CONFIG['n_runs'],\n",
        "    'compute_backend': 'CPU',\n",
        "    'validation_auc': {\n",
        "        'mean': statistics['mean_val_auc'],\n",
        "        'std': statistics['std_val_auc'],\n",
        "        'range': [statistics['min_val_auc'], statistics['max_val_auc']]\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_id,\n",
        "        'validation_auc': statistics['max_val_auc']\n",
        "    },\n",
        "    'training_time_total_minutes': round(total_training_time / 60, 2)\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_2_DIR}/training_summary_CPU.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Training summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 2 TRAINING COMPLETED SUCCESSFULLY (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nEXPERIMENT SUMMARY:\")\n",
        "print(f\"  Method: SelectKBest (Filter - ANOVA F-test)\")\n",
        "print(f\"  Feature selection: {X_train.shape[1]} -> {optimal_k} features\")\n",
        "print(f\"  Reduction: {(1 - optimal_k/X_train.shape[1]) * 100:.1f}%\")\n",
        "print(f\"  Training runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Compute backend: CPU (tree_method='hist')\")\n",
        "print(f\"  Total training time: {total_training_time/60:.2f} minutes\")\n",
        "\n",
        "print(\"\\nK-VALUE OPTIMIZATION:\")\n",
        "for k in SELECTKBEST_CONFIG['k_values']:\n",
        "    marker = \" <- OPTIMAL\" if k == optimal_k else \"\"\n",
        "    print(f\"  k={k:2d}: AUC = {k_value_results[k]['val_auc']:.4f}{marker}\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_val_auc']:.4f} Â± {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Best AUC: {statistics['max_val_auc']:.4f} (Run {best_run_id})\")\n",
        "print(f\"  AUC range: [{statistics['min_val_auc']:.4f}, {statistics['max_val_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nSELECTED FEATURES (Top 10):\")\n",
        "for i, feature in enumerate(selected_features[:10], 1):\n",
        "    print(f\"  {i:2d}. {feature}\")\n",
        "if len(selected_features) > 10:\n",
        "    print(f\"  ... and {len(selected_features) - 10} more\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Training results: {results_path}\")\n",
        "print(f\"  Best model: {best_model_path}\")\n",
        "print(f\"  All models: {MODELS_DIR}/ (10 models)\")\n",
        "print(f\"  Feature selection: {feature_details_path}\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 4: Baseline 3 - XGBoost with RFECV (CPU)\")\n",
        "print(\"  Cell 6: Baseline 2 Testing - Test set evaluation\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR NEXT BASELINE EXPERIMENT\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lGtPmEoWCHNn",
        "outputId": "bee4222b-2f53-4028-b3d7-1c21e888acd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 2 TRAINING: XGBOOST WITH SELECTKBEST (CPU)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/8] Verifying Cell 1 completion...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Training data (1270 samples x 25 features)\n",
            "VERIFIED: Validation data (318 samples)\n",
            "VERIFIED: SelectKBest config (k_values=[8, 12, 16, 20])\n",
            "VERIFIED: Number of runs = 10\n",
            "\n",
            "[STEP 2/8] Setting up CPU-compatible XGBoost configuration...\n",
            "--------------------------------------------------\n",
            "CPU-compatible XGBoost configuration:\n",
            "  tree_method: hist\n",
            "  predictor: cpu_predictor\n",
            "  n_estimators: 500\n",
            "  max_depth: 8\n",
            "\n",
            "[STEP 3/8] Setting up Baseline 2 experiment...\n",
            "--------------------------------------------------\n",
            "Experiment directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest\n",
            "Models directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models\n",
            "\n",
            "Experiment configuration:\n",
            "  Method: SelectKBest (Filter - ANOVA F-test)\n",
            "  K-values to test: [8, 12, 16, 20]\n",
            "  Number of runs: 10\n",
            "  Hardware: CPU-based computation\n",
            "  Selection: Deterministic (same features per k)\n",
            "\n",
            "[STEP 4/8] Phase 1: K-value optimization...\n",
            "--------------------------------------------------\n",
            "\n",
            "Testing k=8 features...\n",
            "----------------------------------------\n",
            "  Selected 8 features\n",
            "  Top 3: ['A1', 'A2', 'A4']\n",
            "  Validation AUC: 0.9671\n",
            "  Validation Accuracy: 0.8836\n",
            "\n",
            "Testing k=12 features...\n",
            "----------------------------------------\n",
            "  Selected 12 features\n",
            "  Top 3: ['A1', 'A2', 'A3']\n",
            "  Validation AUC: 0.9950\n",
            "  Validation Accuracy: 0.9591\n",
            "\n",
            "Testing k=16 features...\n",
            "----------------------------------------\n",
            "  Selected 16 features\n",
            "  Top 3: ['A1', 'A2', 'A3']\n",
            "  Validation AUC: 0.9950\n",
            "  Validation Accuracy: 0.9591\n",
            "\n",
            "Testing k=20 features...\n",
            "----------------------------------------\n",
            "  Selected 20 features\n",
            "  Top 3: ['A1', 'A2', 'A3']\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "\n",
            "[OPTIMAL K DETERMINED]\n",
            "  Best k-value: 20\n",
            "  Validation AUC: 0.9964\n",
            "\n",
            "K-value optimization results:\n",
            "  k= 8: AUC = 0.9671\n",
            "  k=12: AUC = 0.9950\n",
            "  k=16: AUC = 0.9950\n",
            "  k=20: AUC = 0.9964 <- OPTIMAL\n",
            "\n",
            "[STEP 5/8] Preparing feature selection with optimal k...\n",
            "--------------------------------------------------\n",
            "Selected features (k=20):\n",
            "   1. A1\n",
            "   2. A2\n",
            "   3. A3\n",
            "   4. A4\n",
            "   5. A5\n",
            "   6. A6\n",
            "   7. A7\n",
            "   8. A8\n",
            "   9. A9\n",
            "  10. Social_Responsiveness_Scale\n",
            "  ... and 10 more\n",
            "\n",
            "Feature selection details saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/feature_selection_details.csv\n",
            "\n",
            "[STEP 6/8] Phase 2: Training 10 models with optimal k...\n",
            "--------------------------------------------------\n",
            "Feature selection applied: 25 -> 20 features\n",
            "Same features used across all 10 runs\n",
            "\n",
            "Run 1/10 (seed=42)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.16s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_0_model.json\n",
            "\n",
            "Run 2/10 (seed=43)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.17s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_1_model.json\n",
            "\n",
            "Run 3/10 (seed=44)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.19s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_2_model.json\n",
            "\n",
            "Run 4/10 (seed=45)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.16s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_3_model.json\n",
            "\n",
            "Run 5/10 (seed=46)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.17s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_4_model.json\n",
            "\n",
            "Run 6/10 (seed=47)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.16s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_5_model.json\n",
            "\n",
            "Run 7/10 (seed=48)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.16s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_6_model.json\n",
            "\n",
            "Run 8/10 (seed=49)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.20s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_7_model.json\n",
            "\n",
            "Run 9/10 (seed=50)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.17s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_8_model.json\n",
            "\n",
            "Run 10/10 (seed=51)\n",
            "----------------------------------------\n",
            "  Training on 20 selected features...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Training time: 0.18s\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/run_9_model.json\n",
            "\n",
            "Total training time: 1.97s (0.03 min)\n",
            "\n",
            "[STEP 7/8] Computing statistical summary...\n",
            "--------------------------------------------------\n",
            "Validation AUC statistics across 10 runs:\n",
            "  Mean:   0.9964\n",
            "  Std:    0.0000\n",
            "  Min:    0.9964\n",
            "  Max:    0.9964\n",
            "  Median: 0.9964\n",
            "\n",
            "Best run: Run 0 (AUC = 0.9964)\n",
            "\n",
            "[STEP 8/8] Saving best model and results...\n",
            "--------------------------------------------------\n",
            "Best model: Run 0\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Features used: 20\n",
            "  Saved to: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/baseline_2_best_model.json\n",
            "\n",
            "Training results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/baseline_2_training_results_CPU.json\n",
            "Training summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/training_summary_CPU.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 2 TRAINING COMPLETED SUCCESSFULLY (CPU)\n",
            "================================================================================\n",
            "\n",
            "EXPERIMENT SUMMARY:\n",
            "  Method: SelectKBest (Filter - ANOVA F-test)\n",
            "  Feature selection: 25 -> 20 features\n",
            "  Reduction: 20.0%\n",
            "  Training runs: 10\n",
            "  Compute backend: CPU (tree_method='hist')\n",
            "  Total training time: 0.03 minutes\n",
            "\n",
            "K-VALUE OPTIMIZATION:\n",
            "  k= 8: AUC = 0.9671\n",
            "  k=12: AUC = 0.9950\n",
            "  k=16: AUC = 0.9950\n",
            "  k=20: AUC = 0.9964 <- OPTIMAL\n",
            "\n",
            "VALIDATION PERFORMANCE:\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "  Best AUC: 0.9964 (Run 0)\n",
            "  AUC range: [0.9964, 0.9964]\n",
            "\n",
            "SELECTED FEATURES (Top 10):\n",
            "   1. A1\n",
            "   2. A2\n",
            "   3. A3\n",
            "   4. A4\n",
            "   5. A5\n",
            "   6. A6\n",
            "   7. A7\n",
            "   8. A8\n",
            "   9. A9\n",
            "  10. Social_Responsiveness_Scale\n",
            "  ... and 10 more\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Training results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/baseline_2_training_results_CPU.json\n",
            "  Best model: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/baseline_2_best_model.json\n",
            "  All models: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/models/ (10 models)\n",
            "  Feature selection: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_2_selectkbest/feature_selection_details.csv\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 4: Baseline 3 - XGBoost with RFECV (CPU)\n",
            "  Cell 6: Baseline 2 Testing - Test set evaluation\n",
            "\n",
            "================================================================================\n",
            "READY FOR NEXT BASELINE EXPERIMENT\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4: Baseline 3 Training - XGBoost with RFECV (CPU)\n",
        "\n",
        "\"\"\"\n",
        "ASD Detection Project: Baseline Experiments\n",
        "Cell 4: Baseline 3 - XGBoost with RFECV (Wrapper Method)\n",
        "10 independent RFECV runs (each performs feature selection separately)\n",
        "Model-guided iterative feature elimination with cross-validation\n",
        "CPU-compatible implementation for reproducibility and stability\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE 3 TRAINING: XGBOOST WITH RFECV (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==========================================\n",
        "# 1. VERIFY PREREQUISITES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 1/7] Verifying Cell 1 completion...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    assert 'X_train' in dir() and X_train.shape[1] == 25\n",
        "    assert 'X_val' in dir() and X_val.shape[0] == 318\n",
        "    assert 'RFECV_CONFIG' in dir()\n",
        "    assert 'CONFIG' in dir() and CONFIG['n_runs'] == 10\n",
        "    print(f\"VERIFIED: Training data ({X_train.shape[0]} samples x {X_train.shape[1]} features)\")\n",
        "    print(f\"VERIFIED: Validation data ({X_val.shape[0]} samples)\")\n",
        "    print(f\"VERIFIED: RFECV config loaded\")\n",
        "    print(f\"VERIFIED: Number of runs = {CONFIG['n_runs']}\")\n",
        "except (NameError, AssertionError) as e:\n",
        "    raise RuntimeError(\"ERROR: Cell 1 must be executed first\") from e\n",
        "\n",
        "# ==========================================\n",
        "# 2. CPU-COMPATIBLE XGBOOST CONFIGS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 2/7] Setting up CPU-compatible XGBoost configurations...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Lightweight config for RFECV estimator (faster iterations)\n",
        "XGBOOST_RFECV_CONFIG_CPU = {\n",
        "    'n_estimators': 150,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.1,\n",
        "    'subsample': 1.0,\n",
        "    'colsample_bytree': 1.0,\n",
        "    'tree_method': 'hist',          # CPU-compatible histogram method\n",
        "    'predictor': 'cpu_predictor',   # Explicit CPU predictor\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'verbosity': 0,\n",
        "    'nthread': 1,                   # Single thread for stability\n",
        "    'random_state': 42  # Will be overridden per run\n",
        "}\n",
        "\n",
        "# Full config for final model training\n",
        "XGBOOST_UNIFIED_CONFIG_CPU = {\n",
        "    'n_estimators': 500,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'tree_method': 'hist',          # CPU-compatible histogram method\n",
        "    'predictor': 'cpu_predictor',   # Explicit CPU predictor\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'verbosity': 0,\n",
        "    'nthread': 1,                   # Single thread for stability\n",
        "    'random_state': 42  # Will be overridden per run\n",
        "}\n",
        "\n",
        "print(\"CPU-compatible RFECV estimator configuration:\")\n",
        "print(f\"  tree_method: {XGBOOST_RFECV_CONFIG_CPU['tree_method']}\")\n",
        "print(f\"  predictor: {XGBOOST_RFECV_CONFIG_CPU['predictor']}\")\n",
        "print(f\"  n_estimators: {XGBOOST_RFECV_CONFIG_CPU['n_estimators']} (lightweight)\")\n",
        "print(f\"  nthread: {XGBOOST_RFECV_CONFIG_CPU['nthread']} (sequential)\")\n",
        "\n",
        "print(\"\\nCPU-compatible final model configuration:\")\n",
        "print(f\"  tree_method: {XGBOOST_UNIFIED_CONFIG_CPU['tree_method']}\")\n",
        "print(f\"  predictor: {XGBOOST_UNIFIED_CONFIG_CPU['predictor']}\")\n",
        "print(f\"  n_estimators: {XGBOOST_UNIFIED_CONFIG_CPU['n_estimators']} (full)\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. EXPERIMENT SETUP\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 3/7] Setting up Baseline 3 experiment...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "BASELINE_3_DIR = f\"{PROJECT_PATHS['baseline_results']}/baseline_3_rfecv\"\n",
        "MODELS_DIR = f\"{BASELINE_3_DIR}/models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Experiment directory: {BASELINE_3_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n",
        "\n",
        "print(\"\\nExperiment configuration:\")\n",
        "print(f\"  Method: RFECV (Wrapper - model-guided)\")\n",
        "print(f\"  RFECV step: {RFECV_CONFIG['step']} features\")\n",
        "print(f\"  RFECV CV: {RFECV_CONFIG['cv_folds']} folds\")\n",
        "print(f\"  Min features: {RFECV_CONFIG['min_features_to_select']}\")\n",
        "print(f\"  Number of runs: {CONFIG['n_runs']}\")\n",
        "print(f\"  Hardware: CPU-based computation\")\n",
        "print(f\"  Parallel processing: DISABLED (n_jobs=1, nthread=1 for stability)\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAINING LOOP - 10 INDEPENDENT RFECV RUNS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 4/7] Running 10 independent RFECV experiments...\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Note: Each run may take 10-15 minutes due to cross-validation\")\n",
        "\n",
        "training_results = {\n",
        "    'experiment_info': {\n",
        "        'name': 'Baseline 3: XGBoost with RFECV (CPU)',\n",
        "        'description': 'Wrapper method - recursive feature elimination with CV, CPU implementation',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'n_runs': CONFIG['n_runs'],\n",
        "        'gpu_available': False,\n",
        "        'compute_backend': 'CPU',\n",
        "        'notes': 'n_jobs=1, nthread=1, tree_method=hist for stability and reproducibility'\n",
        "    },\n",
        "    'rfecv_configuration': {\n",
        "        'step': RFECV_CONFIG['step'],\n",
        "        'cv_folds': RFECV_CONFIG['cv_folds'],\n",
        "        'min_features_to_select': RFECV_CONFIG['min_features_to_select'],\n",
        "        'scoring': RFECV_CONFIG['scoring'],\n",
        "        'n_jobs': 1\n",
        "    },\n",
        "    'configuration': {\n",
        "        'xgboost_rfecv_config': XGBOOST_RFECV_CONFIG_CPU,\n",
        "        'xgboost_unified_config': XGBOOST_UNIFIED_CONFIG_CPU\n",
        "    },\n",
        "    'training_results': {\n",
        "        'runs': [],\n",
        "        'statistics': {}\n",
        "    },\n",
        "    'feature_stability': {},\n",
        "    'best_model': {}\n",
        "}\n",
        "\n",
        "start_time_total = time.time()\n",
        "validation_aucs = []\n",
        "all_selected_features = []\n",
        "all_optimal_n = []\n",
        "\n",
        "for run_id in range(CONFIG['n_runs']):\n",
        "    print(f\"\\nRun {run_id + 1}/{CONFIG['n_runs']} (seed={CONFIG['random_state'] + run_id})\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    start_time_run = time.time()\n",
        "\n",
        "    try:\n",
        "        # Phase 1: RFECV Feature Selection\n",
        "        print(f\"  Phase 1: RFECV feature selection...\")\n",
        "\n",
        "        # Configure RFECV estimator\n",
        "        rfecv_estimator_config = XGBOOST_RFECV_CONFIG_CPU.copy()\n",
        "        rfecv_estimator_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "        rfecv_estimator = xgb.XGBClassifier(**rfecv_estimator_config)\n",
        "\n",
        "        # Initialize RFECV with n_jobs=1 for stability\n",
        "        rfecv = RFECV(\n",
        "            estimator=rfecv_estimator,\n",
        "            step=RFECV_CONFIG['step'],\n",
        "            cv=RFECV_CONFIG['cv_folds'],\n",
        "            scoring=RFECV_CONFIG['scoring'],\n",
        "            min_features_to_select=RFECV_CONFIG['min_features_to_select'],\n",
        "            n_jobs=1,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Fit RFECV on training data\n",
        "        rfecv_start = time.time()\n",
        "        print(f\"    Starting RFECV (this may take several minutes)...\")\n",
        "        rfecv.fit(X_train, y_train)\n",
        "        rfecv_time = time.time() - rfecv_start\n",
        "\n",
        "        # Extract RFECV results\n",
        "        optimal_n_features = rfecv.n_features_\n",
        "        selected_mask = rfecv.support_\n",
        "        feature_ranking = rfecv.ranking_\n",
        "        cv_scores = rfecv.cv_results_['mean_test_score']\n",
        "        convergence_iteration = len(cv_scores)\n",
        "\n",
        "        # Get selected features\n",
        "        selected_features = X_train.columns[selected_mask].tolist()\n",
        "\n",
        "        print(f\"    RFECV completed in {rfecv_time:.1f}s ({rfecv_time/60:.1f} min)\")\n",
        "        print(f\"    Optimal features: {optimal_n_features}/{X_train.shape[1]}\")\n",
        "        print(f\"    Best CV AUC: {np.max(cv_scores):.4f}\")\n",
        "        print(f\"    Convergence iterations: {convergence_iteration}\")\n",
        "\n",
        "        # Phase 2: Train Final Model with Selected Features\n",
        "        print(f\"  Phase 2: Training final model...\")\n",
        "\n",
        "        # Transform data using selected features\n",
        "        X_train_selected = rfecv.transform(X_train)\n",
        "        X_val_selected = rfecv.transform(X_val)\n",
        "\n",
        "        # Configure final model\n",
        "        final_model_config = XGBOOST_UNIFIED_CONFIG_CPU.copy()\n",
        "        final_model_config['random_state'] = CONFIG['random_state'] + run_id\n",
        "\n",
        "        final_model = xgb.XGBClassifier(**final_model_config)\n",
        "\n",
        "        # Train final model\n",
        "        final_model.fit(X_train_selected, y_train, verbose=False)\n",
        "\n",
        "        # Predict on validation set\n",
        "        y_val_pred = final_model.predict(X_val_selected)\n",
        "        y_val_proba = final_model.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_metrics = calculate_metrics(y_val, y_val_pred, y_val_proba)\n",
        "\n",
        "        # Calculate total training time\n",
        "        training_time = time.time() - start_time_run\n",
        "\n",
        "        # Save RFECV details\n",
        "        rfecv_details_path = f\"{MODELS_DIR}/run_{run_id}_rfecv_details.json\"\n",
        "        rfecv_details = {\n",
        "            'run_id': run_id,\n",
        "            'optimal_n_features': int(optimal_n_features),\n",
        "            'selected_features': selected_features,\n",
        "            'feature_ranking': {feat: int(rank) for feat, rank in zip(X_train.columns, feature_ranking)},\n",
        "            'cv_scores_trajectory': [float(score) for score in cv_scores],\n",
        "            'convergence_iterations': convergence_iteration,\n",
        "            'rfecv_time_seconds': round(rfecv_time, 2)\n",
        "        }\n",
        "        save_results(rfecv_details, rfecv_details_path)\n",
        "\n",
        "        # Save final model\n",
        "        model_path = f\"{MODELS_DIR}/run_{run_id}_model.json\"\n",
        "        final_model.save_model(model_path)\n",
        "\n",
        "        # Store results\n",
        "        run_result = {\n",
        "            'run_id': run_id,\n",
        "            'random_state': CONFIG['random_state'] + run_id,\n",
        "            'rfecv_results': {\n",
        "                'optimal_n_features': int(optimal_n_features),\n",
        "                'selected_features': selected_features,\n",
        "                'convergence_iterations': convergence_iteration,\n",
        "                'best_cv_score': float(np.max(cv_scores)),\n",
        "                'cv_scores_trajectory': [float(score) for score in cv_scores],\n",
        "                'rfecv_time_seconds': round(rfecv_time, 2)\n",
        "            },\n",
        "            'training_time_seconds': round(training_time, 2),\n",
        "            'validation_metrics': val_metrics,\n",
        "            'model_path': model_path,\n",
        "            'rfecv_details_path': rfecv_details_path\n",
        "        }\n",
        "\n",
        "        training_results['training_results']['runs'].append(run_result)\n",
        "        validation_aucs.append(val_metrics['roc_auc'])\n",
        "        all_selected_features.append(set(selected_features))\n",
        "        all_optimal_n.append(optimal_n_features)\n",
        "\n",
        "        print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "        print(f\"  Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "        print(f\"  Total time: {training_time:.2f}s ({training_time/60:.1f} min)\")\n",
        "        print(f\"  Model saved: {model_path}\")\n",
        "        print(f\"  Run {run_id + 1} completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ERROR in Run {run_id + 1}: {str(e)}\")\n",
        "        print(f\"  Skipping this run and continuing...\")\n",
        "        continue\n",
        "\n",
        "total_training_time = time.time() - start_time_total\n",
        "\n",
        "print(f\"\\nTotal training time: {total_training_time:.2f}s ({total_training_time/60:.2f} min)\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. STATISTICAL SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 5/7] Computing statistical summary...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if len(validation_aucs) > 0:\n",
        "    validation_aucs_array = np.array(validation_aucs)\n",
        "    optimal_n_array = np.array(all_optimal_n)\n",
        "\n",
        "    statistics = {\n",
        "        'mean_val_auc': float(np.mean(validation_aucs_array)),\n",
        "        'std_val_auc': float(np.std(validation_aucs_array, ddof=1)),\n",
        "        'min_val_auc': float(np.min(validation_aucs_array)),\n",
        "        'max_val_auc': float(np.max(validation_aucs_array)),\n",
        "        'median_val_auc': float(np.median(validation_aucs_array)),\n",
        "        'best_run_id': int(np.argmax(validation_aucs_array)),\n",
        "        'mean_optimal_features': float(np.mean(optimal_n_array)),\n",
        "        'std_optimal_features': float(np.std(optimal_n_array, ddof=1)),\n",
        "        'total_training_time_seconds': round(total_training_time, 2),\n",
        "        'successful_runs': len(validation_aucs)\n",
        "    }\n",
        "\n",
        "    training_results['training_results']['statistics'] = statistics\n",
        "\n",
        "    print(\"Validation AUC statistics across successful runs:\")\n",
        "    print(f\"  Mean:   {statistics['mean_val_auc']:.4f}\")\n",
        "    print(f\"  Std:    {statistics['std_val_auc']:.4f}\")\n",
        "    print(f\"  Min:    {statistics['min_val_auc']:.4f}\")\n",
        "    print(f\"  Max:    {statistics['max_val_auc']:.4f}\")\n",
        "    print(f\"  Median: {statistics['median_val_auc']:.4f}\")\n",
        "\n",
        "    print(\"\\nFeature selection statistics:\")\n",
        "    print(f\"  Mean features selected: {statistics['mean_optimal_features']:.1f}\")\n",
        "    print(f\"  Std features: {statistics['std_optimal_features']:.1f}\")\n",
        "\n",
        "    print(f\"\\nBest run: Run {statistics['best_run_id']} \"\n",
        "          f\"(AUC = {statistics['max_val_auc']:.4f})\")\n",
        "else:\n",
        "    print(\"ERROR: No successful runs completed\")\n",
        "    raise RuntimeError(\"All RFECV runs failed\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. FEATURE STABILITY ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 6/7] Analyzing feature stability...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Count feature selection frequency\n",
        "feature_frequency = {}\n",
        "for feature_set in all_selected_features:\n",
        "    for feature in feature_set:\n",
        "        feature_frequency[feature] = feature_frequency.get(feature, 0) + 1\n",
        "\n",
        "# Sort by frequency\n",
        "sorted_features = sorted(feature_frequency.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(f\"Feature stability analysis (across {len(all_selected_features)} runs):\")\n",
        "print(f\"  Core features (100% frequency):\")\n",
        "core_features = [f for f, freq in sorted_features if freq == len(all_selected_features)]\n",
        "for feature in core_features:\n",
        "    print(f\"    - {feature}\")\n",
        "\n",
        "if len(core_features) == 0:\n",
        "    print(\"    None (RFECV selections vary across runs)\")\n",
        "    print(f\"  Most frequent features:\")\n",
        "    for feature, freq in sorted_features[:10]:\n",
        "        print(f\"    - {feature}: {freq}/{len(all_selected_features)} runs ({100*freq/len(all_selected_features):.0f}%)\")\n",
        "\n",
        "training_results['feature_stability'] = {\n",
        "    'feature_frequency': feature_frequency,\n",
        "    'core_features': core_features,\n",
        "    'sorted_by_frequency': [{'feature': f, 'frequency': freq} for f, freq in sorted_features]\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 7. IDENTIFY AND SAVE BEST MODEL\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n[STEP 7/7] Saving best model and results...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_run_id = statistics['best_run_id']\n",
        "best_run_result = training_results['training_results']['runs'][best_run_id]\n",
        "\n",
        "# Load and save best model separately\n",
        "best_model = xgb.XGBClassifier()\n",
        "best_model.load_model(best_run_result['model_path'])\n",
        "\n",
        "best_model_path = f\"{BASELINE_3_DIR}/baseline_3_best_model.json\"\n",
        "best_model.save_model(best_model_path)\n",
        "\n",
        "training_results['best_model'] = {\n",
        "    'run_id': best_run_id,\n",
        "    'random_state': best_run_result['random_state'],\n",
        "    'validation_auc': best_run_result['validation_metrics']['roc_auc'],\n",
        "    'validation_metrics': best_run_result['validation_metrics'],\n",
        "    'optimal_n_features': best_run_result['rfecv_results']['optimal_n_features'],\n",
        "    'selected_features': best_run_result['rfecv_results']['selected_features'],\n",
        "    'model_path': best_model_path\n",
        "}\n",
        "\n",
        "print(f\"Best model: Run {best_run_id}\")\n",
        "print(f\"  Validation AUC: {best_run_result['validation_metrics']['roc_auc']:.4f}\")\n",
        "print(f\"  Validation Accuracy: {best_run_result['validation_metrics']['accuracy']:.4f}\")\n",
        "print(f\"  Features selected: {best_run_result['rfecv_results']['optimal_n_features']}\")\n",
        "print(f\"  Saved to: {best_model_path}\")\n",
        "\n",
        "# Save training results\n",
        "results_path = f\"{BASELINE_3_DIR}/baseline_3_training_results_CPU.json\"\n",
        "save_results(training_results, results_path)\n",
        "print(f\"\\nTraining results saved: {results_path}\")\n",
        "\n",
        "# Generate summary statistics file\n",
        "summary = {\n",
        "    'experiment': 'Baseline 3: XGBoost with RFECV (CPU)',\n",
        "    'feature_selection': {\n",
        "        'method': 'Wrapper (Recursive Feature Elimination with CV)',\n",
        "        'original_features': X_train.shape[1],\n",
        "        'mean_features_selected': statistics['mean_optimal_features'],\n",
        "        'std_features_selected': statistics['std_optimal_features'],\n",
        "        'reduction_percent': round((1 - statistics['mean_optimal_features']/X_train.shape[1]) * 100, 1)\n",
        "    },\n",
        "    'n_runs': CONFIG['n_runs'],\n",
        "    'successful_runs': statistics['successful_runs'],\n",
        "    'compute_backend': 'CPU',\n",
        "    'validation_auc': {\n",
        "        'mean': statistics['mean_val_auc'],\n",
        "        'std': statistics['std_val_auc'],\n",
        "        'range': [statistics['min_val_auc'], statistics['max_val_auc']]\n",
        "    },\n",
        "    'best_run': {\n",
        "        'run_id': best_run_id,\n",
        "        'validation_auc': statistics['max_val_auc'],\n",
        "        'features_selected': best_run_result['rfecv_results']['optimal_n_features']\n",
        "    },\n",
        "    'training_time_total_minutes': round(total_training_time / 60, 2)\n",
        "}\n",
        "\n",
        "summary_path = f\"{BASELINE_3_DIR}/training_summary_CPU.json\"\n",
        "save_results(summary, summary_path)\n",
        "print(f\"Training summary saved: {summary_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# COMPLETION SUMMARY\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE 3 TRAINING COMPLETED SUCCESSFULLY (CPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nEXPERIMENT SUMMARY:\")\n",
        "print(f\"  Method: RFECV (Wrapper - model-guided)\")\n",
        "print(f\"  Feature selection: {X_train.shape[1]} -> {statistics['mean_optimal_features']:.1f} Â± {statistics['std_optimal_features']:.1f} features\")\n",
        "print(f\"  Reduction: {(1 - statistics['mean_optimal_features']/X_train.shape[1]) * 100:.1f}%\")\n",
        "print(f\"  Training runs: {statistics['successful_runs']}/{CONFIG['n_runs']} successful\")\n",
        "print(f\"  Compute backend: CPU (tree_method='hist', n_jobs=1)\")\n",
        "print(f\"  Total training time: {total_training_time/60:.2f} minutes\")\n",
        "\n",
        "print(\"\\nVALIDATION PERFORMANCE:\")\n",
        "print(f\"  Mean AUC: {statistics['mean_val_auc']:.4f} Â± {statistics['std_val_auc']:.4f}\")\n",
        "print(f\"  Best AUC: {statistics['max_val_auc']:.4f} (Run {best_run_id})\")\n",
        "print(f\"  AUC range: [{statistics['min_val_auc']:.4f}, {statistics['max_val_auc']:.4f}]\")\n",
        "\n",
        "print(\"\\nMOST STABLE FEATURES:\")\n",
        "for feature, freq in sorted_features[:10]:\n",
        "    print(f\"  - {feature}: {freq}/{len(all_selected_features)} runs ({100*freq/len(all_selected_features):.0f}%)\")\n",
        "\n",
        "print(\"\\nOUTPUTS GENERATED:\")\n",
        "print(f\"  Training results: {results_path}\")\n",
        "print(f\"  Best model: {best_model_path}\")\n",
        "print(f\"  All models: {MODELS_DIR}/ ({statistics['successful_runs']} models)\")\n",
        "print(f\"  RFECV details: {MODELS_DIR}/*_rfecv_details.json\")\n",
        "\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"  Cell 7: Baseline 3 Testing - Test set evaluation\")\n",
        "print(\"  Cell 8: Comprehensive comparison across all methods\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"READY FOR TESTING PHASE\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "icFzJy1iCL_I",
        "outputId": "b7bf12ca-86f0-4bf9-f07b-31dd14fd3814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASELINE 3 TRAINING: XGBOOST WITH RFECV (CPU)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1/7] Verifying Cell 1 completion...\n",
            "--------------------------------------------------\n",
            "VERIFIED: Training data (1270 samples x 25 features)\n",
            "VERIFIED: Validation data (318 samples)\n",
            "VERIFIED: RFECV config loaded\n",
            "VERIFIED: Number of runs = 10\n",
            "\n",
            "[STEP 2/7] Setting up CPU-compatible XGBoost configurations...\n",
            "--------------------------------------------------\n",
            "CPU-compatible RFECV estimator configuration:\n",
            "  tree_method: hist\n",
            "  predictor: cpu_predictor\n",
            "  n_estimators: 150 (lightweight)\n",
            "  nthread: 1 (sequential)\n",
            "\n",
            "CPU-compatible final model configuration:\n",
            "  tree_method: hist\n",
            "  predictor: cpu_predictor\n",
            "  n_estimators: 500 (full)\n",
            "\n",
            "[STEP 3/7] Setting up Baseline 3 experiment...\n",
            "--------------------------------------------------\n",
            "Experiment directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv\n",
            "Models directory: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models\n",
            "\n",
            "Experiment configuration:\n",
            "  Method: RFECV (Wrapper - model-guided)\n",
            "  RFECV step: 5 features\n",
            "  RFECV CV: 3 folds\n",
            "  Min features: 8\n",
            "  Number of runs: 10\n",
            "  Hardware: CPU-based computation\n",
            "  Parallel processing: DISABLED (n_jobs=1, nthread=1 for stability)\n",
            "\n",
            "[STEP 4/7] Running 10 independent RFECV experiments...\n",
            "--------------------------------------------------\n",
            "Note: Each run may take 10-15 minutes due to cross-validation\n",
            "\n",
            "Run 1/10 (seed=42)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.95s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_0_model.json\n",
            "  Run 1 completed successfully\n",
            "\n",
            "Run 2/10 (seed=43)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.95s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_1_model.json\n",
            "  Run 2 completed successfully\n",
            "\n",
            "Run 3/10 (seed=44)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.99s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_2_model.json\n",
            "  Run 3 completed successfully\n",
            "\n",
            "Run 4/10 (seed=45)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.94s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_3_model.json\n",
            "  Run 4 completed successfully\n",
            "\n",
            "Run 5/10 (seed=46)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.94s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_4_model.json\n",
            "  Run 5 completed successfully\n",
            "\n",
            "Run 6/10 (seed=47)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.93s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_5_model.json\n",
            "  Run 6 completed successfully\n",
            "\n",
            "Run 7/10 (seed=48)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.99s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_6_model.json\n",
            "  Run 7 completed successfully\n",
            "\n",
            "Run 8/10 (seed=49)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 0.8s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 0.95s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_7_model.json\n",
            "  Run 8 completed successfully\n",
            "\n",
            "Run 9/10 (seed=50)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 1.9s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 2.19s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_8_model.json\n",
            "  Run 9 completed successfully\n",
            "\n",
            "Run 10/10 (seed=51)\n",
            "----------------------------------------\n",
            "  Phase 1: RFECV feature selection...\n",
            "    Starting RFECV (this may take several minutes)...\n",
            "    RFECV completed in 1.7s (0.0 min)\n",
            "    Optimal features: 25/25\n",
            "    Best CV AUC: 0.9950\n",
            "    Convergence iterations: 5\n",
            "  Phase 2: Training final model...\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Total time: 1.93s (0.0 min)\n",
            "  Model saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/run_9_model.json\n",
            "  Run 10 completed successfully\n",
            "\n",
            "Total training time: 12.14s (0.20 min)\n",
            "\n",
            "[STEP 5/7] Computing statistical summary...\n",
            "--------------------------------------------------\n",
            "Validation AUC statistics across successful runs:\n",
            "  Mean:   0.9964\n",
            "  Std:    0.0000\n",
            "  Min:    0.9964\n",
            "  Max:    0.9964\n",
            "  Median: 0.9964\n",
            "\n",
            "Feature selection statistics:\n",
            "  Mean features selected: 25.0\n",
            "  Std features: 0.0\n",
            "\n",
            "Best run: Run 1 (AUC = 0.9964)\n",
            "\n",
            "[STEP 6/7] Analyzing feature stability...\n",
            "--------------------------------------------------\n",
            "Feature stability analysis (across 10 runs):\n",
            "  Core features (100% frequency):\n",
            "    - A5\n",
            "    - Social/Behavioural Issues\n",
            "    - A9\n",
            "    - Speech Delay/Language Disorder\n",
            "    - Jaundice\n",
            "    - Genetic_Disorders\n",
            "    - Depression\n",
            "    - Age_Years\n",
            "    - Family_mem_with_ASD\n",
            "    - Childhood Autism Rating Scale\n",
            "    - Anxiety_disorder\n",
            "    - A10_Autism_Spectrum_Quotient\n",
            "    - A7\n",
            "    - A2\n",
            "    - A3\n",
            "    - Qchat_10_Score\n",
            "    - Who_completed_the_test\n",
            "    - A6\n",
            "    - A4\n",
            "    - A1\n",
            "    - Learning disorder\n",
            "    - Social_Responsiveness_Scale\n",
            "    - Global developmental delay/intellectual disability\n",
            "    - A8\n",
            "    - Sex\n",
            "\n",
            "[STEP 7/7] Saving best model and results...\n",
            "--------------------------------------------------\n",
            "Best model: Run 1\n",
            "  Validation AUC: 0.9964\n",
            "  Validation Accuracy: 0.9591\n",
            "  Features selected: 25\n",
            "  Saved to: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/baseline_3_best_model.json\n",
            "\n",
            "Training results saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/baseline_3_training_results_CPU.json\n",
            "Training summary saved: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/training_summary_CPU.json\n",
            "\n",
            "================================================================================\n",
            "BASELINE 3 TRAINING COMPLETED SUCCESSFULLY (CPU)\n",
            "================================================================================\n",
            "\n",
            "EXPERIMENT SUMMARY:\n",
            "  Method: RFECV (Wrapper - model-guided)\n",
            "  Feature selection: 25 -> 25.0 Â± 0.0 features\n",
            "  Reduction: 0.0%\n",
            "  Training runs: 10/10 successful\n",
            "  Compute backend: CPU (tree_method='hist', n_jobs=1)\n",
            "  Total training time: 0.20 minutes\n",
            "\n",
            "VALIDATION PERFORMANCE:\n",
            "  Mean AUC: 0.9964 Â± 0.0000\n",
            "  Best AUC: 0.9964 (Run 1)\n",
            "  AUC range: [0.9964, 0.9964]\n",
            "\n",
            "MOST STABLE FEATURES:\n",
            "  - A5: 10/10 runs (100%)\n",
            "  - Social/Behavioural Issues: 10/10 runs (100%)\n",
            "  - A9: 10/10 runs (100%)\n",
            "  - Speech Delay/Language Disorder: 10/10 runs (100%)\n",
            "  - Jaundice: 10/10 runs (100%)\n",
            "  - Genetic_Disorders: 10/10 runs (100%)\n",
            "  - Depression: 10/10 runs (100%)\n",
            "  - Age_Years: 10/10 runs (100%)\n",
            "  - Family_mem_with_ASD: 10/10 runs (100%)\n",
            "  - Childhood Autism Rating Scale: 10/10 runs (100%)\n",
            "\n",
            "OUTPUTS GENERATED:\n",
            "  Training results: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/baseline_3_training_results_CPU.json\n",
            "  Best model: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/baseline_3_best_model.json\n",
            "  All models: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/ (10 models)\n",
            "  RFECV details: /content/drive/MyDrive/ASD_GWO_XGBoost_Project/03_Results/output_notebook_02/cell_1_setup/baseline_3_rfecv/models/*_rfecv_details.json\n",
            "\n",
            "NEXT STEPS:\n",
            "  Cell 7: Baseline 3 Testing - Test set evaluation\n",
            "  Cell 8: Comprehensive comparison across all methods\n",
            "\n",
            "================================================================================\n",
            "READY FOR TESTING PHASE\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}